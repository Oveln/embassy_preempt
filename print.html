<!DOCTYPE HTML>
<html lang="zh-CN" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Embassy Preempt</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="An async preempt RTOS for embedded systems, inspired by embassy &amp; ucosii">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon-de23e50b.svg">
        <link rel="shortcut icon" href="favicon-8114d1fc.png">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex-ff4bb2db.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc-e5fa4c25.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">Embassy Preempt</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>
                        <a href="https://github.com/KMSorSMS/embassy_preempt" title="Git repository" aria-label="Git repository">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="介绍"><a class="header" href="#介绍">介绍</a></h1>
<h1 id="embassy-preempt"><a class="header" href="#embassy-preempt">embassy-preempt❤️</a></h1>
<p>embassy_preempt是一个嵌入式异步实时操作系统的调度模块。它通过Rust提供的协程机制，结合embassy的异步执行器的实现方式，并借鉴传统嵌入式实时操作系统uCOSII的任务切换机制，在任务调度时，若当前任务主动让权，则会进行栈复用；若当前任务被抢占，则会进行栈分配，并进行现场的保存，使得embassy_preempt同时具有了embassy低内存开销的优势以及uCOSII高实时性的特点。</p>
<h1 id="项目背景"><a class="header" href="#项目背景">项目背景📝</a></h1>
<p>在通常情况下，如uCOSII的嵌入式操作系统基本都以线程（或任务）为基本单位进行调度，这就使得每一个任务都将占有一个私有的栈空间。而在实际的应用中，在任务调度的过程中，大部分任务释放CPU都是由于主动让权，而非被高优先级的任务抢占，这使得栈空间存在一定的浪费。</p>
<p>而在embassy中，通过引入Rust的协程机制，使得栈空间的利用率得到了极大的提升。但是由于embassy的线程执行器中的协程之间无法进行抢占，并且进行协程调度时并没有优先级裁决机制，在多任务的情景下将导致若干个任务出现未被及时唤醒的情况，导致实时性较差，这是一个嵌入式实时操作系统无法接受的。</p>
<p>我们希望在已有的嵌入式实时操作系统的高实时性以及embassy的协程机制之间进行“折衷”，编写一个既可以满足实时应用环境下的实时性要求，又可以尽可能缩小内存使用的嵌入式异步实时操作系统调度模块——embassy_preempt。</p>
<h1 id="技术报告"><a class="header" href="#技术报告"><a href="#技术报告-1">技术报告</a>📦</a></h1>
<p><a href="https://liamy.clovy.top/article/RTOS/embassy-preempt">开发全流程日志</a></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="开发记录"><a class="header" href="#开发记录">开发记录</a></h1>
<h1 id="本篇主要内容"><a class="header" href="#本篇主要内容">本篇主要内容</a></h1>
<p>本篇的主要内容为：按照老师提供的实现路线进行开发时的设计、实现以及所遇到的问题</p>
<h1 id="一二阶段开发记录"><a class="header" href="#一二阶段开发记录">一、二阶段开发记录</a></h1>
<h2 id="关于入队列的变动"><a class="header" href="#关于入队列的变动">关于入队列的变动</a></h2>
<p>embassy里面是直接采用头插法将新的task_ref插入，从而更新run-queue链表，而仔细想想，我们的抢占式设计是不需要一个run-queue链表的，我们通过arena分配给taskstorage相应的空间过后，只需要保存它的指针到以数组里面即可（这个数组就相当于ucosii的OSTCBPRIO数组）</p>
<blockquote>
<p>之所以没有了一个freelist和tcblist维护分配信息，是因为分配的过程是由arena进行动态分配的，因为任务的大小不一样，但是很致命的一点是arena没办法对分配的任务（taskstorage）进行回收，尽管在嵌入式的情况来看，的确不需要，因为每个任务应该都是一个死循环，永远不会退出，所以也就不存在回收的问题。</p>
</blockquote>
<p>如果是这样的话，我们目前可以去掉下面这两个TCB的成员，因为不需要维护一个tcb的链表</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span> OSTCBNext: SyncUnsafeCell&lt;Option&lt;OS_TCB_REF&gt;&gt;, /* Pointer to next     TCB in the TCB list                 */
 OSTCBPrev: SyncUnsafeCell&lt;Option&lt;OS_TCB_REF&gt;&gt;, /* Pointer to previous TCB in the TCB list                 */
<span class="boring">}</span></code></pre>
<p>所以我们只需要一个以优先级为下标索引到OS_TCB_REF的数组，这个数组可以就放到全局的executor里面，同时还有位图的部分也应该放进去，主要是OSRdyGrp和OSRdyTbl</p>
<h2 id="poll-to-unready"><a class="header" href="#poll-to-unready">Poll to UNready</a></h2>
<p>在执行器里面采取这样的机制：</p>
<p>原来的embassy是poll的时候将整个队列里面的元素都按顺序poll一遍，并且从就绪队列里面删除。现在的思路是：</p>
<ol>
<li>首先没有抢占的情况：所有的任务都会poll一次，然后poll到await点的地方，就会返回，然后由executor将该任务重新设置为非就绪状态（i.e. 更新位图），然后根据位图找到下一个最高优先级任务去执行</li>
<li>再考虑加上抢占的情况：任务如果是在poll过程中被打断，executor不会更新它的位图，仍然该任务处于就绪状态，保存上下文后，切换到更高优先级任务执行。而如果在poll执行完，由执行器正在处理更新位图，以及查找下一个最高优先级的调度过程的时候，我们打算将这个地方设置为临界区，这样保证这里不会发生中断，中断只能发生在查找到并且转入下一个最高优先级任务之后的时候。</li>
</ol>
<h2 id="执行流程"><a class="header" href="#执行流程">执行流程</a></h2>
<p>原来的embassy的方式是：一次执行器的poll执行当前runqueue的所有任务，中途有就绪的任务会加入到“新”的runqueue（其实是原来的runqueue，只是runqueue在执行第一个任务时就会被清空），然后被poll的任务如果await了，就会自然的走到下一个任务执行。</p>
<p>而我们这里取消掉一次性poll完任务，而是一次poll一个任务，完成之后，将该任务设置为非就绪态，然后转到最高优先级任务执行，这里很重要的一点就是这里对于临界区的设置：</p>
<p>对于位图的所有操作都需要加在临界区里面完成：</p>
<p>我们的临界区应该这里需要包含：设置当前任务在位图中为非就绪， 查找位图找到最高优先级，并且设置OSCURPRIO为这个优先级</p>
<p>因为只需要保证在对于位图这个关键变量的读取修改过程是原子的即可</p>
<blockquote>
<p>这个设计比较巧妙，特别是我们需要将位图的修改（原任务）和读取（查找最高优先级新任务）放置在同一个临界区，我们拿几个假想情况来说明：
<del>1（反面例子）. 在查找位图之前，我们设置完当前任务在位图中为非就绪之后，如果能够发生抢占，有更高优先级任务就绪被调度，那么保存现场时，这个现场应该属于哪一个任务呢？当前任务刚刚被设置为非就绪，如果保存到这个任务上，那这个任务就不可能再被唤醒了（因为它并没有等待任何事件，并且被设置为了非就绪态），而新的任务还没有找到，所以我们的上下文就没有位置保存</del>
2（正面例子）. 在查找位图选择到最高优先级任务，并且设置当前任务为此任务后，如果还没有poll就遇到了中断抢占，如果此抢占中就绪的任务优先级不如我们这里调度的这个任务，那么这部分调度就直接不会进行，然后交换控制权，回到这个任务，从而继续执行。而如果优先级更高，就是任务切换的环节，那么就会查看这个当前任务是否拥有栈，如果没有栈，就需要将当前的协程栈（公共栈）分配给它，而反之，如果该任务有栈，那么就只需要把上下文放到这个栈里面，并且更新任务tcb中保存的堆栈ref即可（这部分在我们设计文档<a href="https://github.com/KMSorSMS/embassy_preempt/blob/main/docs/%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3.md">https://github.com/KMSorSMS/embassy_preempt/blob/main/docs/设计文档.md</a>里面有写，这里也会简要涉及一下）。切换到新任务执行的时候，如果新任务是没有栈的一个协程，那么由于前面的协程公共栈被抢了，所以需要分配一个新的公共栈给协程，并且通过poll来恢复执行程序，而如果新的任务有栈（算是线程），那么就只需要恢复线程就能恢复执行。</p>
</blockquote>
<p>这个关键的临界区过程的代码如下：</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>             self.set_task_unready(task);
                // after set the task as unready, we need to revoke its stack if it has.
                if task.OSTCBStkPtr.is_some() {
                    dealloc_stack(task.OSTCBStkPtr.as_ref().unwrap());
                }
                // set the task's stack to None
                task.OSTCBStkPtr = None;
                self.find_highrdy_set_cur()
<span class="boring">}</span></code></pre>
<p>注意这里我们还包含了栈的回收，说明一下它也是有必要在这里和位图的更新查找放在一起在同一个临界区进行的：</p>
<p>假设我们把这个过程提前，放在更新位图之前，如果它不在临界区，那么栈的回收过程如果被打断，那么可能会出现当前刚刚回收完成（因为回收过程是原子的，通过lock实现），任务的栈指针还在，所以抢占情况下，会将上下文保存在这个栈里面，但是这个栈已经被回收了，会出现未定义的行为。</p>
<p>那如果把这个过程单独放到一个临界区，那么也会有错误，因为在回收过后，如果任务还没被设置为非就绪态的时候，如果被抢占，那么会将当前程序的栈分配给该任务，然后又调用栈分配器分配一个新的栈给程序，这种情况下，恢复执行后，该任务的栈并不会被回收，因为上一步已经回收过了，然后该任务同样保留着栈，尽管它是经过主动让权来的，并且只是在主动让权的执行器处理中被抢占，但是这种处理就会使得这个任务让权后仍然是一个线程而不是协程。（当然，这样让我想到如果把执行器这部分过程也看做一个任务的话，好像就是可以接受的，不过我们暂且先按照原来的思路实现，后续改进可以考虑）</p>
<h3 id="续写临界区的讨论"><a class="header" href="#续写临界区的讨论">续写：临界区的讨论</a></h3>
<p>发现前面对于临界区的想法不是很全面，实际上就正确性而言的确只需要保证对全局变量的原子性即可，后续我们还会调整原来的这个设计。</p>
<h3 id="补充这个部分涉及栈回收"><a class="header" href="#补充这个部分涉及栈回收">补充：这个部分涉及栈回收</a></h3>
<p>在poll完一个任务之后（这个时候就是由于await主动让权走到执行器这里），如果任务是占有栈的，那么就把这个栈给回收了，如果没有占有栈，那就不需要做出什么变动。</p>
<p>我们先只考虑主动让权的情况：</p>
<p>那么肯定当前任务只要拥有栈，那就将这个栈回收（注意这里的任务没有现场保护，因为是主动让权，一定是await或者任务结束），然后我们选择最高优先级任务进行调度，如果这个任务有栈，那么就应该按照线程的恢复方式恢复现场，如果没有栈才会调用poll。</p>
<h3 id="补充同时这里恢复现场需要内联汇编"><a class="header" href="#补充同时这里恢复现场需要内联汇编">补充：同时这里恢复现场需要内联汇编</a></h3>
<p><a href="https://course.rs/advance/unsafe/inline-asm.html">内联汇编 - Rust语言圣经(Rust Course)</a></p>
<h2 id="wfe指令与时钟"><a class="header" href="#wfe指令与时钟">WFE指令与时钟</a></h2>
<p>WFE指令的功能如下：</p>
<p><img src="docs/graph/record1.png" alt="Untitled"></p>
<p>从上表中可以发现当我们使用了WFE指令之后将进入Sleep mode。</p>
<p>而几乎所有的处理器，进入低功耗模式或睡眠模式之后都会有部分CPU/MCU功能以及部分外设无法使用以实现降低能耗。而我们需要保证在使用了WFE指令之后，我们的delay还能正常工作，就必须保证我们使用的定时器不会在进入低功耗模式的时候被关闭。</p>
<p><img src="docs/graph/record2.png" alt="Untitled"></p>
<p>从上图中可以发现当我们使用了WFE指令之后，除了处理器时钟（AHB总线）被停止，其他所有的时钟都将正常工作。这意味着挂载在APB上的外设时钟Timer都可以正常工作。</p>
<p>唯一一个需要注意的点是：</p>
<p><img src="docs/graph/record3.png" alt="Untitled"></p>
<p>手册中提到，SysTick是基于处理器时钟的，因此当我们使用了WFE指令之后，将会导致SysTick无法正常工作。这应该也是Embassy中选择使用外设时钟进行delay设计的原因之一。<strong>同样的，在我们的系统中，由于我们在无任务调度的时候使用了WFE指令，因此我们不能使用Systick来实现操作系统的时间触发机制，我们只能按照Embassy的做法，占用一个外设时钟来作为delay的驱动时钟。</strong></p>
<h2 id="关于memoryx的设置问题"><a class="header" href="#关于memoryx的设置问题">关于Memory.x的设置问题</a></h2>
<p><a href="https://github.com/rust-embedded/cortex-m-quickstart/blob/master/README.md">https://github.com/rust-embedded/cortex-m-quickstart/blob/master/README.md</a></p>
<h2 id="过大函数调用栈开销"><a class="header" href="#过大函数调用栈开销">过大函数调用栈开销</a></h2>
<p><img src="docs/graph/record4.png" alt="Untitled"></p>
<p>claim这里，这个critical-section，在进入这个临界区之前，sp是170，进入之后170的栈直接没了，直接消耗完了</p>
<p><img src="docs/graph/record5.png" alt="Untitled"></p>
<p>这个闭包的栈这么大，416Byte</p>
<p>这就得仔细看看反汇编它为啥吃了这么多栈（sub sp, #408 进一步确认了里面函数栈用掉了408字节（416B是加上r7和sp的压栈））：</p>
<p><img src="docs/graph/record6.png" alt="Untitled"></p>
<p>进入到arena的alloc后，用的栈也不少，我开始觉得是不是这里编译器没有优化（因为我为了调试方便设置的不优化）</p>
<p><img src="docs/graph/record7.png" alt="Untitled"></p>
<h3 id="于是我就试试开优化"><a class="header" href="#于是我就试试开优化">于是我就试试开优化</a></h3>
<p>又出问题了，开了优化之前换栈之后的跳转返回出问题了</p>
<p><img src="docs/graph/record8.png" alt="Untitled"></p>
<p>发现原因，优化过后这里做成内联了：</p>
<p><img src="docs/graph/record9.png" alt="Untitled"></p>
<p>于是我想到：是不是可以利用这个，我想办法让这个外部函数做出内联，这样以后都直接不需要函数跳转返回了</p>
<h1 id="第三阶段开发记录"><a class="header" href="#第三阶段开发记录">第三阶段开发记录</a></h1>
<h2 id="第三阶段"><a class="header" href="#第三阶段"><strong>第三阶段</strong></a></h2>
<p>在uCOS中<strong>有中断的场景</strong>下，引入embassy和优先级，以支持线程和协程的优先级调度；</p>
<ul>
<li>中断就是抢占情况，需要保存堆栈，并（有可能）分配新堆栈，用于恢复下一个任务；</li>
</ul>
<h2 id="第三阶段设计"><a class="header" href="#第三阶段设计"><strong>第三阶段设计</strong></a></h2>
<p>在开始第三阶段的coding之前，需要考虑以下的几个问题</p>
<h3 id="明确任务边界"><a class="header" href="#明确任务边界"><strong>明确任务边界</strong></a></h3>
<p>即需要明确哪一部分代码属于任务执行的代码。由于编译器为我们完成了非叶子future状态机的状态转换过程，因此导致在判定代码是否属于任务时会显得比较模糊。但是经过我们的分析之后，认为只有当从任务中返回到执行器代码时，才代表着该任务结束，即将状态转移等编译器生成的代码的执行也认为是任务的执行。如果这样划分的话，那么在中断时是否需要分配栈就变得容易区分了：如果当前在执行的是执行器代码，那么此时在中断中不需要分配栈(因为上一个任务已经主动让权了)；如果当前执行的不是执行器代码，那么此时如果发生了抢占，就需要在中断中就需要分配栈，因为当前的任务的执行流被打断了，并且即将被抢占。</p>
<h3 id="如何让中断程序知道当前在执行哪部分代码"><a class="header" href="#如何让中断程序知道当前在执行哪部分代码"><strong>如何让中断程序知道当前在执行哪部分代码？</strong></a></h3>
<p>对中断服务程序而言，如果不做任何的干预，它是无法知道当前在执行的究竟是执行器代码还是任务代码的。我们目前的设想是，将执行器代码放入临界区中，让其不可被打断，那么这样就会使得所有的中断都将在执行任务代码时产生，这样所有将导致抢占的中断都可以无脑分配一个栈给当前任务，使得处理得以简化。</p>
<p>目前有两种比较类型的实现方式：</p>
<ul>
<li>为执行器增加一个状态成员，以标记当前执行器是否在执行任务代码</li>
<li>设定一个全局变量：进入执行器代码时以及退出执行器代码时都对一个全局变量进行设置，在进行栈分配时对全局变量进行检查</li>
</ul>
<h3 id="中断服务程序如何设计"><a class="header" href="#中断服务程序如何设计"><strong>中断服务程序如何设计？</strong></a></h3>
<p>在中断服务程序中，我们还应该在中断返回时增加几个功能：</p>
<ul>
<li>栈分配模块(仅在发生抢占时执行，即新任务的优先级更高)：用于分配一个新栈以供系统继续运行。而旧栈将用于保存原有任务的执行现场</li>
<li>唤醒模块：将新任务设置为就绪状态</li>
<li>抢占调度模块：用于在中断返回时进行重调度 我们将把前两个模块作为唤醒器Waker的功能。而对于抢占重调度，我们将重新编写一个调度函数接口。</li>
</ul>
<h3 id="抢占调度"><a class="header" href="#抢占调度">抢占调度</a></h3>
<p>首先先回顾一下目前我们的poll函数的执行流程：</p>
<ul>
<li>启动：找到当前优先级最高的任务，然后执行该任务。</li>
</ul>
<aside>
💡 此时，我们会判断当前任务是否拥有一个栈，即判断任务是由线程执行还是由协程执行
</aside>
<ul>
<li>栈回收：在该任务让权之后，将会判断该任务是否拥有一个栈，如果拥有一个栈的话，将回收该栈</li>
<li>继续调度：完成栈回收之后，将重新寻找最高优先级的任务，并执行该任务。接下来将循环2、3步直至所有的任务都主动让权。</li>
</ul>
<p>目前我们的设想是通过修改poll函数，使其能够在完成现阶段的功能下（即支持让权调度）支持抢占调度。</p>
<p>我们目前设想的方案为：若新任务没有栈（即代表新任务未被抢占过），旧任务没有栈，则此时需要分配一个新栈以供所有的任务执行，而旧栈将作为旧任务的私有栈用于保存上下文以及调用关系；若新任务有栈，旧任务没有栈，则此时不需要再额外分配一个栈，而是直接将新任务的上下文从栈中恢复之后，再将新栈作为所有任务的公共栈，而非新任务的私有栈，直至通过poll函数找到了一个拥有栈的任务之后，再将当前的公用栈回收再从。而旧栈同样将做为旧任务的私有栈使用。</p>
<p>此外，我们将对栈的操作分为三类：</p>
<ul>
<li>栈回收：即将栈“销毁”，对应的可能是栈清空等操作</li>
<li>栈复用：即将某一个任务的私有栈作为所有任务共用的栈，只是将任务TCB中的栈指针置为None</li>
<li>栈分配：即通过栈分配器分配一个栈用以接下来的任务共用</li>
</ul>
<p>因此，上述文字转换为表格即为：</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>切换方式</th><th>新任务</th><th>旧任务</th><th>操作</th></tr>
</thead>
<tbody>
<tr><td>抢占</td><td>无栈</td><td>无栈</td><td>不存在</td></tr>
<tr><td>抢占</td><td>无栈</td><td>有栈</td><td>无需操作</td></tr>
<tr><td>抢占</td><td>有栈</td><td>无栈</td><td>不存在</td></tr>
<tr><td>抢占</td><td>有栈</td><td>有栈</td><td>不存在？</td></tr>
<tr><td>让权</td><td>无栈</td><td>无栈</td><td>无需操作</td></tr>
<tr><td>让权</td><td>无栈</td><td>有栈</td><td>不存在</td></tr>
<tr><td>让权</td><td>有栈</td><td>无栈</td><td>栈回收</td></tr>
<tr><td>让权</td><td>有栈</td><td>有栈</td><td>不存在</td></tr>
</tbody>
</table>
</div>
<aside>
💡 不可能出现的情况在上表中记为“不存在”，不需要做做任何操作，仅需要进行正常任务调度的情况记为“无需操作”。在这里已经不会出现栈分配的情况是由于所有抢占调度的栈分配都将在栈分配阶段完成，因此在调度阶段旧任务无栈的情况是不存在的；这里没有栈复用的情况是由于，我们目前认为，中断服务程序只会唤醒通过await让权之后退出就绪队列的任务，即新任务无栈，因此栈复用的情况也不存在了
</aside>
<p>从上表的讨论可以发现，如果在wake阶段以及栈分配阶段进行栈分配并且将任务置入就绪队列的话，那么或许就可以直接复用现有的poll方法。</p>
<h2 id="关于抢占的讨论与看法"><a class="header" href="#关于抢占的讨论与看法">关于抢占的讨论与看法</a></h2>
<p>在前面做1、2阶段的实现的时候，我在写执行器的poll函数的时候想了比较多的地方，最开始认为集中的把：设置当前任务为unready、回收栈、查找最高优先级任务调度整个过程都设计在一个临界区里面保证线性连续执行是高效并且有必要的。但是在后续开发思考的时候，至少对于必要性有了质疑，这里我先论证一下是否必要：</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>self.set_task_unready(task);
// after set the task as unready, we need to revoke its stack if it has.
if task.OSTCBStkPtr.is_some() {
    dealloc_stack(task.OSTCBStkPtr.as_mut().unwrap());
}
// set the task's stack to None
task.OSTCBStkPtr = None;
self.find_highrdy_set_cur()
<span class="boring">}</span></code></pre>
<p>我认为只需要对executor（因为设计为全局变量）的关键成员变量（也就是位图，OSPrioCur）分别设置临界区就行了，同样正确性是不会有问题的。</p>
<p>为了证明这一点，只能（我能想到的方法）列举出（几乎）所有情况来说明：</p>
<p>我们poll的操作如下：</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub(crate) unsafe fn poll(&amp;'static self) {
        // find the highest priority task in the ready queue
        let task = critical_section::with(|_| self.find_highrdy_set_cur());
        if task.is_none() {
            return;
        }
        let mut task = task.unwrap();
        if task.OSTCBStat.run_dequeue() {
            if task.OSTCBStkPtr.is_none() {
                task.OS_POLL_FN.get().unwrap_unchecked()(task);
            } else {
                // if the task has stack, it's a thread, we need to resume it not poll it
                task.restore_context_from_stk();
            }
        }
        // after the task is done, we need to set the task to unready(in bitmap) and also we need to find the next task to run
        // both of this process should be done in critical section
        loop {
            match critical_section::with(|_| {
                self.set_task_unready(task);
                // after set the task as unready, we need to revoke its stack if it has.
                if task.OSTCBStkPtr.is_some() {
                    dealloc_stack(task.OSTCBStkPtr.as_mut().unwrap());
                }
                // set the task's stack to None
                task.OSTCBStkPtr = None;
                self.find_highrdy_set_cur()
            }) {
                Some(t) =&gt; {
                    task = t;
                    if task.OSTCBStat.run_dequeue() {
                        // in the future, we should consider thread here
                        task.OS_POLL_FN.get().unwrap_unchecked()(task);
                    }
                }
                None =&gt; {
                    break;
                }
            }
        }
    }
<span class="boring">}</span></code></pre>
<p>poll里面会进行任务的让权切换，poll的调用总是由于当前没有任务执行后才调用的，也就是所有任务都await了，这里我就想到有个地方会出问题：如果最后一个任务被poll调度执行了，然后它await出来，然后executor发现目前没有任务可以调度，那么跑到None准备break，如果这个时候中断来了，wake了某个任务，从而让该任务变为就绪，这个时候当然就在interrupt里面可以执行任务抢占调度，转向高优先级任务执行（也就是刚就绪的那个任务），<del>这一步跳转的实现我在想应该可以复用执行器的poll，这样如果这个任务执行await让权，又能重新继续。</del> <del>这会经历将当前的程序栈分配给当前任务，将当前任务设置为</del>  这个时候是没有任务被选择执行的状态，那么是不是就没有保证当前上下文的必要，直接跳转到新的任务执行即可，并且这个时候是能直接复用poll的，只需要我们把外部的wfe的执行放置到idle任务去执行：</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    loop {
        unsafe {
            GlobalSyncExecutor.as_ref().unwrap().poll();
            info!("==========enter Task Idle...===========");
            run_idle();
            info!("==============wake up!==============");
        }
    }
<span class="boring">}</span></code></pre>
<p>也就是在这里，把run_idle()更改到idle任务（prio为OS_LOWEST_PRIO）去执行</p>
<p>TODO：临界区分开设置的可行性讨论：</p>
<h3 id="ok顺着这个思路我们重新想想中断的处理"><a class="header" href="#ok顺着这个思路我们重新想想中断的处理">ok，顺着这个思路我们重新想想中断的处理</a></h3>
<p>如果中断都变成只是任务设置为就绪，那实时性无法保证，而且也做不到抢占调度。我的设想是执行器的poll就做成**一个循环：**找到最高优先级，调度最高优先级任务执行，然后将任务设置为非就绪，然后重复。中途发生抢占只会出现在执行任务的过程中（注意，这个是包括了：</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>   if task.OSTCBStkPtr.is_none() {
                task.OS_POLL_FN.get().unwrap_unchecked()(task);
            } else {
                // if the task has stack, it's a thread, we need to resume it not poll it
                task.restore_context_from_stk();
            }
<span class="boring">}</span></code></pre>
<p>这整个过程）</p>
<p>这个时候如果中断抢占调度，那么将当前的栈（程序栈）分配给执行任务，保存它的上下文到这个栈，然后恢复新的任务，如果该任务有栈，那么把它的栈给到程序栈（设置PROGRAM_STACK变量，并且更改PSP设置程序栈），然后去掉该任务的栈（设置它的stk为NONE），然后恢复它的上下文执行，但是这里，这样这个任务执行的时候就是一个无栈的协程，用的是程序栈。<del>等这个程序执行完成后，会先返回到原来中断处理函数的结尾（但是此时是函数返回进入，在调度执行前，应该要设置取消掉中断状态），然后继续返回回执行器的poll部分</del>。</p>
<p>感觉还可以把这个过程细化的说一下（将几个关键过程放在同一个临界区的模式，后续这种模式可能会改变为拆分成多个临界区）：</p>
<ol>
<li>中断抢占发生, 一部分现场立刻被保存到当前程序栈(psp)上（xPSR, PC, LR, R12, R0-R3），同时栈会切换到msp异常堆栈</li>
<li>中断处理函数里面，由于某个future好了，设置对应的任务为就绪，执行执行器的中断poll函数（目前还没写这个函数），并且在cortex-m的情况下，我们想要退出中断处理模式需要参考手册：</li>
</ol>
<p><img src="docs/graph/record10.png" alt="Untitled"></p>
<p><img src="docs/graph/record11.png" alt="Untitled"></p>
<ol>
<li>
<p>在执行器的中断poll函数（目前还没写这个函数，这个函数参考ucosii port里面的pendsv的实现）中， 会找到最高优先级任务，然后将程序栈分配给被打断的程序（可以判断是否当前任务就是最高优先级的，是的话就不分配栈，直接异常/中断返回即可）。这样当前任务的上下文就保存了。然后转向最高优先级任务的处理。</p>
</li>
<li>
<p>如果最高优先级任务是没有栈的，这里就和ucosii不一样，首先我们要给它<strong>分配一个栈空间</strong>用于程序执行，然后这里需要模拟压栈（先是xPSR, PC, LR, R12, R0-R3，其中xpsr赋值为0x01000000，PC赋值为执行器poll的地址，LR为一个TASK_RETURN函数地址，R12，R0-R3的值任意，然后是R4-R11赋值为任意, LR赋值为0xFFFFFFFD），这样后续的过程和第5步一样，相当于任务的栈就是目前的psp</p>
</li>
<li>
<p><del>如果最高优先级任务是有栈的，和ucosii基本一样，将任务的栈先出栈R4-R11, R14（这些是任务保存的不是进入异常保存的寄存器），然后将psp设置为当前的任务栈（出栈后的）（这里同步修改全局变量PROGRAM_STACK，之前它的值的所有权会转移给原任务的OSTCBStkPtr字段，用于上下文保存），然后执行BX LR（也就是R14，通常这里面会装入0xFFFFFFFD），进行异常返回，从而切换到新的任务执行。</del></p>
<p><img src="docs/graph/record12.png" alt="Untitled"></p>
</li>
</ol>
<p>执行器的poll的body也有变动：</p>
<p>对于执行到有栈的任务的时候，就需要进行栈回收，因为切换到该任务执行后就是把整个psp函数栈都切换走了，实际上当前的这个psp栈就不需要了，所以将变量PROGRAM_STACK的值更新为新的栈，将原来的栈dealloc掉。这里也就是我们这个栈回收的地方，前面上文的抢占过程就是栈分配产生的地方。</p>
<p>至此整个流程设计完成，还剩下关于临界区的分割的问题，我觉得可以写完了代码之后再做细化。</p>
<h3 id="一点更正"><a class="header" href="#一点更正">一点更正</a></h3>
<p>会更模仿ucosii的处理，借助pendsv中断实现抢占的时候的任务切换。</p>
<p>中断poll函数：</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// this function must be called in the interrupt context, and it will trigger pendsv to switch the task
    /// when this function return, the caller interrupt will also return and the pendsv will run.
    pub(crate) unsafe fn interrupt_poll(&amp;'static self) {
        extern "Rust" {
            fn OSTaskStkInit(stk_ref: NonNull&lt;OS_STK&gt;) -&gt; NonNull&lt;OS_STK&gt;;
            fn restore_thread_task();
        }
        // find the highest priority task in the ready queue
        critical_section::with(|_| self.set_highrdy());
        // judge if the highest priority task is the current running task(which has been preemped by the interrupt)
        // prio's number is small indicates the priority is high
        if self.OSPrioHighRdy.get() &gt;= self.OSPrioCur.get() {
            return;
        }
        let mut task  = self.OSTCBHighRdy.get();
        // then we need to restore the highest priority task
        if task.OSTCBStkPtr.is_none() {
            // if the task has no stack, it's a task, we need to mock a stack for it.
            // we need to alloc a stack for the task
            let layout = Layout::from_size_align(TASK_STACK_SIZE, 8).unwrap();
            let mut stk = alloc_stack(layout);
            // then we need to mock the stack for the task(the stk will change during the mock)
            stk.STK_REF = OSTaskStkInit(stk.STK_REF);
            task.OSTCBStkPtr = Some(stk);
        }
        // restore the task from stk
        unsafe { restore_thread_task() };
    }
<span class="boring">}</span></code></pre>
<h3 id="说明为什么需要用pendsv"><a class="header" href="#说明为什么需要用pendsv">说明：为什么需要用PendSV</a></h3>
<p><a href="https://stackoverflow.com/questions/74805269/pendsv-and-svcall-in-rtos">https://www.embedded.com/programming-embedded-systems-rtos-automating-the-context-switch/</a></p>
<blockquote>
<p>In ARM Cortex-M, ISRs can also nest (preempt each other), so only the return from the last nested interrupt (back to the thread level) should perform a context switch. The problem is that the order of ISR preemption changes dynamically at runtime, so you generally don’t know which one will be the last.</p>
<p>An elegant solution employed in virtually all RTOSs for ARM Cortex-M is to take advantage of the same interrupt nesting mechanism that created the problem in the first place. Specifically, Cortex-M provides the PendSV exception (Pend Service Call) [2], which you can program to perform the context switch and configure with the lowest interrupt priority (0xFF). When the RTOS detects the need to switch the context, it can pend the PendSV exception. The interrupt prioritization ensures that PendSV will be the last ISR to run just before returning to the thread level. Moreover, the NVIC in ARM Cortex-M has a built-in hardware optimization called “tail chaining,” which eliminates the overhead of exiting one interrupt (e.g., SysTick) and entering PendSV, so the context switch is performed with minimal overhead.</p>
</blockquote>
<p><a href="https://blog.csdn.net/u012351051/article/details/124789418">https://blog.csdn.net/u012351051/article/details/124789418</a></p>
<blockquote>
<p>当OS的Systick中断级别低于外部中断时，确实不会触发Fault，但是这带来了一个问题：</p>
<blockquote>
<p>一般OS在调度任务时，会关闭中断，也就是进入临界区，而OS任务调度是要耗时的，这就会出现一种情况：</p>
<p>在任务调度期间，如果新的外部IRQ发生，CPU将不能够快速响应处理。</p>
</blockquote>
<ol>
<li>滴答定时器中断，制作业务调度前的判断工作，不做任务切换。</li>
<li>触发PendSV，PendSV并不会立即执行，因为PendSV的优先级最低，如果此时正好有IRQ请求，那么先响应IRQ，最后等到所有优先级高于PendSV的IRQ都执行完毕，再执行PendSV，进行任务调度。</li>
</ol>
</blockquote>
<h2 id="差分等待链表的讨论"><a class="header" href="#差分等待链表的讨论">差分等待链表的讨论</a></h2>
<p>参考embassy-executor的poll里面timer queue的设计：</p>
<p><img src="docs/graph/record13.png" alt="image.png"></p>
<p><img src="docs/graph/record14.png" alt="image.png"></p>
<p><img src="docs/graph/record15.png" alt="image.png"></p>
<p>通过观察，我发现仿照这种定时器思路，设置一个超时时间，这种方式下，差分链表没什么意义，因为不需要去更新每个tcb的等待时间，只需要保留tcb的expire的绝对时间即可。不过每次需要找到等待时间队列里面expire值最小的任务，如果不提前进行排序的话，就要遍历查找了。</p>
<p>我的感觉是维护一个有序链表更好，让链表的头结点存放最小expire的等待任务，这样超时出队的时候也很快，只需要依次弹出所有的超时任务，直到遇到一个非超时的就停止，同时找next_expiration的值也很简单，只需要在deque后，把链表头的任务的等待值给出即可。它唯一的开销就是在await的时候注册这样一个等待任务，但是这种开销本身和遍历查找类似，并且发生在程序运行时，而我们设计的这个时间更新情况，是发生在中断时，中断时的处理应该简单迅速，所以我决定有序链表更好。</p>
<p>那么我们需要和原来embassy变动的地方就主要是那几个时间链表的关键接口：</p>
<p><img src="docs/graph/record16.png" alt="image.png"></p>
<h2 id="时钟中断的设计问题记录"><a class="header" href="#时钟中断的设计问题记录">时钟中断的设计问题记录</a></h2>
<p>如果是通过设置定时器的触发中断来实现定时唤醒，那不仅在普通的poll里面会这样设置时间</p>
<p><img src="docs/graph/record17.png" alt="image.png"></p>
<p>（我是拿一个变量set_time来表示目前定时器设置的中断触发时间点），同时还需要每次触发时钟中断后，马上也再设置下一次的中断唤醒时间点，</p>
<h2 id="中断开发"><a class="header" href="#中断开发">中断开发</a></h2>
<p><a href="https://github.com/embassy-rs/stm32-data-generated/blob/63dcecb1b412ec6e7f872b652f6bf4809e0a94c2/stm32-metapac/src/chips/stm32f401re/pac.rs#L62">https://github.com/embassy-rs/stm32-data-generated/blob/63dcecb1b412ec6e7f872b652f6bf4809e0a94c2/stm32-metapac/src/chips/stm32f401re/pac.rs#L62</a></p>
<p>这里是pac定义中断向量名称的地方。</p>
<p>有个问题是怎么实现</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// an async delay
pub fn OSTimeDly(_ticks: INT32U) {
    
}
<span class="boring">}</span></code></pre>
<p>普通的函数里面是不能使用await的，而事实上，我们不可能让delay一个函数做到和await一样的效果，因为await是需要编译器生成代码的时候针对代码的上下文生成相应的状态保存代码，而这不可能由一个函数在运行时做到。</p>
<h1 id="debug记录"><a class="header" href="#debug记录">debug记录</a></h1>
<h2 id="pendsv恢复栈出现问题"><a class="header" href="#pendsv恢复栈出现问题">pendsv恢复栈出现问题：</a></h2>
<p><img src="docs/graph/record18.png" alt="image.png"></p>
<p>但是上一步分给没有栈的新任务的模拟压栈是0x20001800</p>
<p><img src="docs/graph/record19.png" alt="image.png"></p>
<p><img src="docs/graph/record20.png" alt="image.png"></p>
<p>然后压栈完成后会变成17c0（因为有16个4字节寄存器压栈）</p>
<p><img src="docs/graph/record21.png" alt="image.png"></p>
<p>走进pendsv这一步还是对的，取出来的highrdy的栈是0x200017c0：</p>
<p><img src="docs/graph/record22.png" alt="image.png"></p>
<p>这一步出问题了；</p>
<p><img src="docs/graph/record23.png" alt="image.png"></p>
<p>找到原因：</p>
<p><img src="docs/graph/record24.png" alt="image.png"></p>
<p>这里我先把cur设置为了highrdy导致后面将上下文最终保存到cur任务的时候实际上保存错了位置，保存到highrdy的位置里面去了。所以应该修改为保存了上下文到cur任务后，再调整cur任务为higrdy任务：</p>
<p><img src="docs/graph/record25.png" alt="image.png"></p>
<p>改完后，到这里，栈pop出的值都是对的：</p>
<p><img src="docs/graph/record26.png" alt="image.png"></p>
<p>观察模拟压栈的内容：</p>
<p><img src="docs/graph/record27.png" alt="image.png"></p>
<p>是完全正确的。</p>
<h2 id="发现pendsv被连续触发怀疑是需要清除什么中断标志"><a class="header" href="#发现pendsv被连续触发怀疑是需要清除什么中断标志">发现pendsv被连续触发，怀疑是需要清除什么中断标志</a></h2>
<p><img src="docs/graph/record28.png" alt="image.png"></p>
<p><img src="docs/graph/record29.png" alt="image.png"></p>
<p>但是发现进入pendsv的时候PENDSVSET这一位就被清零了的</p>
<p><img src="docs/graph/record30.png" alt="image.png"></p>
<p>最后发现是新任务有栈（之前模拟压栈或者本身就有，导致进入poll之后就又跑去restore context了)：</p>
<p><img src="docs/graph/record31.png" alt="image.png"></p>
<h2 id="中断保存的lr有问题"><a class="header" href="#中断保存的lr有问题">中断保存的lr有问题</a></h2>
<p><img src="docs/graph/record32.png" alt="image.png"></p>
<p>在进入中断的时候出现了问题，这里有个跳转才会进入我写的pendsv，那就会出现pendsv里面保存的lr是错误的。</p>
<p>所以我在想是不是开优化可以解决这个问题，做到不进行函数跳转。</p>
<p><img src="docs/graph/record33.png" alt="image.png"></p>
<p>果然如此</p>
<h2 id="栈溢出"><a class="header" href="#栈溢出">栈溢出</a></h2>
<p>在进行模拟压栈时，由于没有考虑到满递减堆栈的前自减，导致最高地址的xpsr寄存器溢出：</p>
<p><img src="docs/graph/record34.png" alt="image.png"></p>
<p>使得堆分配器的元数据的hole的size成员被覆盖：</p>
<p><img src="docs/graph/record35.png" alt="image.png"></p>
<h2 id="唤醒时的none"><a class="header" href="#唤醒时的none">唤醒时的None</a></h2>
<p>在alarm中断出现时，发现在对需要唤醒的任务引用调用wake方法时，出现自动解引用的None/unwrap异常</p>
<p>经过排查发现是dequeue中的set函数将导致头节点中的Some被覆盖为None：</p>
<p><img src="docs/graph/record36.png" alt="image.png"></p>
<p>因此我们将on_task函数的调用提前到set函数之前执行</p>
<h2 id="唤醒错误"><a class="header" href="#唤醒错误">唤醒错误</a></h2>
<p>在alarm中断发生时，在多个任务需要等待的情况下，发现唤醒的任务错误。经过排查发现是update更新time_queue时出现错误，没有考虑到需要插入到队尾的情况，导致当某一个任务需要被插入到队尾时，会直接将头指针覆盖，使得被唤醒的任务不符合预期</p>
<h2 id="set_alarm的设计"><a class="header" href="#set_alarm的设计">set_alarm的设计</a></h2>
<p>我们采取使用循环set_alarm的方式实现alarm的设置：</p>
<p><img src="docs/graph/record37.png" alt="image.png"></p>
<p>使用这种方式的主要原因如下：</p>
<blockquote>
<p>就是假如说现在timequeue里面已经有一个任务（假如说叫任务1）正在延时，然后我现在有一个任务也需要延时，但是他在set_alarm的时候发现已经到了，set_alarm就会返回false，但是他并不会去设置输出比较通道的ccr寄存器。如果这个时候是if判断的话，那么现在这个执行流就会继续往下走了，但是这个时候alarm并没有被设置为任务1的延时时间点</p>
</blockquote>
<p>我们在讨论的过程中还出现了一种想法：</p>
<blockquote>
<p>还有就是可能在原来任务延时的时候他的时钟设置就被设置了，然后在新任务发现超时了之后，由于没有对时钟配置进行修改，就会使得时钟还保留着原来任务的延时时间设置。这么看的话好像又不用重新set alarm一次。但是我刚刚重新看了一遍set alarm，他的timestamp是每次调用set alarm都会被设置的，所以好像还是要像poll里面那样用循环。但是讲道理这个对我们的影响应该不大，因为每次任务执行结束我们都会set一次alarm。但是我不知道embassy是怎么处理这个问题的，可能他也觉得影响不大就直接忽略了)</p>
</blockquote>
<p>我们认为在我们当前的系统中为了提高实时性，仍然需要采用循环的方式进行alarm的设置，因为：</p>
<blockquote>
<p>在新任务出现超时时，仍然可能对原来的时钟配置进行修改</p>
<p><img src="docs/graph/record38.jpg" alt="62f21eb1c0a70f2782d6288bd710a48d.JPG"></p>
<p>set_alarm有两次超时情况，第一次超时的确不会改变时钟配置，但是如果第一次检测没超时，但是设置了时钟后又超时，就会更改时钟</p>
<p><img src="docs/graph/record39.jpg" alt="eec7af38112f6b662e72301371662023.JPG"></p>
<p>。而且你后面说的timestamp的存在也确实导致需要通过这样的while循环来设置正确的时钟：</p>
<p><img src="docs/graph/record40.jpg" alt="b5e5928f696b93e2fad19a620650697d.JPG"></p>
</blockquote>
<h2 id="神奇的ffi"><a class="header" href="#神奇的ffi">神奇的ffi</a></h2>
<p><img src="docs/graph/record38.png" alt="image.png"></p>
<p>这个时候就是把参数从R0开始作为第一个参数放置的位置</p>
<h3 id="详细描述一下这个问题"><a class="header" href="#详细描述一下这个问题">详细描述一下这个问题：</a></h3>
<p>参数情况：</p>
<pre><code class="language-toml"># cargo build --release
[profile.release]
codegen-units = 1
debug = 2  
opt-level = 0  
</code></pre>
<p>执行命令cargo build –release</p>
<p>结果：</p>
<pre><code class="language-bash">  Compiling ucosii v0.1.0 (/home/liam/learnRust/embassy_preempt/ucosii)
  Finished `release` profile [unoptimized + debuginfo] target(s) in 2.48s
</code></pre>
<p>用gdb-multiarch进行调试，调试代码：</p>
<p>尤其注意!!!返回值OS_ERR_STATE这里是4字节</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span> // os初始化
    OSInit();
    // 创建两个任务
    SyncOSTaskCreate(task1, 12 as *mut c_void, 11 as *mut usize, 10);
    ...
    
    //
pub trait ReturnUnitOrNeverReturn {}

impl ReturnUnitOrNeverReturn for ! {}
impl ReturnUnitOrNeverReturn for () {}
/// Create a task in uC/OS-II kernel. This func is used by C
// _ptos is not used in this func, because stack allocation is done by the stack allocator when scheduling
pub extern "aapcs" fn SyncOSTaskCreate&lt;F, R&gt;(task: F, p_arg: *mut c_void, _ptos: *mut OS_STK, prio: INT8U) -&gt; OS_ERR_STATE
where
    // check by liam: why the future is 'static: because the definition of OS_TASK_STORAGE's generic F is 'static
    F: FnOnce(*mut c_void) -&gt; R + 'static,
    R: ReturnUnitOrNeverReturn,
{
    // check the priority
    if prio &gt; OS_LOWEST_PRIO as u8 {
        return OS_ERR_STATE::OS_ERR_PRIO_INVALID;
    }
    ...
}

<span class="boring">}</span></code></pre>
<p>看到对应的汇编部分（完整的给出传参部分的处理）</p>
<pre><code class="language-bash">0x080031dc  preempt_test::__cortex_m_rt_test_basic_schedule+6  bl      0x8006344 &lt;ucosii::os_core::OSInit&gt;
0x080031e0  preempt_test::__cortex_m_rt_test_basic_schedule+10 movs    r0, #12
0x080031e2  preempt_test::__cortex_m_rt_test_basic_schedule+12 str     r0, [sp, #8]
0x080031e4  preempt_test::__cortex_m_rt_test_basic_schedule+14 movs    r1, #11
0x080031e6  preempt_test::__cortex_m_rt_test_basic_schedule+16 str     r1, [sp, #4]
0x080031e8  preempt_test::__cortex_m_rt_test_basic_schedule+18 movs    r2, #10
0x080031ea  preempt_test::__cortex_m_rt_test_basic_schedule+20 bl      0x8000d80 &lt;ucosii::os_task::SyncOSTaskCreate&gt;
//调用函数,包含部分传参
...
0x08000d80  ucosii::os_task::SyncOSTaskCreate+0  push  {r7, lr}
0x08000d82  ucosii::os_task::SyncOSTaskCreate+2  mov   r7, sp
0x08000d84  ucosii::os_task::SyncOSTaskCreate+4  sub   sp, #136        ; 0x88
0x08000d86  ucosii::os_task::SyncOSTaskCreate+6  str   r1, [sp, #28]
0x08000d88  ucosii::os_task::SyncOSTaskCreate+8  str   r0, [sp, #32]
0x08000d8a  ucosii::os_task::SyncOSTaskCreate+10 mov   r3, r2
0x08000d8c  ucosii::os_task::SyncOSTaskCreate+12 str   r3, [sp, #36]   ; 0x24
0x08000d8e  ucosii::os_task::SyncOSTaskCreate+14 str   r0, [sp, #76]   ; 0x4c
0x08000d90  ucosii::os_task::SyncOSTaskCreate+16 str   r1, [sp, #80]   ; 0x50
0x08000d92  ucosii::os_task::SyncOSTaskCreate+18 strb.w        r2, [r7, #-49]
0x08000d96  ucosii::os_task::SyncOSTaskCreate+22 movs  r0, #0
0x08000d98  ucosii::os_task::SyncOSTaskCreate+24 strb.w        r0, [r7, #-62]
0x08000d9c  ucosii::os_task::SyncOSTaskCreate+28 movs  r0, #1
0x08000d9e  ucosii::os_task::SyncOSTaskCreate+30 strb.w        r0, [r7, #-62]
0x08000da2  ucosii::os_task::SyncOSTaskCreate+34 cmp   r2, #63 ; 0x3f
0x08000da4  ucosii::os_task::SyncOSTaskCreate+36 bhi.n 0x8000df0 &lt;ucosii::os_task::SyncOSTaskCreate+112&gt;
0x08000da6  ucosii::os_task::SyncOSTaskCreate+38 b.n   0x8000da8 &lt;ucosii::os_task::SyncOSTaskCreate+40&gt;
0x08000da8  ucosii::os_task::SyncOSTaskCreate+40 ldr   r0, [sp, #32]
0x08000daa  ucosii::os_task::SyncOSTaskCreate+42 movs  r1, #0
</code></pre>
<p>可以观察到，参数的值来源于栈，下图给出了gdb-multiarch里面的变量信息（执行到0x08000da2  ucosii::os_task::SyncOSTaskCreate+34 cmp   r2, #63 ; 0x3f）</p>
<p>可以看到变量值都是对的（task的值为0xc40这里不太懂为什么）。</p>
<pre><code class="language-bash">─── Variables ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
arg task = 0xc40: {fn (*mut core::ffi::c_void)} 0xc40, p_arg = 0xc: (core::ffi::c_void::__variant2 | unknown: 204), _ptos = 0xb: 14994696, prio = 10
</code></pre>
<p>当我们把返回值OS_ERR_STATE改为8字节的时候，就开始出现问题：</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>0x08000eaa  ucosii::os_task::SyncOSTaskCreate+0  push  {r7, lr}
0x08000eac  ucosii::os_task::SyncOSTaskCreate+2  mov   r7, sp
0x08000eae  ucosii::os_task::SyncOSTaskCreate+4  sub   sp, #128        ; 0x80
0x08000eb0  ucosii::os_task::SyncOSTaskCreate+6  str   r2, [sp, #24]
0x08000eb2  ucosii::os_task::SyncOSTaskCreate+8  str   r1, [sp, #28]
0x08000eb4  ucosii::os_task::SyncOSTaskCreate+10 str   r0, [sp, #32]
0x08000eb6  ucosii::os_task::SyncOSTaskCreate+12 mov   r0, r3
0x08000eb8  ucosii::os_task::SyncOSTaskCreate+14 str   r0, [sp, #36]   ; 0x24
0x08000eba  ucosii::os_task::SyncOSTaskCreate+16 str   r1, [sp, #72]   ; 0x48
0x08000ebc  ucosii::os_task::SyncOSTaskCreate+18 str   r2, [sp, #76]   ; 0x4c
0x08000ebe  ucosii::os_task::SyncOSTaskCreate+20 strb.w        r3, [r7, #-45]
0x08000ec2  ucosii::os_task::SyncOSTaskCreate+24 movs  r0, #0
0x08000ec4  ucosii::os_task::SyncOSTaskCreate+26 strb.w        r0, [r7, #-58]
0x08000ec8  ucosii::os_task::SyncOSTaskCreate+30 movs  r0, #1
0x08000eca  ucosii::os_task::SyncOSTaskCreate+32 strb.w        r0, [r7, #-58]
0x08000ece  ucosii::os_task::SyncOSTaskCreate+36 cmp   r3, #63 ; 0x3f
<span class="boring">}</span></code></pre>
<p>刚进入函数的时候，寄存器的值如下</p>
<p><img src="docs/graph/record39.png" alt="image.png"></p>
<p>对比两次反汇编，能看到最大的不同有两个：</p>
<ol>
<li>除了task参数，其他参数在4字节返回值的时候是放在r0 r1 r2的，而8字节的时候是放在r1 r2 r3的</li>
<li>sub   sp, #136        ; 0x88这里是返回值为8字节的时候，比4字节在栈的使用上，多用了4字节。</li>
</ol>
<p>同样走到cmp r3,#63的位置，这个时候看变量的值：</p>
<pre><code class="language-bash">─── Variables ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
arg task = 0xc00: {fn (*mut core::ffi::c_void)} 0xc00, p_arg = 0xc: (core::ffi::c_void::__variant2 | unknown: 112), _ptos = 0xb: 14971144, prio = 10s
</code></pre>
<p>同样是正常的。</p>
<p>相同的方式，我们将优化等级开到o1，保持8字节的OS_ERR_STATE返回值</p>
<p>同样进入函数时可以看到寄存器的值（同时变量的值也是正确的）：</p>
<p><img src="docs/graph/record40.png" alt="image.png"></p>
<p><img src="docs/graph/record41.png" alt="image.png"></p>
<p>由于优化，直接把最开始的判断prio部分去掉了，因为测试里面没有大于64的情况（并且测试发现，即使有这种情况，也会优化掉）。</p>
<p><img src="docs/graph/record42.png" alt="image.png"></p>
<p><img src="docs/graph/record43.png" alt="image.png"></p>
<p>到这一步都是完全符合预期的，8字节的内容并没有影响到gdb-multiarch对于变量值的解析，只是参数的处理上有些变化，于是，我进一步有一个猜想，如果我按照aapcs的abi标准调用SyncOSTaskCreate, 是否可能出现在c语言那边调用rust库那样的问题：</p>
<p>这里是开优化（完全符合aapcs的规范，除了R0没有使用，R1-R3放了前三个参数，第四个参数就放进了栈里面）</p>
<p><img src="docs/graph/record44.png" alt="image.png"></p>
<p>一切正常，上图是开优化的结果</p>
<p>不开优化（同样参数完全正确，并且完全符合aapcs的规范，除了R0没有使用，R1-R3放了前三个参数，第四个参数就放进了栈里面）：</p>
<p>ps: 这里你能注意到r0的值是进入函数之前，保存的栈的值，对应汇编add sp, #8(不明白为什么这里需要这条指令)</p>
<p><img src="docs/graph/record45.png" alt="image.png"></p>
<p>而我们只调整返回值为4字节看看：</p>
<p>开优化下，你可以看到这里的值完完全全符号正宗的aapcs规范：</p>
<p><img src="docs/graph/record46.png" alt="image.png"></p>
<p>那说明在rust的这边（ap文件也是rust写的），是的确都正确的，那我们返回去看看c代码调用rust的静态库出的问题：</p>
<h3 id="回到c-ffi的问题"><a class="header" href="#回到c-ffi的问题">回到c ffi的问题</a></h3>
<p><img src="docs/graph/record47.png" alt="image.png"></p>
<p>如果返回值OS_ERR_STATE是4字节，那么这个是正常合理的结果，传参放在r0-r3四个参数正好都能放在寄存器里面</p>
<p>但是如果我将返回值OS_ERR_STATE改为8字节：</p>
<p><img src="docs/graph/record48.png" alt="image.png"></p>
<p>终于能解释这里问题的原因了：</p>
<p>因为rustc编译器对于64字节（在aapcs的abi情况下）的处理就是：</p>
<p>将r0保留(目前不知道为什么不使用r0,并且进入函数之前，设置r0的值为add  r0, sp, #8), 然后同样参数依次传递到r1(第一个参数) r2(第二个参数) r3(第三参数) 以及栈上(第四个以及之后的参数)。这种abi模式的情况和gcc的不兼容，我后续尝试声明c的extern函数的返回值为64位，但是它并没有在传参上做特殊处理，但是我仍然疑惑的是，为什么在网上没有查到rustc编译器对于这部分的特殊处理，或者说aapcs有规定这部分的处理吗？</p>
<h2 id="关于抢占的细节问题"><a class="header" href="#关于抢占的细节问题">关于抢占的细节问题</a></h2>
<p>当一个任务被抢占，现场保留到栈上，当它在恢复的时候，如果又被抢占了，同样上下文保存在栈里面，然后在再一次恢复的时候，只恢复到第二次被抢占的位置，并且第一次被抢占时保留的上下文都清除了，这就导致了bug。</p>
<p>更简明的说法是，原本任务的interrupt poll是抢占了一个无栈的协程，但是现在出现有可能抢占的是一个有栈的线程的情况</p>
<p>一个解决方法是，避免这种抢占的发生，改进pendsv和poll的实现</p>
<p>poll在resume线程（有栈）任务的时候，不再设置cur与highrdy一致，这样当进入pendsv的时候，cur与highrdy必然不等，在TCB里面新加入一个成员变量：is_in_thread_poll用于标记任务是在协程状态还是线程状态，这个值用于在pendsv里面判断是否需要保存当前任务上下文。</p>
<p>这种情况下，不可能会抢占一个有栈的线程，因为当cur任务被设置为有栈的线程这种情况是在pendsv里面进行的，而在外部正常程序运行的时候，所有任务都被看成是无栈的协程在运行，不会存在在thread模式下，cur task是有栈的。</p>
<h3 id="bug补充"><a class="header" href="#bug补充">bug补充</a></h3>
<p>还会存在一种丢失唤醒的情况，这是因为在当前任务（假设优先级为35）delay时，设置加入1ns延迟，然后切换到idle任务去执行（目前所有任务都在delay），然而正在切换的过程中，就发生了TIM的时钟中断，将当前任务唤醒，并且dequeue了所有任务（也就是此时所有任务都就绪了），然后设置超时时间就顺其自然的设置为u64 max，因为所有任务都就绪了，</p>
<p>下图的task18的优先级就是35</p>
<pre><code class="language-toml">└─ ucosii::executor::{impl#10}::set_highrdy @ src/executor/mod.rs:694 
INFO  ---task18 end---
└─ comprehensive_test::task18 @ src/bin/comprehensive_test.rs:352 
TRACE OSTimeDly
└─ ucosii::os_time::OSTimeDly @ src/os_time/mod.rs:25  
TRACE set_task_unready
└─ ucosii::executor::{impl#10}::set_task_unready @ src/executor/mod.rs:729 
INFO  in delay_tick the next expire is 489460
└─ ucosii::os_time::delay_tick @ src/os_time/mod.rs:42  
TRACE set_alarm
└─ ucosii::port::time_driver::{impl#4}::set_alarm @ src/port/time_driver/mod.rs:329 
INFO  set the alarm at 489460
└─ ucosii::port::time_driver::{impl#4}::set_alarm @ src/port/time_driver/mod.rs:330 
TRACE set_highrdy
└─ ucosii::executor::{impl#10}::set_highrdy @ src/executor/mod.rs:694 
TRACE interrupt_poll
└─ ucosii::executor::{impl#10}::interrupt_poll @ src/executor/mod.rs:573 
INFO  interrupt poll :the highrdy task's prio is 63
└─ ucosii::executor::{impl#10}::interrupt_poll @ src/executor/mod.rs:579 
TRACE TIM3
└─ ucosii::port::time_driver::TIM3 @ src/port/time_driver/mod.rs:46  
INFO  the alarm is triggered!!!
└─ ucosii::port::time_driver::{impl#3}::on_interrupt::{closure#0} @ src/port/time_driver/mod.rs:244 
TRACE trigger_alarm
└─ ucosii::port::time_driver::{impl#3}::trigger_alarm @ src/port/time_driver/mod.rs:281 
TRACE alarm_callback
└─ ucosii::executor::{impl#10}::alarm_callback @ src/executor/mod.rs:472 
INFO  dequeue expired
└─ ucosii::executor::timer_queue::{impl#0}::dequeue_expired @ src/executor/timer_queue.rs:67  
TRACE wake_task_no_pend
└─ ucosii::executor::wake_task_no_pend @ src/executor/mod.rs:766 
TRACE set_alarm
└─ ucosii::port::time_driver::{impl#4}::set_alarm @ src/port/time_driver/mod.rs:329 
INFO  set the alarm at 18446744073709551615
└─ ucosii::port::time_driver::{impl#4}::set_alarm @ src/port/t
TRACE IntCtxSW
└─ ucosii::executor::{impl#10}::IntCtxSW @ src/executor/mod.rs:539 
TRACE find_highrdy_prio
└─ ucosii::executor::{impl#10}::find_highrdy_prio @ src/executor/mod.rs:717 
INFO   the new_prio is 35, the highrdy task's prio is 63, the cur task's prio is 35
└─ ucosii::executor::{impl#10}::IntCtxSW::{closure#0} @ src/executor/mod.rs:543 
INFO  no need to switch task
└─ ucosii::executor::{impl#10}::IntCtxSW::{closure#0} @ src/executor/mod.rs:551 
TRACE exit TIM3
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="技术报告-1"><a class="header" href="#技术报告-1">技术报告</a></h1>
<h1 id="摘要"><a class="header" href="#摘要">摘要</a></h1>
<p>embassy_preempt是一个嵌入式异步实时操作系统的调度模块。它通过Rust提供的协程机制，结合embassy的异步执行器的实现方式，并借鉴传统嵌入式实时操作系统uCOSII的任务切换机制，在任务调度时，若当前任务主动让权，则会进行栈复用；若当前任务被抢占，则会进行栈分配，并进行现场的保存，使得embassy_preempt同时具有了embassy低内存开销的优势以及uCOSII高实时性的特点。</p>
<h1 id="项目背景-1"><a class="header" href="#项目背景-1">项目背景</a></h1>
<p>在通常情况下，如uCOSII的嵌入式操作系统基本都以线程（或任务）为基本单位进行调度，这就使得每一个任务都将占有一个私有的栈空间。而在实际的应用中，在任务调度的过程中，大部分任务释放CPU都是由于主动让权，而非被高优先级的任务抢占，这使得栈空间存在一定的浪费。</p>
<p>而在embassy中，通过引入Rust的协程机制，使得栈空间的利用率得到了极大的提升。但是由于embassy的线程执行器中的协程之间无法进行抢占，并且进行协程调度时并没有优先级裁决机制，在多任务的情景下将导致若干个任务出现未被及时唤醒的情况，导致实时性较差，这是一个嵌入式实时操作系统无法接受的。</p>
<p>我们希望在已有的嵌入式实时操作系统的高实时性以及embassy的协程机制之间进行“折衷”，编写一个既可以满足实时应用环境下的实时性要求，又可以尽可能缩小内存使用的嵌入式异步实时操作系统调度模块——embassy_preempt。</p>
<h1 id="实现方案"><a class="header" href="#实现方案">实现方案</a></h1>
<h3 id="执行器部分"><a class="header" href="#执行器部分">执行器部分</a></h3>
<p>执行器分成两个环节：thread模式下没有任务抢占的循环POLL环节和interrupt模式下发生任务抢占的interrupt POLL环节</p>
<ul>
<li>
<p>thread的循环poll思路：</p>
<p>函数会直接从执行器里面取出highrdy任务调度执行，所以需要保证调用thread poll的时候是已经确定好了最高优先级的任务的，然后循环里面先poll任务执行，任务poll完后，一定是遇到pending或者任务完成退出，由于我们内置了时钟，这里就需要进行时钟的更新设置，然后就设置任务为非就绪等待后续的waker环节。最后找到新的最高优先级，继续循环</p>
</li>
<li>
<p>interrupt poll的思路：</p>
<p>中断POLL函数会进行抢占式的任务调度，在这里个函数里面主体会进行最高优先级是否有栈的检验，对于没有栈的最高优先级任务，它的调度执行我们会进行模拟压栈，让其变成一个有栈的任务，从而做到栈的分配（因为原有的栈在抢占调度的情况下会分配给当前执行任务用于上下文保存，那么新的任务执行一定需要额外的栈，要么是新任务本身就自带了，不然就需要额外分配一个）。然后我们会开始同一个的任务切换操作，这个操作被放置在pendsv可悬挂软中断里面，这是因为需要及时满足其它中断的需求，最后结束其它中断处理后才进行统一的任务切换处理。</p>
<blockquote>
<p>这里说明一下，interrupt poll实际上只被我们暴露给用户的外部接口IntCtxSW调用，这个接口只是在调用interrupt poll之前进行了优先级判断，检查是否需要进行任务切换，如果需要就会调用interrupt poll</p>
</blockquote>
</li>
</ul>
<h3 id="核心环节是栈的分配和回收"><a class="header" href="#核心环节是栈的分配和回收">核心环节是栈的分配和回收</a></h3>
<ul>
<li>
<p>栈的分配过程是在中断过程中发生的（也就是抢占式调度），在发生中断并且需要抢占的时候，先设置当前任务状态是interrupt状态，表明当前任务被抢占，然后判断最高优先级任务（即将切换到的任务）是否有栈：</p>
<ul>
<li>对于没有栈的待切换任务，就需要先进行栈分配并“模拟压栈”：即将此分配的栈模拟为一个被中断抢占的有栈任务的栈，那么里面就会保存有中断的pc指针以及其它寄存器信息，这里我们主要是设置pc指针为执行器POLL函数指针从而让没有栈的任务能够通过poll执行。</li>
<li>而对于有栈的待切换任务，这里不需要做处理，后续的操作都会认为任务是有栈的</li>
</ul>
<p>然后在实际任务切换环节，采用悬挂的pendsv软中断形式进行，避免重复无效任务切换，保证处理完紧急中断之后才进行任务切换。</p>
</li>
<li>
<p>栈的回收是在pendsv中断里面完成的，正好是顺着往下描述，</p>
<p>进入pendsv的时候就需要把现场进行保护，保存任务的上下文到psp栈</p>
<ul>
<li>对于当前任务是thread模式的情况，如果进入pendsv中断，那么就说明是在恢复一个有栈的任务，并且当前任务是正常await让权出来的，那么就需要drop掉当前协程任务共用的程序栈，转而使用恢复了栈的任务的栈，也就是说在恢复有栈任务执行的时候，将其变成无栈协程执行，并且回收掉之前（当前任务）使用的程序栈（这个时候就不存在任务上下文的保存）。</li>
<li>而对于当前任务是interrupt模式的情况，说明进入pendsv中断是由于任务抢占导致的，那么需要将当前的程序栈从协程任务共享的栈变成当前interrupt私有的栈，然后将程序栈换成待调度的最高优先级的任务的栈（最高优先级任务一定有栈，触发pendsv之前保证了这一点（模拟压栈）），这样就存在现场的保存需求，需要将任务的psp栈保存到任务tcb的栈指针上。然后同样的也是恢复最高优先级任务执行。</li>
</ul>
</li>
</ul>
<h3 id="思维流程图"><a class="header" href="#思维流程图">思维流程图：</a></h3>
<p><img src="docs/graph/tech_image1.png" alt="image.png"></p>
<h1 id="创新点"><a class="header" href="#创新点">创新点</a></h1>
<h3 id="可抢占的内核"><a class="header" href="#可抢占的内核">可抢占的内核</a></h3>
<p>可以中断正在运行的任务，切换到另一个任务执行。嵌入式系统里通常是由于中断触发任务的调度，用户可以在实现中断驱动后，使用IntCtxSW调用操作系统的抢占调度操作</p>
<h3 id="栈复用"><a class="header" href="#栈复用">栈复用</a></h3>
<p>充分利用rust的协程机制，在非抢占的情况下，所有任务共同使用一个栈区，没有任务私有栈。当发生抢占调度时，分配给被抢占任务栈用于现场保护，并且能在恢复任务继续执行时合理回收不使用的栈，使得空间的利用率得到了一定程度上的提升。此外，栈的分配为了实时性和通用性采用了block allocation和linked-list allocation 算法结合的方式</p>
<h3 id="兼容性taskcreateostimedly"><a class="header" href="#兼容性taskcreateostimedly">兼容性（Taskcreate、OSTimeDly）</a></h3>
<p>主要是在和原来ucosii的c接口上进行兼容，通过FFI实现任务创建函数和delay函数与原来一致的接口</p>
<h3 id="time_queue与时钟的优化"><a class="header" href="#time_queue与时钟的优化">time_queue与时钟的优化</a></h3>
<p>为了保证调度的高效实时，timer_queue做成了超时时间的排序链表，并且时钟设置采用单TIM单Channel上升沿触发超时完成所有任务的超时设置，能更准确高效的保证实时性。此外，我们还考虑到了等待时间极短的情况。我们通过循环设置alarm的方式保证在等待时间极短的情况下alarm一定会被设置为下一个超时时间。</p>
<h1 id="难点"><a class="header" href="#难点">难点</a></h1>
<h2 id="模拟压栈与内存对齐"><a class="header" href="#模拟压栈与内存对齐">模拟压栈与内存对齐</a></h2>
<p>模拟压栈的问题在于传入的栈指针很可能不是我们想要的8字节对齐的（肯定是4字节对齐），所以我们会把栈指针给先向上加4字节再截取8字节对齐，从而向上8字节对齐，但是由于传入的栈指针是满堆栈的初始指针，默认是当前元素是已有内容的，压栈的时候需要先栈指针下移，然后再压入栈，所以最后的栈指针的指向一定是偏移17个4字节（因为保存了17个寄存器的内容）。</p>
<h2 id="临界区与任务边界"><a class="header" href="#临界区与任务边界"><strong>临界区与任务边界</strong></a></h2>
<p>只在对于竞争资源（主要是全局变量）的访问修改处进行了临界区设置，保证了可抢占性，并且操作系统启动之后，执行到任何时刻的代码都会对应着一个任务的执行，在执行器的poll和interrup poll中，也都会属于到当前任务的代码，不存在没有任务对应的代码，保证了抢占时的上下文有明确的任务tcb保存</p>
<h2 id="如何统一异步任务与同步任务"><a class="header" href="#如何统一异步任务与同步任务">如何统一异步任务与同步任务？</a></h2>
<p>统一异步任务与同步任务，从本质上来看是统一二者的TCB；而在TCB中，一个同步任务与一个异步任务的之间有两个区别：</p>
<ul>
<li>任务函数的保存方式：同步任务通常是直接保存函数指针，而一个异步任务则是保存任务异步函数对应的future。</li>
<li>栈的分配：同步任务通常在初始化的时候就占有了一个栈，而一个异步任务<strong>只有</strong>在被抢占时才会得到一个栈。</li>
</ul>
<p>为了充分发挥Rust异步的<strong>空间</strong>优势，我们只能尝试将一个同步任务函数转换为一个异步的future，并且尝试将同步任务的栈分配模式与异步任务的栈分配模式统一。因此对异步任务而言，我们可以直接借鉴embassy的做法，不需要做任何改变；而对同步任务而言，如果要把同步任务也转换为一个future，我们就需要解决以下问题：</p>
<ul>
<li>我们应该如何根据一个同步任务函数指针（或闭包）创建出一个对应的future？</li>
<li>栈分配模式如何统一？</li>
</ul>
<p>首先，对第一个问题，从逻辑上来看，对一个同步任务而言，他并没有一个主动让权的await点，那么同步任务实际上与一个<strong>没有await点</strong>的异步任务无异。因此如果将这个逻辑应用在我们的系统中，那么我们就只需要为同步任务函数套上一层async函数闭包，那么我们就将得到一个没有await点、代表着同步函数的future，而这样的闭包由于rust的特性，是直接创建在代码区的，而不会去占用内存空间。</p>
<p>对于第二个问题，我们首先要知道“任务栈”在一个操作系统中的作用是什么。在一个OS中，一个任务栈主要有两个：</p>
<ul>
<li>保存一个任务执行过程中的函数调用</li>
<li>当一个任务<strong>被抢占</strong>时进行任务现场保存，以便后续进行现场恢复</li>
</ul>
<p>此外，一个线程与一个协程最大的区别就是，一个协程是<strong>无栈的</strong>，而线程是<strong>有栈的</strong>。因此我们可以简单地通过一个任务是否有一个私有栈来判断一个任务是线程状态还是协程状态。</p>
<p>我们还需要在这里明确“抢占”与“让权”的意义是什么。在我们的系统中，除了异步任务通过await点主动<strong>让权</strong>将CPU交给内核进行调度外，其余的的任务切换方式都认为是<strong>抢占</strong>的。</p>
<p>因此，一个任务其实仅仅需要在他被<strong>抢占</strong>的时候，将当前使用的栈变为他的私有栈，并用于上下文保存即可。所以如果我们成功将一个同步函数转换为一个future，并且在同步任务创建时将其自带的栈回收并且统一由堆分配器进行任务栈分配，那么同步任务与异步任务的栈分配模式就可以统一了：</p>
<ul>
<li>抢占模式：需要将当前的栈（需要将当前栈作为私有栈是由于当前栈上保存了任务中的函数调用）作为当前任务的私有栈并且进行上下文保存。</li>
<li>让权模式：一个任务通过await点进行任务切换时，将不会进行栈切换，而是所有处于协程状态的任务共用一个栈，而每一个线程状态的任务都拥有自己的私有栈。</li>
</ul>
<p>除此以外，我们将对原来idle的处理也改为了协程模式，idle任务是不会拥有栈执行的，在遇到idle任务被抢占的时候，会将idle任务使用的协程栈转让给抢占的将执行的无栈协程任务，用于模拟压栈，而idle的上下文是不会被保留的，这一点和普通的任务被抢占是不一样的，从而优化的任务抢占的情况，并且也减少了栈的开销。</p>
<p>因此，经过我们处理的同步任务由于没有await点，就不会存在让权切换的模式。因此同步任务将在创建时通过栈回收从线程模式转换为协程模式，然后在其第一次被抢占时拥有它的私有栈，并且从协程模式转换为线程模式，并且由于同步任务不存在让权，其将一直处于线程模式。而这一套同步任务的任务切换方式与异步任务的切换方式是<strong>兼容的</strong>。在这种模式下，任务在运行的过程中将不一定从始至终都以线程或者协程的方式存在，而是在不断进行状态的转换。至此我们就将同步任务与异步任务统一起来了。</p>
<p>最后我们的测试结果表明（详见后面的测试结果）：</p>
<ul>
<li>
<p>在纯线程模式下，即所有任务都是同步任务时，在执行的前期，会为每个任务依次分配栈，使任务一直处于线程模式。在情况下，切换的响应速度和ucosii这种强实时的多线程RTOS的速度是很接近的（调度时间相差0.5us左右，CPU主频84Mhz，大致相差50条汇编指令），所以我们兼容的情况表现是良好的。</p>
</li>
<li>
<p>在引入协程的测试里面，由于协程的唤醒的poll机制，导致了额外的代码执行开销，所以会多消耗3-4us用于这部分代码执行，我们仔细的查看了时间开销的情况，确定了几个额外的开销原因：</p>
<ul>
<li>栈分配：这里的栈分配指的是我们已经优化了任务抢占idle的情况的。在有协程存在的情况下，当一个处于协程状态的任务抢占了另一个非idle的任务，栈分配是不可避免的。</li>
<li>模拟压栈：由于每次分配栈以及进行栈转移（即协程任务抢占idle之后，将idle栈转移给该任务）之后<strong>都</strong>需要进行模拟压栈以便后续PendSV进行现场恢复。</li>
<li>poll执行：poll函数的执行为协程任务唤醒的必备流程，是<strong>无法优化</strong>的</li>
</ul>
<p>目前来看无法进一步优化这里（即在协程模式下）的额外开销，因为这的确是协程机制所带来的额外且必需的负担。但是得到的内存开销的收益是极好的（相同情况下，至少减少了50%的栈开销）</p>
</li>
</ul>
<p>通过这种方式，我们将同步任务和异步任务统一起来，但是我们几乎没有破坏线程、协程本身的优良特性，即在我们的系统中，线程可以保持原有的高实时性的特点，而协程可以保持原有的低内存开销、高并发的特点。</p>
<h2 id="aapcs与ffi"><a class="header" href="#aapcs与ffi">aapcs与FFI</a></h2>
<p>首先介绍一下aapcs（Procedure Call Standard for the ARM Architecture，ARM过程调用标准）。在ARM架构的CPU（或MCU）中，当一个函数调用一个子函数时，若子函数需要接收四个及以下的参数，那么就将通过R0-R3进行传递；若子函数需要接收四个以上的参数，则多余的参数将通过堆栈进行传递。而在子函数返回时，则对不同的返回值类型有不同的处理，在这里我们仅仅说明我们所遇到的情况：当子函数的返回值为32位以上的非基本数据类型时，返回值本身将被存储在堆栈上，并且在函数返回时将把返回值的地址存储在R0中，R1将存储NCRN的值（Next Core Register Number，NCRN)。当子函数的返回值小于32位时，返回值将直接被存储在R0寄存器中。</p>
<p>需要注意的是，在子函数返回值为32位以上的非基本数据类型时，R0中存储的返回值地址应该由主调函数决定，因此在进行传参时，R0就将被赋为一个主调函数决定的地址，而函数参数将通过R1-R3寄存器以及堆栈进行传递。</p>
<p>在我们最初暴露出的FFI接口OSTaskCreate中，其需要接收四个参数并且返回值为一个八字节对齐的枚举类型OS_ERR_STATE。在运行过程中出现以下情况：</p>
<ul>
<li>rustc编译器将把R0保留用以记录返回值地址，并且将函数参数传递至R1-R3寄存器以及堆栈。即rustc编译器完全符合aapcs规范。</li>
<li>gcc编译器将直接把函数的四个参数保存至R0-R3寄存器，并不会预留R0用于保存返回值的地址。即gcc编译器貌似并没有按照正规的aapcs规范进行处理</li>
</ul>
<p>由于C与Rust二者的编译器对函数传参处理的不同，自然就导致了FFI接口无法正常运行。但是由于这是C与Rust二者的编译器的兼容性出现了问题，所以我们无法直接解决这个问题，只能另辟蹊径。</p>
<p>我们发现在四字节返回值的情况下，C与Rust编译器的表项如下：</p>
<ul>
<li>rustc编译器由于返回值为非基本数据类型，并且位数小于32，就不会预留R0作为返回值地址。因此rustc编译器从R0-R3中获取函数的四个参数。</li>
<li>gcc编译器无论是在返回值为四字节还是八字节的情况，都将把四个函数参数传递进R0-R3寄存器。这也恰好符合了返回值为四字节非基本数据类型的aapcs规范。</li>
</ul>
<p>不难发现，在FFI接口返回值为四字节非基本数据类型时，C与Rust编译器的处理方式是兼容的。因此我们最终的解决方案为，将Rust提供的FFI接口的返回值设定为四字节对齐。</p>
<h1 id="测试结果"><a class="header" href="#测试结果">测试结果</a></h1>
<h2 id="功能测试"><a class="header" href="#功能测试">功能测试</a></h2>
<h3 id="硬件驱动测试"><a class="header" href="#硬件驱动测试">硬件驱动测试</a></h3>
<p>硬件驱动测试包括了<a href="https://github.com/KMSorSMS/embassy_preempt/blob/main/ucosii/src/bin/bottom_test.rs">按键驱动测试</a>以及<a href="https://github.com/KMSorSMS/embassy_preempt/blob/main/ucosii/src/bin/hardware_test.rs">Timer驱动测试</a>。</p>
<p>在硬件驱动测试中，我们仅创建了一个任务，以便排除调度过程中出现的问题对排查硬件驱动问题的影响。</p>
<p>经过测试，按键驱动与Timer中断均可正常工作。</p>
<h3 id="调度正确性测试"><a class="header" href="#调度正确性测试">调度正确性测试</a></h3>
<p>在<a href="https://github.com/KMSorSMS/embassy_preempt/blob/main/ucosii/src/bin/scheduling2_test.rs">调度正确性测试</a>中，我们创建了若干个任务，并在代码的关键位置（如任务中、开始抢占调度时，正常调度时）检查就绪队列，并输出日志信息，并将所有的日志信息输出到文件中。通过对文件中的数据进行分析，我们发现代码的执行流符合我们的预期。</p>
<h3 id="压力测试"><a class="header" href="#压力测试">压力测试</a></h3>
<p>在<a href="https://github.com/KMSorSMS/embassy_preempt/blob/main/ucosii/src/bin/comprehensive_test.rs">压力测试</a>中，我们创建了30个任务，并将delay时长设置为1tick、10tick、100tick、10000tick与100000tick，以模拟各种应用场景下的调度（中断）频率。</p>
<p>对压力测试程序，我们持续运行了1h30min，并未出现异常。</p>
<h2 id="性能测试"><a class="header" href="#性能测试">性能测试</a></h2>
<p><a href="https://github.com/KMSorSMS/embassy_preempt/tree/main/performance_test">性能测试代码</a></p>
<h3 id="时间尺度"><a class="header" href="#时间尺度">时间尺度</a></h3>
<ul>
<li>
<p>实时性</p>
<ul>
<li>
<p>测试原理</p>
<p>在多任务环境下，实时性体现为：当<strong>最高优先级</strong>任务(对embassy而言为某一个特定的任务)需要等待的事件发生时，最高优先级任务可以及时被唤醒并被调度。因此我们将通过最高优先级任务中的实际delay的时长与设定的delay时长的误差来衡量测试对象的实时性。</p>
<p>我们将在delay函数开始前拉高PA0引脚的电平，并在delay函数结束后拉低PA0引脚的电平，则高电平持续时间即为实际delay的时长。</p>
</li>
<li>
<p>测试结果</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>   测试对象<br>测试数据(ms)</th><th>embassy_preempt</th><th>ucosii</th><th>embassy</th></tr>
</thead>
<tbody>
<tr><td>数据1</td><td>50.17</td><td>49.574</td><td>107.212</td></tr>
<tr><td>数据2</td><td>50.12</td><td>49.452</td><td>85.775</td></tr>
<tr><td>数据3</td><td>50.13</td><td>49.287</td><td>107.212</td></tr>
<tr><td>数据4</td><td>50.12</td><td>49.528</td><td>85.774</td></tr>
<tr><td>数据5</td><td>50.07</td><td>49.055</td><td>85.776</td></tr>
<tr><td>数据6</td><td>50.09</td><td>49.566</td><td>85.768</td></tr>
<tr><td>数据7</td><td>50.12</td><td>49.905</td><td>107.214</td></tr>
<tr><td>数据8</td><td>5.013</td><td>49.453</td><td>107.212</td></tr>
<tr><td>数据9</td><td>50.11</td><td>49.383</td><td>107.218</td></tr>
<tr><td>数据10</td><td>50.12</td><td>49.046</td><td>85.774</td></tr>
<tr><td>数据11</td><td>50.12</td><td>49.399</td><td>85.773</td></tr>
<tr><td>数据12</td><td>50.11</td><td>49.833</td><td>107.212</td></tr>
<tr><td>数据13</td><td>50.17</td><td>49.185</td><td>85.774</td></tr>
<tr><td>数据14</td><td>50.13</td><td>49.046</td><td>85.773</td></tr>
<tr><td>平均值</td><td>50.12214</td><td>49.408</td><td>94.96193</td></tr>
<tr><td>误差</td><td>0.244%</td><td>1.184%</td><td>89.924%</td></tr>
</tbody>
</table>
</div>
<p>注：delay时间为50ms，任务数量为6个</p>
</li>
<li>
<p>测试结论</p>
<p>由于embassy_preempt与ucosii具有抢占机制，因此二者的delay时间误差较小，实时性较高，基本符合嵌入式实时操作系统对实时性的要求。</p>
<p>而在embassy中由于没有优先级以及抢占机制，使得任务只能被逐个执行，导致某个特定的任务无法被及时执行，因此embassy的delay时间误差较大，实时性较低，无法符合嵌入式实时操作系统对实时性的要求。</p>
</li>
</ul>
</li>
<li>
<p>调度复杂度</p>
<ul>
<li>
<p>测试原理</p>
<p>调度复杂度体现为<strong>最高优先级</strong>任务等待的事件发生，至该任务开始执行所花费的时间（记为调度时间）。调度时间越长，则代表着调度算法以及调度过程越复杂。</p>
<p>我们将在唤醒任务的ISR开始时拉高PA1的电平，并在任务开始执行时拉低PA1的电平，则高电平时间即为调度时间。</p>
</li>
<li>
<p>测试结果</p>
</li>
</ul>
<div class="table-wrapper">
<table>
<thead>
<tr><th>  测试对象<br> 测试数据</th><th>ucosii</th><th>embassy_preempt线程模式</th><th>embassy_preempt协程模式</th><th>embassy(ms)</th></tr>
</thead>
<tbody>
<tr><td>数据1</td><td>7.00</td><td>7.375</td><td>10.125</td><td>67.361</td></tr>
<tr><td>数据2</td><td>7.042</td><td>7.375</td><td>10.167</td><td>91.294</td></tr>
<tr><td>数据3</td><td>7.00</td><td>7.375</td><td>10.167</td><td>105.108</td></tr>
<tr><td>数据4</td><td>7.042</td><td>8.333</td><td>10.125</td><td>93.332</td></tr>
<tr><td>数据5</td><td>7.00</td><td>8.333</td><td>10.167</td><td>47.646</td></tr>
<tr><td>数据6</td><td>7.00</td><td>7.375</td><td>10.083</td><td>80.193</td></tr>
<tr><td>数据7</td><td>7.042</td><td>7.375</td><td>10.083</td><td>69.887</td></tr>
<tr><td>数据8</td><td>7.00</td><td>8.333</td><td>10.167</td><td>105.108</td></tr>
<tr><td>数据9</td><td>7.00</td><td>7.375</td><td>10.125</td><td>72.472</td></tr>
<tr><td>数据10</td><td>7.00</td><td>8.333</td><td>10.167</td><td>47.897</td></tr>
<tr><td>数据11</td><td>7.042</td><td>7.375</td><td>10.167</td><td>68.355</td></tr>
<tr><td>数据12</td><td>7.00</td><td>7.375</td><td>10.167</td><td>119.003</td></tr>
<tr><td>数据13</td><td>7.00</td><td>8.333</td><td>10.083</td><td>47.897</td></tr>
<tr><td>数据14</td><td>7.00</td><td>7.375</td><td>10.125</td><td>103.280</td></tr>
<tr><td>数据15</td><td>7.042</td><td>7.375</td><td>10.083</td><td>80.472</td></tr>
<tr><td>平均值</td><td>7.014</td><td>7.6943</td><td>10.1334</td><td>79.954</td></tr>
</tbody>
</table>
</div>
<p>注：任务数量为6个</p>
<ul>
<li>
<p>测试结果分析</p>
<p>由于embassy无抢占机制，在测试调度时间时无法确定下一个执行的任务为我们指定的任务，因此通过我们的方式测量出的“调度时间”中将包含其他任务的执行时间以及重调度时间，从数据中也可以发现，每一次对embassy测试出的“调度时间”变化较大，因此对embassy测量的”调度时间”为<strong>无效数据</strong>。</p>
</li>
<li>
<p>解释8.333的问题（也是分析线程模式和ucosii时间差距的关键），是因为当当前是idle任务时，如果发生抢占，我们不希望idle任务保存上下文，所以如果切换到的任务有栈，那么就会将原来的程序栈释放掉，设置新的程序栈为有栈的任务的栈，从而回收栈，所以这就导致了回收栈的额外开销（≈1us—对应84条指令的样子），经过测试，在任务执行频率很高的情况下，或者协程任务比较多的情况下，这种情况就几乎不会发生，所以embassy_preempt协程模式的数据区别不是很大</p>
</li>
<li>
<p>而协程模式之所以会多2.5us的样子，是因为几个地方的开销：</p>
<ul>
<li>栈分配：这里的栈分配指的是我们已经优化了任务抢占idle的情况的。在有协程存在的情况下，当一个处于协程状态的任务抢占了另一个非idle的任务，栈分配是不可避免的。</li>
<li>模拟压栈：由于每次分配栈以及进行栈转移（即协程任务抢占idle之后，将idle栈转移给该任务）之后<strong>都</strong>需要进行模拟压栈以便后续PendSV进行现场恢复。</li>
<li>poll执行：poll函数的执行为协程任务唤醒的必备流程，是<strong>无法优化</strong>的</li>
</ul>
</li>
<li>
<p>测试结论</p>
<p>ucosii的调度时间短于embassy_preempt，说明ucosii的调度过程优于embassy_preempt。但由于二者的调度时间差距为微秒级，这在实际应用场景中几乎可以忽略不计。因此可以认为ucosii与embassy_preempt的调度复杂度相近。</p>
</li>
</ul>
</li>
</ul>
<h3 id="空间尺度"><a class="header" href="#空间尺度">空间尺度</a></h3>
<ul>
<li>静态空间
<ul>
<li>
<p>测试原理</p>
<p>在RAM区的大小为96K的情况下，创建64个任务，并采取统一的优化等级（Rust优化设置为1，C优化设置为3），查看编译后生成的elf文件的大小。</p>
<p>栈大小设置：由于堆分配器的限制，将embassy_preempt中的异常栈以及程序栈的大小都设置为2K，以便能够满足任务的<strong>最大</strong>栈需求；对于ucosii，则将每个任务的栈大小设置为512B。</p>
<p>Arena设置：在embassy与embassy_preempt中，Arena用于进行TCB分配。我们将二者的Arena都设置为10K，以满足创建64个任务的需求。</p>
</li>
<li>
<p>测试结果</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>   测试对象<br> 段(B，十进制表示)</th><th>embassy_preempt</th><th>ucosii</th><th>embassy</th></tr>
</thead>
<tbody>
<tr><td>.text</td><td>40284</td><td>6284</td><td>50168</td></tr>
<tr><td>.data</td><td>56</td><td>0</td><td>56</td></tr>
<tr><td>.bss</td><td>10744</td><td>40904</td><td>10900</td></tr>
<tr><td>总大小</td><td>51084</td><td>47188</td><td>61124</td></tr>
</tbody>
</table>
</div>
</li>
<li>
<p>测试结果分析</p>
<p>由于可用的栈空间与.data段与.bss段的大小有关（除去.data段与.bss段，几乎所有剩余的RAM空间都可用作栈空间），因此这里主要分析RAM（.bss+.data）的开销</p>
<ul>
<li>
<p>embassy_preempt与embassy</p>
<p>embassy_preempt与embassy的RAM空间主要用于进行TCB的静态分配（即Arena开销）</p>
</li>
<li>
<p>ucosii</p>
<p>为了实现空间分配的确定性，在ucosii中大部分数据结构都是提前静态分配的，并且任务栈也需要我们使用数组的形式进行手动分配。因此在ucosii中，bss段的主要开销为任务栈以及各种OS需要的数据结构（如TCB等）。</p>
</li>
</ul>
</li>
<li>
<p>测试结论</p>
<ul>
<li>代码段：embassy_preempt占用FLASH空间小于embassy，但二者均远大于ucosii。可见embassy_preempt与embassy的代码复杂度大于ucosii。</li>
<li>RAM区（.bss+.data）：embassy_preempt与embassy占用的RAM空间相近，且二者均远小于ucosii。</li>
</ul>
</li>
</ul>
</li>
<li>动态空间（即栈空间）
<ul>
<li>
<p>测试原理</p>
<ul>
<li>对embassy_preempt与embassy：在静态空间测试的前提下，将RAM区的大小不断缩小，直至程序无法运行（即出现爆栈），最终得到的最小的、可运行程序的RAM空间减去静态空间测试中测量出的RAM区空间即可近似表示二者的动态空间占用。</li>
<li>对ucosii：由于在ucosii中所有的栈都将静态分配，则ucosii的动态空间即为预分配的任务栈数组所占用的RAM空间</li>
</ul>
</li>
<li>
<p>测试结果</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th> 测试对象<br> 测试</th><th>embassy_preempt</th><th>ucosii</th><th>embassy</th></tr>
</thead>
<tbody>
<tr><td>最小RAM空间</td><td>24K</td><td>39K</td><td>12K</td></tr>
<tr><td>静态空间</td><td>≈10K</td><td></td><td>≈10K</td></tr>
<tr><td>动态空间</td><td>≈14K</td><td>32K</td><td>≈2K</td></tr>
</tbody>
</table>
</div>
<p>注：测试时长为30min</p>
</li>
<li>
<p>测试结果分析</p>
<p>在embassy_preempt中，当栈空间为14K时，除去2K的异常栈，可以发现在峰值情况下，最多有6/64个任务拥有自己的栈。</p>
<p>而在ucosii中，由于其无法事先准确预测任务所需要的栈大小，使得其栈空间存在大量的内零头，使得其运行时所需的动态空间最大。</p>
<p>而embassy所有任务共用同一个栈，因此所需的栈空间最小</p>
</li>
<li>
<p>测试结论</p>
<p>embassy运行所需的栈空间最小，其次为embassy_preempt，而ucosii运行时所需的栈空间最大。</p>
</li>
</ul>
</li>
</ul>
<h1 id="总结"><a class="header" href="#总结">总结</a></h1>
<p>我们设计实现embassy_preempt的初衷为：在不影响ucosii的实时性的基础上，借助Rust的异步机制以及embassy的实现方式，在一定程度上提高了空间的利用率。从目前的测试结果来看，embassy_preempt的表现符合我们的预期。</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="embassy_preempt设计文档"><a class="header" href="#embassy_preempt设计文档">embassy_preempt设计文档</a></h1>
<h2 id="整体设计"><a class="header" href="#整体设计">整体设计</a></h2>
<p>分成两个接口，一个接口是对于c/rust的普通函数的，另一个接口是对于rust的异步函数的。</p>
<p>然而对于c/rust普通函数，我们对它进行包装，在接口内转为一个future 对象，从而将调度都统一到执行器进行。</p>
<p>后续可以通过宏或者接口中直接区别rust的普通函数和异步函数从而对于rust普通函数和异步函数进行合并</p>
<p>下面以表格形式给出各种情况的上下文切换情况：</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>当前执行现场</th><th>新执行现场</th><th>切换条件</th><th>是否需要保存上下文</th><th>是否需要恢复上下文</th></tr>
</thead>
<tbody>
<tr><td>协程</td><td>线程</td><td>await</td><td>否</td><td>是</td></tr>
<tr><td>协程</td><td>协程（未被打断）</td><td>await</td><td>否</td><td>否</td></tr>
<tr><td>协程</td><td>协程（被打断）</td><td>await</td><td>否</td><td>是</td></tr>
<tr><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td>协程/线程</td><td>线程</td><td>非await</td><td>是</td><td>是</td></tr>
<tr><td>协程/线程</td><td>协程（未被打断）</td><td>非await</td><td>是</td><td>否</td></tr>
<tr><td>协程/线程</td><td>协程（被打断）</td><td>非await</td><td>是</td><td>是</td></tr>
</tbody>
</table>
</div>
<h3 id="栈部分的分析"><a class="header" href="#栈部分的分析">栈部分的分析</a></h3>
<p>首先将上下文切换的分类分成抢占和让权两种；
在对于抢占的时候需要分为保存和恢复两步：</p>
<ul>
<li>对于保存：不管什么情况，都是先给当前任务分配一个堆栈，然后将当前任务的上下文保存到堆栈中</li>
<li>对于恢复： 需要先判定需要转移的任务是否有堆栈，如果没有，说明是协程，那么直接poll就能恢复调度执行，而对于有堆栈的情况，需要将堆栈中的上下文恢复到寄存器中（这里面就包括了pc的恢复从而跳转到任务执行）</li>
</ul>
<p>仔细考虑一下栈的动态分配问题：</p>
<blockquote>
<p>对于普通的线程，通常由用户指定一个栈的区域，从而我们将栈分配给任务，但是这样的话，我们无法做到栈的动态分配，我想做到在可能的情况下，如果不存在抢占，那么所有的线程以及协程都是共用一套栈，等到遇到抢占的时候再分配</p>
</blockquote>
<p>动态分配时，首先所有的协程以及线程（实际上我们也把线程处理为了一个没有await点的协程从而做到统一的调度），都是共用一套栈,我们这里统一术语称为程序栈。当遇到抢占的时候，我们需要将当前任务的栈保存起来，也就是说之前协程共用的这一套栈（程序栈）被分给了当前任务用于它的上下文保存，然而程序的运行是需要栈的，所以这个时候需要立刻分配一个新的栈给所有的协程（也就是程序栈），然后恢复的时候，需要根据恢复的任务是协程还是线程（其实是根据任务是有栈还是无栈）来分情况处理。
换句话说就是，程序运行肯定会有一个栈（分配出来的），这个栈也是所有协程开始执行的时候所在的公共堆栈，如果没有发生抢占那么这个栈就会复用。而发生抢占的时候当前的这个堆栈就认为是当前这个协程所占有的堆栈，然后重新分配一个新的栈给执行器用来继续执行整个程序（也就是协程）</p>
<blockquote>
<p>这里强调一下恢复运行后的任务的栈不一定就是所有协程所在的栈（也就是说恢复后的任务不一定就变成协程，也可能是线程）：因为恢复的任务可能之前是被抢占的，那么恢复的时候就需要从堆栈中恢复上下文（包括pc与sp等）从而继续执行。而这里注意，是不可以在恢复现场的时候释放掉栈的，因为还有一些现场本身是放在栈里面的，这个栈需要继续使用，但是继续执行之后，如果遇到await（也就主动让权的情况）或者整个任务完成退出，那么就可以释放掉自己使用的栈到栈池了。</p>
</blockquote>
<p>这里实际上最关键的就是这个栈分配器的实现，我感觉这里就和堆分配器一样（实际上就是堆分配了已经），考虑就直接用堆分配器的算法进行动态的栈分配（采取fixed-sized的算法进行分配）
我们这里复用的堆分配器的实现，新建了一个栈分配器的实例，将0x20000000开始的40KB分配给栈使用，heap可以用后续的空间（不过目前还没有涉及）
<br>而fixed-sized支持的固定大小数组是：[128, 256, 512, 1024, 2048, 4096, 8192, 16384] 单位Byte
<br>不在这个枚举里面的值，是可以支持分配的（因为底层我们使用了linked-list的分配算法进行优化，从而支持非固定大小的支持，但是在栈分配里面我们不会利用这个，这个特性我们只是给堆空间的分配使用提供）</p>
<blockquote>
<p>最后总结一下抢占下切换的时候关于栈的处理：在保存现场的时候，我们将当前的堆栈给到当前任务，它就拥有了这个堆栈，并且需要给程序执行重新分配一个堆栈（也同样是协程的公共堆栈），然后进入恢复阶段，如果恢复的任务是一个线程，直接就把sp恢复，因为线程有sp，如果任务没有堆栈指针（也就是说是个协程），那么就使用程序的堆栈（刚刚分配了的），这个堆栈是给所有协程任务使用的。</p>
</blockquote>
<h1 id="第一阶段第二阶段"><a class="header" href="#第一阶段第二阶段">第一阶段+第二阶段</a></h1>
<p>第一阶段：在uCOS中<strong>没有中断的场景</strong>下，引入embassy，以支持协程；（线程被视为不会暂停的协程）</p>
<ul>
<li>统一线程和协程的控制块结构TCB（Task Control Block）；</li>
<li>只有让权情况出现，让权时栈空，可以复用栈；（解决堆栈的分配和回收问题）
第二阶段：在uCOS中没有中断的场景下，引入embassy和<strong>优先级</strong>，以支持线程和协程的优先级调度；</li>
<li>按优先级选就绪任务（可能是线程，也可能是协程）；</li>
</ul>
<h2 id="第一阶段第二阶段设计"><a class="header" href="#第一阶段第二阶段设计">第一阶段&amp;第二阶段设计</a></h2>
<p>为了将协程与线程统一，我们采取lazy的策略为线程分配栈空间。只有当线程开始运行时，该线程才会占有当前执行器所使用的栈。而在线程结束之后，其所拥有的线程栈将被回收。因此在第一阶段&amp;第二阶段这种没有抢占的情况下，在进行调度时，线程(同步任务)与协程(异步任务)的表现将<strong>完全一致</strong>。可以查看我们的测试程序，</p>
<ul>
<li>tests/integration.rs</li>
<li>src/bin/ucosii_main.rs</li>
<li>src/bin/prio_test.rs</li>
<li>src/heap/stack_allocator.rs(里面有个独立的测试模块)</li>
</ul>
<h2 id="第一阶段第二阶段调试记录"><a class="header" href="#第一阶段第二阶段调试记录">第一阶段&amp;第二阶段调试记录</a></h2>
<h3 id="栈初始化"><a class="header" href="#栈初始化">栈初始化</a></h3>
<p>在操作系统启动之前，需要进行若干初始化的操作，而此时的栈指针sp将被设定为链接脚本中指定的值(下面简称为初始化栈)。因此在操作系统启动之前(还未使用我们的栈分配器之前)，所有的系统初始化相关的部分都将保存在初始化栈中。因此在系统启动、准备换栈之前，需要提前将初始化栈上的变量等drop，如果将drop操作延后至换栈之后，就将找不到需要drop的变量进而导致错误。</p>
<h3 id="爆栈问题"><a class="header" href="#爆栈问题">爆栈问题</a></h3>
<p>在调试的过程中我们多次遇到了爆栈的问题。经过调试，我们发现主要有以下两个原因会导致爆栈：</p>
<ul>
<li>copy or clone
在内存空间紧张的嵌入式设备中，如果在一个函数中需要使用某一个变量时，使用的是copy或clone，而非引用的话，就极有可能会导致当前函数所占用的栈空间过大(这是由于局部变量也保存在函数栈中)，进而导致爆栈。
实际上在Embassy Book中也有相关的提示：</li>
</ul>
<blockquote>
<p>However, in most embedded applications you don’t want to spend resources on an allocator and end up placing buffers on the stack. This, however, can easily blow up your stack if you are not careful.<br>–from: https://embassy.dev/book/#_passing_buffers_by_reference</p>
</blockquote>
<ul>
<li>优化
在我们解决copy&amp;clone导致的爆栈之后，我们发现我们的栈空间的利用率还是很低(通过查看反汇编代码发现似乎局部变量与函数传参的存储并不紧凑)，因此我们怀疑是由于我们没有开启优化导致部分函数携带了许多额外的信息。在我们调高了优化等级之后，栈空间的利用率得到了提高，爆栈问题得到了解决。</li>
</ul>
<p>更细致的设计、调试、分析记录在链接文档（notion）：https://liamy.notion.site/7b079c095dbe40018de93c3092664ca1?pvs=4</p>
<h1 id="第三阶段-1"><a class="header" href="#第三阶段-1">第三阶段</a></h1>
<p>在uCOS中<strong>有中断的场景</strong>下，引入embassy和优先级，以支持线程和协程的优先级调度；</p>
<p>- 中断就是抢占情况，需要保存堆栈，并（有可能）分配新堆栈，用于恢复下一个任务；</p>
<h2 id="第三阶段设计-1"><a class="header" href="#第三阶段设计-1">第三阶段设计</a></h2>
<p>第三阶段有几个关键点：</p>
<ul>
<li>
<p>哪一部分代码属于任务执行的代码？</p>
<ul>
<li>设计思路：我们认为只有当从任务中返回到执行器代码时，才代表着该任务结束，即将状态转移等编译器生成的代码的执行也认为是任务的执行。</li>
</ul>
</li>
<li>
<p>如何让中断程序知道当前在执行哪部分代码？</p>
<ul>
<li>设计思路：将执行器代码放入临界区中，让其不可被打断，那么这样就会使得所有的中断都将在执行任务代码时产生，这样所有将导致抢占的中断都可以无脑分配一个栈给当前任务，使得处理得以简化。</li>
<li>长远计划：尝试在执行器代码(即poll函数)中任何对正确性没有影响的代码处都允许中断的发生，这样可以进一步提高系统的实时性，并且可能对空间开销没有影响。
<ul>
<li>初步设计思路：为全局执行器增加一个成员变量以标记当前正在执行的代码。</li>
</ul>
</li>
</ul>
</li>
<li>
<p>中断服务程序如何设计？</p>
<ul>
<li>
<p>设计思路：在中断服务程序中，我们还应该在中断返回时增加几个功能：</p>
<ul>
<li>栈分配模块(仅在发生抢占时执行，即新任务的优先级更高)：用于分配一个新栈以供系统继续运行。而旧栈将用于保存原有任务的执行现场</li>
<li>唤醒模块：将新任务设置为就绪状态</li>
<li>抢占调度模块：用于在中断返回时进行重调度</li>
</ul>
<p>我们将把前两个模块作为唤醒器Waker的功能。而对于抢占重调度，我们将尝试<strong>复用</strong>原有的普通调度函数。</p>
</li>
</ul>
</li>
<li>
<p>抢占调度如何设计？</p>
<ul>
<li>poll函数的重构：由于我们在一二阶段实现poll函数时考虑的情况过于混杂，导致poll函数的质量并不是很高。在第三阶段中，我们将对poll函数进行重构，以更好地支持抢占调度的情况。重写后的poll函数应该保证以下几点：
<ul>
<li>任何任务在执行时都是无栈状态：为了满足这种条件，在poll函数执行时，如果新任务无栈，则正常执行；若新任务有栈，则将从该栈中恢复现场并将原栈回收。</li>
<li>只有主动让权的任务才会有对应的中断来唤醒该任务：如果满足了这种条件，则在发生抢占时，新任务一定是无栈的情况（因为一个任务有栈，就代表他曾经被抢占过）</li>
</ul>
</li>
<li>设计思路：假设目前有一个优先级更高的任务需要抢占当前任务，那么在中断服务程序的抢占调度中，我们应该在抢占调度之前将旧任务的执行现场保存在原有的栈上，然后额外分配一个新栈以供剩余的所有任务共用。</li>
</ul>
</li>
</ul>
<h2 id="第三阶段实现"><a class="header" href="#第三阶段实现">第三阶段实现</a></h2>
<h3 id="中断抢占流程"><a class="header" href="#中断抢占流程">中断/抢占流程</a></h3>
<ol>
<li>中断抢占发生, 一部分现场立刻被保存到当前程序栈(psp)上（xPSR, PC, LR, R12, R0-R3，由硬件实现），同时栈会切换到msp异常堆栈</li>
<li>中断处理程序需要响应的事务结束之后，需要将对应的任务唤醒，即设置对应的任务为就绪</li>
<li>接下来我们将调用执行器的中断poll函数。在执行器的中断poll函数中，会找到最高优先级任务，然后将程序栈分配给被打断的程序（需要判断是否当前任务就是最高优先级的，是的话就不分配栈，直接异常/中断返回原任务继续执行即可）。此外还需要继续保存硬件未保存的、旧任务的执行现场到旧栈上。这样当前任务的上下文就保存了。然后将转向最高优先级任务的处理。</li>
</ol>
<h3 id="详细说明最后一步的处理方式"><a class="header" href="#详细说明最后一步的处理方式">详细说明最后一步的处理方式：</a></h3>
<ul>
<li>这里我们把任务切换的实际过程放在pendsv中断中进行处理
<blockquote>
<p>因为如果不在中断中处理，有个关键的过程很难完成：在抢占时，需要压入所有的寄存器（上下文）到程序栈，并且将这个程序栈分配给任务，如果不是在中断里面而是tread模式下，那么本身就在使用这个程序栈，在这种情况下操作，可能需要大量的汇编代码的设计（来控制栈的使用），这样实现可读性也不好。</p>
</blockquote>
</li>
<li>pendsv会马上保存中断前的上下文到psp栈上（后续这个psp栈可能会分配给旧任务，也有可能直接被回收，因为抢占的情况进入的pendsv是需要保存现场给当前优先级任务，然而正常thread下poll的时候恢复到有栈的任务是不需要保存现场给当前任务，这两者的区别在于当前优先级任务和最高优先级任务是否是同一个），如果是由于中断抢占后，调用的pendsv，那么对应的当前任务prio和最高优先级任务prio是不同的（最高优先级任务prio在中断抢占里面被设置为了新的最高优先级任务的值），而正常thread下poll的时候恢复到有栈的任务，进入pendsv时，当前优先级任务和最高优先级任务是同一个。</li>
<li>pendsv保存了上下文到psp栈后，就会将程序栈设置为最高优先级任务的栈，并且将原来保存的栈的所有权弹出到一个临时变量，如果需要上下文保存，那么最终这个所有权会被转移给旧任务的TCB里面，如果不需要保存，那么这个栈就会被回收。</li>
<li>最后就是恢复最高优先级任务的现场，这里就是将psp栈的上下文恢复到寄存器中，从而异常返回到最高优先级任务的执行。</li>
</ul>
<h3 id="模拟压栈"><a class="header" href="#模拟压栈">模拟压栈</a></h3>
<p>由于在中断返回时，硬件将自动执行一部分恢复现场的工作(即恢复硬件自动保存的部分：xPSR, PC, LR, R12, R0-R3)，因此在中断服务程序中进行栈分配时，我们需要对分配的新栈进行模拟压栈。其中xpsr赋值为0x01000000，PC赋值为执行器poll的地址，LR为一个TASK_RETURN函数地址，R12，R0-R3的值任意，然后是R4-R11赋值为任意, LR赋值为0xFFFFFFFD。经过模拟压栈之后，在中断服务程序返回时，就将自动复用普通的poll函数，并且将使用新分配的栈空间继续进行任务调度了。</p>
<h3 id="poll函数的改造"><a class="header" href="#poll函数的改造">poll函数的改造</a></h3>
<p>对于执行到有栈的新任务的时候，就需要进行栈回收，因为切换到新任务执行后就是把整个psp函数栈都切换走了，那么实际上当前的这个psp栈就不需要了，所以需要将当前的程序栈设置为新任务的私有栈(即将私有栈作为公共栈)，并将新任务的栈指针设置为None，以表示该任务已经没有私有栈了，最后将原来的栈dealloc掉。</p>
<div style="break-before: page; page-break-before: always;"></div>
<p>对 <code>embassy_preempt</code> 整个项目进行代码的解析，以便后续同学能更快上手此项目。</p>
<p>说明：分析的代码版本为 <code>2708047c63abed651966bada817a2aeee4bbf672</code>(2025-6-3)，此时已完成大部分的代码以及组件化的工作，但为了更好地分析，仍然以未进行组件化的代码文件进行分析，即项目里的 ‘/embassy_preempt’ 文件夹（组件化的工作主要集中在modules文件夹）。</p>
<p>​</p>
<pre><code>./embassy_preempt
└── src
    ├── app
    ├── bin
    ├── cfg
    ├── event
    ├── os_time
    ├── port
    ├── executor
    └── lib.rs
</code></pre>
<p>​</p>
<h1 id="app"><a class="header" href="#app">app</a></h1>
<pre><code>app
├── led.rs
└── mod.rs
</code></pre>
<p>LED以及所用GPIO的初始化代码，主要用在性能测试，通过拉高拉低电平来测试两者间的时间差值。调用的是 <code>stm32_metapac</code> 提供的接口。</p>
<p>注：<code>stm32_metapac</code> 是一个为 <strong>STM32 微控制器</strong> 提供 <strong>硬件抽象层（HAL）和寄存器访问接口</strong> 的库。</p>
<p>​</p>
<h1 id="cfg"><a class="header" href="#cfg">cfg</a></h1>
<pre><code>cfg
├── mod.rs
├── tick.rs
└── ucosii.rs
</code></pre>
<p><code>tick.rs</code> ：是用来配置实现异步的定时器的 tick 值，也就是设定多少时间定时器的计数器加一，默认 <code>TICK_HZ</code> 设置为 100_000</p>
<p><code>ucosii.rs</code> ：<strong>提供系统全局配置、数据类型定义、函数声明、全局变量</strong>，是整个系统的基础接口文件。</p>
<p>​</p>
<h1 id="event"><a class="header" href="#event">event</a></h1>
<pre><code>event
├── mod.rs
├── os_flag.rs
├── os_mbox.rs
├── os_mutex.rs
├── os_q.rs
└── os_sem.rs
</code></pre>
<h2 id="modrs"><a class="header" href="#modrs">mod.rs</a></h2>
<blockquote>
<p>事件机制的底层实现代码</p>
</blockquote>
<h3 id="os_event"><a class="header" href="#os_event">OS_EVENT</a></h3>
<blockquote>
<p>描述一个Event</p>
</blockquote>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct OS_EVENT {
    pub OSEventType: OS_EVENT_TYPE,
    pub OSEventPtr: SyncUnsafeCell&lt;Option&lt;OS_EVENT_REF&gt;&gt;,
    pub OSEventCnt: INT16U,
    pub OSEventGrp: OS_PRIO,
    pub OSEventTbl: [OS_PRIO; OS_EVENT_TBL_SIZE as usize],
    #[cfg(feature = "OS_EVENT_NAME_EN")]
    pub OSEventName: String,
}
<span class="boring">}</span></code></pre>
<p>OS_EVENT 结构体存储着 <code>OSEventType</code>、<code>OSEventPtr</code>、<code>OSEventCnt</code>、<code>OSEventGrp</code>、<code>OSEventTbl</code> 以及需特性激活 <code>OSEventName</code>。</p>
<ul>
<li><code>OSEventType</code>：标识事件类型</li>
<li><code>OSEventPtr</code>：下一事件指针，用于在Event池中快速取到空闲Event控制块的指针</li>
<li><code>OSEventCnt</code>：事件计数</li>
<li><code>OSEventGrp</code>、<code>OSEventTbl</code>：事件等待队列，管理阻塞在该事件上的任务，原理与优先级位图法一致</li>
<li><code>OSEventName</code>：Event 事件名称</li>
</ul>
<p>​</p>
<h3 id="event_type"><a class="header" href="#event_type">EVENT_TYPE</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum OS_EVENT_TYPE {
    /// the unused type
    UNUSED = 0,
    /// the mailbox type
    MBOX = 1,
    /// the queue type
    Q = 2,
    /// the semaphore type
    SEM = 3,
    /// the mutex type
    MUTEX = 4,
    /// the flag type
    FLAG = 5,
}
<span class="boring">}</span></code></pre>
<p>标志Event的类型</p>
<p>​</p>
<h3 id="eventpool"><a class="header" href="#eventpool">EventPool</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct EventPool {
    /// Pointer to free list of event control blocks
    pub OSEventFreeList: SyncUnsafeCell&lt;Option&lt;OS_EVENT_REF&gt;&gt;, 
    OSEventTbl:  SyncUnsafeCell&lt;[OS_EVENT_REF; OS_MAX_EVENTS as usize]&gt;,
}
<span class="boring">}</span></code></pre>
<p>通过 <code>EventPool</code> 集中管理系统中的所有 <code>Event</code>，目前设计容量为20，也就是最多支持20个event。</p>
<p><code>EventPool</code>封装了 <code>OSEventFreeList</code>以及 <code>OSEventTbl</code> ，进而实现完成对全局 <code>Event</code> 的管理。</p>
<ul>
<li>
<p><code>OSEventTbl</code> 为 Event 表，管理着整个系统运行时使用过以及未使用过的 event</p>
</li>
<li>
<p><code>OSEventFreeList</code> 为空闲节点的指针，指向 全局<code>EventPool</code> 的 <code>OSEventTbl</code> 中未分配的 event</p>
<ul>
<li>这里提一下 Event 结构体成员的 <code>EventPtr</code> 将始终指向空闲节点或者空，这样就不需要通过算法查找空闲节点，只需要在分配Event时修改一下指针以及 <code>OSEventFreeList</code></li>
</ul>
</li>
</ul>
<p>​</p>
<p>另外采用 <code>lazy_static</code> 实现静态初始化（类似于 <code>GlobalSyncExecutor</code> 全局调度器的设计：</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>lazy_static! {
    /// the global event pool
    pub static ref GlobalEventPool: Option&lt;EventPool&gt; = 	Some(EventPool::new());
}
<span class="boring">}</span></code></pre>
<p>​</p>
<p>实现思路：</p>
<p><code>EventPool</code> 管理的每个 event 都是通过 <code>ARENA</code> 分配，这点参考的是在executor中关于 <code>OS_TCB</code> 的分配方式。alloc 方法会直接从 <code>OSEventFreeList</code> 拿到其指向的 <code>event</code>，并判断是否为空（通过给指针套上一层 Option 来完成，另外全局的 <code>OSEventTbl</code> 和 <code>event</code> 的 <code>OSEventTbl</code> 也均采用这种方式 ），为空则表示该元素并未被分配空间，转而通过 <code>ARENA</code> 去分配。</p>
<p>需要提一下的是，设计的 <code>free</code> 方法来释放 <code>event</code> 时，其实并不会去回收 <code>ARENA</code> 分配给 Event 的地址空间，而是仅将 <code>OSEventType</code> 重新设置为 <code>UNUSED</code>，和重新设置<code>OSEventFreeList</code>，其余 Event 结构体成员的重新初始化将在 alloc 中完成（通过判断 <code>OS_EVENT_REF</code> 的 ptr 指针是否为空，为空(None)则是新的 <code>event</code>，为 some 则之前被使用过并被 free 释放，将在此处清除之前的数据）。</p>
<p>​</p>
<p>问题：</p>
<blockquote>
<p>在对全局 <code>EventPool</code> 进行初始化时，ucosii 会将 <code>OSEventTbl</code> 中的 <code>event</code> 链接成链表，上一个 <code>event</code> 的 <code>OSEventPtr</code> 将指向下一个 <code>event</code>。但是这里的前提是全部的 <code>event</code> 的空间均已经被分配，而 ucosii 通过全局结构体数组的形式，那么就可以直接在初始化的时候就进行链接。</p>
<p>不幸的是我目前设计的方案是延迟初始化 <code>Event</code>，也就是说在os初始化之后， <code>OSEventTbl</code> 中的每个 <code>event</code> 指针指向的地址均为 <code>None</code>，那么如果此时将它们进行链接，会产生未定义行为，没办法将其链接成链表。</p>
</blockquote>
<p>解决方案：没办法链成链表的话，就需要在分配的时候手动搜索未使用的 <code>event</code> ，而链接成链表其实就是为了不产生搜索开销的。所以经考虑，采用空间换时间的形式，在初始化的时候就给 <code>OSEventTbl</code> 中 每个 <code>event</code> 分配空间。</p>
<p>实现如下：</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// EventPool结构体的init方法
pub unsafe fn init(&amp;self) {
       critical_section::with(|cs| {
           for i in 0..OS_MAX_EVENTS {
               if self.OSEventTbl.get_mut()[i].ptr.is_none() {
                   self.OSEventTbl.get_mut()[i] = EventPool::claim(cs);
               }
           }
       });
       
       /
       ...
       /
}
<span class="boring">}</span></code></pre>
<p>​</p>
<h2 id="os_semrsos_qrsos_flagrsos_mboxrsos_qrs"><a class="header" href="#os_semrsos_qrsos_flagrsos_mboxrsos_qrs">os_sem.rs&amp;os_q.rs&amp;os_flag.rs&amp;os_mbox.rs&amp;os_q.rs</a></h2>
<p>基于 <code>EventPool</code> 的上层实现，有点类似于管程统一管理？详细内容见代码</p>
<p>​</p>
<h1 id="os_time"><a class="header" href="#os_time">os_time</a></h1>
<pre><code>os_time
├── blockdelay.rs
├── duration.rs
├── instant.rs
├── mod.rs
└── timer.rs
</code></pre>
<p>​</p>
<h2 id="blockdelayrs"><a class="header" href="#blockdelayrs">blockdelay.rs</a></h2>
<p>ARM汇编编写的 delay 函数</p>
<p>​</p>
<h2 id="durationrs"><a class="header" href="#durationrs">duration.rs</a></h2>
<p>主要实现了一个用于表示时间间隔的 <code>Duration</code> 结构体，以及相关的构造和转换方法。为时间间隔运算提供了基础类型和工具，方便 tick 与常用时间单位之间的转换与运算。</p>
<ul>
<li><code>Duration</code> 结构体内部用 <code>ticks: u64</code> 字段表示时钟节拍数（tick），用于描述两个时间点之间的差值。</li>
<li>提供了多种从 tick、s、ms、us创建 <code>Duration</code> 的静态方法，包括向上/向下取整版本。</li>
</ul>
<p>​</p>
<h2 id="instantrs"><a class="header" href="#instantrs">instant.rs</a></h2>
<p>主要实现了一个用于表示“某一时刻”的 <code>Instant</code> 结构体，以及相关的时间操作方法。为环境下的“时间点”提供了基础类型和工具，方便获取当前时间、进行时间点与时间间隔的运算等操作。</p>
<p>​</p>
<h2 id="timerrs"><a class="header" href="#timerrs">timer.rs</a></h2>
<p>为异步任务提供延时功能，支持多种时间单位</p>
<p>​</p>
<h2 id="modrs-1"><a class="header" href="#modrs-1">mod.rs</a></h2>
<p>异步任务的延时函数实现</p>
<h3 id="delay_tick"><a class="header" href="#delay_tick">delay_tick</a></h3>
<blockquote>
<p>延时函数的底层实现，这是调度器运行的核心代码之一，主动让权</p>
</blockquote>
<p>实现思路：</p>
<ol>
<li>设置当前任务的过期时间为 当前时间的时间戳 + 延迟的<code>tick</code>值</li>
</ol>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>task.expires_at.set(RTC_DRIVER.now() + _ticks);
<span class="boring">}</span></code></pre>
<ol start="2">
<li>讲当前任务移出就绪队列，并加入时钟队列等待唤醒</li>
</ol>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut next_expire = critical_section::with(|_| {
	executor.set_task_unready(*task);
    critical_section::with(|_| executor.timer_queue.update(*task))
});
<span class="boring">}</span></code></pre>
<ol start="3">
<li>
<p>判断是否需要为当前需要延迟的任务设置闹钟</p>
</li>
<li>
<p>根据位图更新最高优先级及最高优先级TCB指针，如果当前任务不是最高优先级则调用<code>interrupt_poll</code>进入调度器代码</p>
</li>
</ol>
<p>​</p>
<p><code>OSTimeDly</code>，<code>OSTimeDlyHMSM</code>均是 <code>ucosii</code> 的函数接口，<code>OSTimeDlyHMSM</code>可以指定延时具体时分秒</p>
<p><code>OSTimeDlyResume</code>用于唤醒处于延时的异步任务</p>
<p>​</p>
<h1 id="port"><a class="header" href="#port">port</a></h1>
<pre><code>port
├── lang_items.rs
├── os_cpu.rs
├── time_driver
│    └── mod.rs
└── mod.rs
</code></pre>
<p>体系架构相关，以及时钟驱动的实现代码。（bottom_driver文件夹，是袁子为同学实现的底层驱动，但没有使用故不做说明）</p>
<p>​</p>
<h2 id="lang_itemsrs"><a class="header" href="#lang_itemsrs">lang_items.rs</a></h2>
<p>为嵌入式环境提供 panic、退出和硬件异常的自定义处理，便于调试和与主机工具交互</p>
<p>​</p>
<h2 id="os_cpurs"><a class="header" href="#os_cpurs">os_cpu.rs</a></h2>
<p>核心代码，PenSV软中断以及TCB栈初始化</p>
<h3 id="pensv异常软中断"><a class="header" href="#pensv异常软中断">PenSV异常软中断</a></h3>
<blockquote>
<p>核心中断处理程序，负责在任务切换时保存和恢复上下文。即当PenSV异常中断产生时，会进行上下文的切换</p>
</blockquote>
<ol>
<li><code>PenSV</code> 触发时，会<strong>立即将当前任务的上下文保存到 PSP</strong></li>
</ol>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>unsafe {
    asm!(
        "CPSID I",
        "MRS     R0, PSP",
        // save the context
        "STMFD   R0!, {{R4-R11, R14}}",
        // fix: we need to write back to the PSP
        "MSR     PSP, R0",
        // "CPSIE   I",
        options(nostack, preserves_flags)
    );
}
<span class="boring">}</span></code></pre>
<ol start="2">
<li>如果最高优先级跟当前优先级一致，则不需要切换上下文，立马恢复上面保存的上下文</li>
</ol>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if prio_highrdy == prio_cur {
    // we will reset the msp to the original
    let msp_stk = INTERRUPT_STACK.get().STK_REF.as_ptr();
    unsafe {
        asm!(
            // "CPSID I",
            "MRS    R0, PSP",
            "LDMFD   R0!, {{R4-R11, R14}}",
            "MSR     PSP, R0",
            // reset the msp
            "MSR     MSP, R1",
            "CPSIE   I",
            "BX      LR",
            in("r1") msp_stk,
            options(nostack, preserves_flags),
        )
    }
}
<span class="boring">}</span></code></pre>
<ol start="3">
<li>获取最高优先级任务的栈指针，然后将其放入<code>PROGRAM_STACK</code>程序栈，并弹出原本的旧栈指针到<code>old_stk</code>（这里<code>PROGRAM_STACK</code>是一个全局变量，在OS初始化时被设置。始终确保<code>PROGRAM_STACK</code>表示当前任务的栈，弹出<code>old_stk</code>表示原先任务的栈）。</li>
</ol>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut old_stk = PROGRAM_STACK.swap(stk_ptr);
<span class="boring">}</span></code></pre>
<ol start="4">
<li>随后判断当前任务是否是协程
<ul>
<li>如果不是则需要保存上下文，即将<code>PSP</code>值放入<code>old_stk</code>的栈引用里，并设置当前任务的TCB的栈指针指向弹出来的<code>old_stk</code></li>
<li>是协程，而且堆指针与新栈的堆指针不一致，则销毁旧栈，即回收协程的栈</li>
</ul>
</li>
</ol>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if !*tcb_cur.is_in_thread_poll.get_unmut() {
	let old_stk_ptr: *mut usize;
	unsafe {
		asm!(
			"MRS     R0, PSP",
			out("r0") old_stk_ptr,
			options(nostack, preserves_flags),
		)
	}
	old_stk.STK_REF = NonNull::new(old_stk_ptr as *mut OS_STK).unwrap();
	tcb_cur.set_stk(old_stk);
} else if old_stk.HEAP_REF != stk_heap_ref {
	drop(old_stk);
} else {
	mem::forget(old_stk);
}
<span class="boring">}</span></code></pre>
<ol start="5">
<li>恢复高优先级任务的上下文</li>
</ol>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let msp_stk = INTERRUPT_STACK.get().STK_REF.as_ptr();
unsafe {
	asm!(
        // "CPSID I",
        "LDMFD   R0!, {{R4-R11, R14}}",
        "MSR     PSP, R0",
        // reset the msp
        "MSR     MSP, R1",
        "CPSIE   I",
        "BX      LR",
        in("r0") program_stk_ptr,
        in("r1") msp_stk,
        options(nostack, preserves_flags),
	)
}
<span class="boring">}</span></code></pre>
<p>​</p>
<h3 id="ostaskstkinit"><a class="header" href="#ostaskstkinit">OSTaskStkInit</a></h3>
<blockquote>
<p>也是比较重要的底层函数，实现对任务的栈初始化工作</p>
</blockquote>
<p>主要是对任务栈实现模拟压栈（模拟压栈的作用是确保在进行上下文切换时，能正常弹出上下文尽管上下文是没有意义的。如果没有压栈的话，会产生未定义行为，因为会去访问没有初始化的地址空间）。但是这里的模拟压栈很特殊也比较重要的一点是，模拟压栈时压入的PC值。</p>
<ul>
<li>在 <code>ucosii</code> 里进行模拟压栈时，压入的PC值是任务的入口地址，也就是说，当切换到该任务，上下文切换后，PC的值会指向该任务代码的入口地址，直接执行任务代码。</li>
<li>而在 <code>embassy_preempt</code> 中，压入的PC值是一个函数闭包，闭包如下：</li>
</ul>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let executor_function_ptr: fn() = || unsafe {
    let global_executor = GlobalSyncExecutor.as_ref().unwrap();
    let task = global_executor.OSTCBHighRdy.get_mut().clone();
    global_executor.single_poll(task);
    global_executor.poll();
};
<span class="boring">}</span></code></pre>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// initialize the stack
unsafe {
    (*psp).r0 = 0;
    (*psp).r1 = 0x01010101;
    (*psp).r2 = 0x02020202;
    (*psp).r3 = 0x03030303;
    (*psp).r4 = 0x04040404;
    (*psp).r5 = 0x05050505;
    (*psp).r6 = 0x06060606;
    (*psp).r7 = 0x07070707;
    (*psp).r8 = 0x08080808;
    (*psp).r9 = 0x09090909;
    (*psp).r10 = 0x10101010;
    (*psp).r11 = 0x11111111;
    (*psp).r12 = 0x12121212;
    (*psp).r14 = 0xFFFFFFFD;
    (*psp).lr = 0;
    (*psp).pc = executor_function_ptr as u32;	// 压入的PC值
    (*psp).xpsr = 0x01000000;
}
<span class="boring">}</span></code></pre>
<p>可以看到核心代码就是调度器的函数 <code>single_poll(task)</code> ，这里简单说一下，该函数会去调用异步任务存放在.bss段的poll方法，执行任务代码。这也是异步带来的不同之处。<code>single_poll</code> 后面还有 <code>poll</code> ，但是不会执行。</p>
<p>​</p>
<h2 id="time_driverrs"><a class="header" href="#time_driverrs">time_driver.rs</a></h2>
<blockquote>
<p>时钟驱动，涉及时间戳，任务唤醒</p>
</blockquote>
<p>在原本的 <code>ucosii</code> 中，任务的时间管理依赖于  STM32的<code>SysTick</code>内核外设，每次 <code>SysTick</code> 触发中断时，将会遍历 TCB链表，逐步递减TCB的 <code>OSTCBDly</code> 计数，若计数归零，则说明任务延迟结束，将该任务加入就绪队列。</p>
<p>已知异步是事件驱动的，不需要轮询，性能较好，这也是引入异步带来的好处之一。但是异步的时钟驱动会比轮询实现起来复杂，不再像轮询那样只是编写一个中断函数简单。以下内容将介绍本项目是如何实现的。</p>
<p>​</p>
<h3 id="实现思路"><a class="header" href="#实现思路">实现思路</a></h3>
<p>因为不再轮询，所以需要知道异步任务延迟的时间以及被唤醒的准确时间，并在该时间准时唤醒该异步任务。所以时钟驱动的核心是 <code>Alarm</code> ，当异步任务通过 <code>OSTimeDly</code> 主动释放控制权，会在该任务的 <code>OS_TCB</code>设置过期时间，并设定一个闹钟，当 <code>Alarm</code> 到达，执行注册的回调函数 ，实现将该任务唤醒</p>
<p>要想实现事件触发机制，像 <code>ucosii</code> 那样使用<code>SysTick</code> 没办法满足要求，因为它不具备多通道中断触发，是没办法实现 <code>Alarm</code> 功能的。所以采用 Embassy 的方案，单独采用通用定时器（这里使用的是TIM3）完成 <code>Alarm</code> 的功能，鉴于 <code>TIM3</code> 有完整的4个通道，其中一个用来中点是能配置3个 <code>Alarm</code> 来对异步任务进行定时唤醒的。</p>
<p>关于<code>Alarm</code> 是如何实现的。通过配置通用定时器 <code>TIM3</code> 的四个通道的比较捕获中断实现的，当创建一个 <code>Alarm</code> 时，会根据设置的到期时间去配置TIM3与 <code>Alarm</code> 对应通道的CCR，当定时器计数值CNT到达时设定值，触发中断，判断哪个通道触发， 并 调用<code>Alarm</code> 绑定的回调函数实现唤醒</p>
<p>​</p>
<h3 id="alarm实现"><a class="header" href="#alarm实现">Alarm实现</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct AlarmState {
    timestamp: Cell&lt;INT64U&gt;,
    // This is really a Option&lt;(fn(*mut ()), *mut ())&gt;
    // but fn pointers aren't allowed in const yet
    callback: Cell&lt;*const ()&gt;,
    ctx: Cell&lt;*mut ()&gt;,
}
<span class="boring">}</span></code></pre>
<ul>
<li>
<p><code>timestamp</code>：该alarm所代表的异步任务的抵达时间</p>
</li>
<li>
<p><code>callback</code>：唤醒时所调用的回调函数，<code>set_alarm_callback</code>会将其固定指向调度器代码的 <code>alarm_callback</code></p>
</li>
<li>
<p><code>ctx</code>：<code>alarm</code> 的上下文内容？调用<code>set_alarm_callback</code>时会将其固定指向全局调度器<code>GlobalSyncExecutor</code>，好像没有什么作用</p>
</li>
</ul>
<p>​</p>
<h3 id="驱动"><a class="header" href="#驱动">驱动</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub(crate) struct RtcDriver {
    /// Number of 2^15 periods elapsed since boot.
    period: AtomicU32,
    alarm_count: AtomicU8,
    /// Timestamp at which to fire alarm. u64::MAX if no alarm is scheduled.
    alarms: Mutex&lt;[AlarmState; ALARM_COUNT]&gt;,
    #[cfg(feature = "low-power")]
    rtc: Mutex&lt;CriticalSectionRawMutex, Cell&lt;Option&lt;&amp;'static Rtc&gt;&gt;&gt;,
}
<span class="boring">}</span></code></pre>
<ul>
<li>period：整个系统的时间戳，从上电后完成硬件初始化后开始计时</li>
<li>alarm_count：可用 <code>alarm</code> 的数量</li>
<li>alarms：alarm句柄</li>
</ul>
<p><code>RtcDriver.init()</code>配置 <code>TIM3</code> ，启用捕获中断和溢出中断，<code>TIM3</code> 为 100_000 Hz，<code>ARR</code> 设置为65535，<code>CRR</code> 设置为32768当启动定时器后，每隔 （1/100_000）s TIM3的CNT寄存器会加一，当CNT到达32,768时，触发中断执行中断服务程序 <code>RtcDriver.on_interrupt（）</code>，会调用 <code>RtcDriver.next_period()</code> ，这里会<code>period</code> 会加一，当CNT溢出时也会触发，也就是说0.32768s <code>period</code> 会进行自增。 <code>period&lt;&lt;15+count</code> 为当前时间的事件戳。</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn next_period(&amp;self) {
    // We only modify the period from the timer interrupt, so we know this can't race.
    let period = self.period.load(Ordering::Relaxed) + 1;
    self.period.store(period, Ordering::Relaxed);
    let t = (period as u64) &lt;&lt; 15;

    critical_section::with(move |cs| {
        TIMER.dier().modify(move |w| {
            for n in 0..ALARM_COUNT {
                let alarm = &amp;self.alarms.borrow(cs)[n];
                let at = alarm.timestamp.get();

                if at &lt; t + 0xc000 {
                    // just enable it. `set_alarm` has already set the correct CCR val.
                    w.set_ccie(n + 1, true);
                }
            }
        })
    })
}
<span class="boring">}</span></code></pre>
<ul>
<li>7-19行，则是检查延迟到达时间与当前时间戳的差值是否小于0xc000（四分之三的ARR值），小于则说明该任务即将达到，向定时器注册捕获中断，中断到达则说明有任务到达，转去执行设定好的闹钟回调函数。</li>
</ul>
<p>三个 <code>Alarm</code> 对应着TIM3的2、3、4通道，通过开关通道的中断来实现对闹钟的开关。</p>
<p>​</p>
<h2 id="modrs-2"><a class="header" href="#modrs-2">mod.rs</a></h2>
<ul>
<li>
<p>平台架构相关的类型定义</p>
</li>
<li>
<p>配置异步调度器所需要的定时器，默认选择的是TIM3</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// set the time driver to be Timer3
pub const TIMER: TimGp16 = stm32_metapac::TIM3;
<span class="boring">}</span></code></pre>
</li>
<li>
<p>初始化内核外设，涉及STM32的SCB（配置中断优先级分组），中断配置等。将在系统初始化时调用</p>
</li>
</ul>
<p>​</p>
<h1 id="executor"><a class="header" href="#executor">executor</a></h1>
<p>嵌入式实时异步调度器</p>
<h2 id="cell"><a class="header" href="#cell">cell</a></h2>
<p>Rust内部可变性的上层封装</p>
<h3 id="uprs"><a class="header" href="#uprs">up.rs</a></h3>
<p>实现无需 <code>unsafe</code> 的安全内部可变性封装，便于全局静态数据的安全访问和修改</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct UPSafeCell&lt;T&gt; {
    /// inner data
    inner: RefCell&lt;T&gt;,
}
<span class="boring">}</span></code></pre>
<p>可以看到底层是RefCell，只不过进行了封装。在 <code>executor/mem/heap</code> 中对程序栈 <code>PROGRAM_STACK</code> 以及 <code>INTERRUPT_STACK</code> 的声明时会使用到。</p>
<p>​</p>
<h3 id="utilrs"><a class="header" href="#utilrs">util.rs</a></h3>
<h4 id="uninitcellt-结构体"><a class="header" href="#uninitcellt-结构体"><code>UninitCell&lt;T&gt; 结构体</code></a></h4>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct UninitCell&lt;T&gt;(MaybeUninit&lt;UnsafeCell&lt;T&gt;&gt;);
<span class="boring">}</span></code></pre>
<p>用于安全地延迟初始化和析构一个类型为 T 的内存单元，内部用 <code>MaybeUninit</code> 实现。<strong>每个异步任务的 <code>future</code> 将会用此类型进行声明</strong></p>
<p>​</p>
<h4 id="syncunsafecellt-结构体"><a class="header" href="#syncunsafecellt-结构体"><code>SyncUnsafeCell&lt;T&gt; 结构体</code></a></h4>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct SyncUnsafeCell&lt;T&gt; {
    value: UnsafeCell&lt;T&gt;,
}
<span class="boring">}</span></code></pre>
<p>是对 <code>UnsafeCell</code> 的简单封装，带有 <code>Sync</code> 实现（当 T: Sync 时），用于多线程环境下的内部可变性。</p>
<p>​</p>
<h2 id="memrs"><a class="header" href="#memrs">mem.rs</a></h2>
<p>系统的内存管理</p>
<h3 id="heap"><a class="header" href="#heap">heap</a></h3>
<blockquote>
<p>堆栈内存管理，为异步任务分配栈</p>
</blockquote>
<h4 id="liked_list"><a class="header" href="#liked_list">liked_list</a></h4>
<p>底层代码，整个堆栈内存管理都基于在此实现的 <code>Linked List Allocator</code> 链表分配器</p>
<h4 id="fixed_size_blockrs"><a class="header" href="#fixed_size_blockrs">fixed_size_block.rs</a></h4>
<p><code>liked_list</code> 的上层实现，能够灵活分配 [128, 256, 512, 1024, 2048, 4096, 8192, 16384] 大小的内存空间</p>
<p>​</p>
<h5 id="fixedsizeblockallocator-结构体"><a class="header" href="#fixedsizeblockallocator-结构体"><code>FixedSizeBlockAllocator 结构体</code></a></h5>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct FixedSizeBlockAllocator {
    list_heads: [Option&lt;&amp;'static mut ListNode&gt;; BLOCK_SIZES.len()],
    fallback_allocator: Heap,
}
<span class="boring">}</span></code></pre>
<ul>
<li><code>list_heads</code>：空闲链表池，维护不同大小的内存块。当任务请求栈空间时，首先尝试从这里分配。</li>
<li><code>fallback_allocator</code>：底层的 <code>Heap</code> 结构，作为备用分配器。当空闲链表无法满足分配需求时，从 <code>Heap</code> 申请新内存</li>
</ul>
<p><strong>FixedSizeBlockAllocator</strong> 的方法：</p>
<p>为 <code>FixedSizeBlockAllocator</code> 实现 <code>GlobalAlloc</code> Trait，这点亲身完成训练营任务会比较熟悉。</p>
<p><code>GlobalAlloc</code>Trait 定义了堆分配器必须提供的功能。 该Trait很特殊，因为程序员几乎从不直接使用它。 相反，当使用<code>alloc</code>分配内存和使用集合类型时，编译器将自动向trait中的方法插入适当的调用。</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>unsafe impl GlobalAlloc for Locked&lt;FixedSizeBlockAllocator&gt;
<span class="boring">}</span></code></pre>
<p>​</p>
<ol>
<li>alloc</li>
</ol>
<p>核心代码，完成基于链表分配器的内存分配</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>
unsafe fn alloc(&amp;self, layout: Layout) -&gt; *mut u8 {
	let mut allocator = self.lock();
	match list_index(&amp;layout) {
		Some(index) =&gt; {
			match allocator.list_heads[index].take() {
				Some(node) =&gt; {
                    allocator.list_heads[index] = node.next.take();
                    node as *mut ListNode as *mut u8
                }
				None =&gt; {
                    // no block exists in list =&gt; allocate new block
                    let block_size = BLOCK_SIZES[index];
                    // only works if all block sizes are a power of 2
                    let block_align = block_size;
                    let layout = Layout::from_size_align(block_size, block_align).unwrap();
                    // TODO: added to debug, remove later when release
                    let ptr = allocator.fallback_alloc(layout);
                    ptr
				}
			}
		}
		None =&gt; allocator.fallback_alloc(layout),
	}
}
<span class="boring">}</span></code></pre>
<ul>
<li>通过 <code>Layout</code> 计算任务栈所需的大小，并在 <code>BLOCK_SIZES</code> 中找到最匹配内存大小的索引
<ul>
<li>如果对应索引的空闲链表中有可用内存块，则直接取出链表头，并将 <code>next</code> 指向的块作为新的链表头。</li>
<li>如果该索引的链表为空，说明此前没有相应大小的块可用，需要调用 <code>fallback_alloc</code>，从 <code>Heap</code> 中申请新栈空间。</li>
</ul>
</li>
</ul>
<ol start="2">
<li>dealloc</li>
</ol>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>unsafe fn dealloc(&amp;self, ptr: *mut u8, layout: Layout) {
    let mut allocator = self.lock();
    match list_index(&amp;layout) {
        Some(index) =&gt; {
            let new_node = ListNode {
                next: allocator.list_heads[index].take(),
            };
            // verify that block has size and alignment required for storing node
            // check liam: maybe below assert code should palce at the beginning Some(index) branch
            assert!(mem::size_of::&lt;ListNode&gt;() &lt;= BLOCK_SIZES[index]);
            assert!(mem::align_of::&lt;ListNode&gt;() &lt;= BLOCK_SIZES[index]);
            let new_node_ptr = ptr as *mut ListNode;
            new_node_ptr.write(new_node);
            allocator.list_heads[index] = Some(&amp;mut *new_node_ptr);
        }
        None =&gt; {
            let ptr = NonNull::new(ptr).unwrap();
            allocator.fallback_allocator.deallocate(ptr, layout);
        }
    }
}
<span class="boring">}</span></code></pre>
<ul>
<li>
<p>3行，依据 <code>Layout</code> 计算待释放内存块的大小，找到最匹配的链表索引，确定回收的空闲链表</p>
</li>
<li>
<p>4-19行，在释放的内存块上创建一个 <code>ListNode</code>，让它的 <code>next</code> 指向当前的空闲链表头。这样，新回收的块会被插入到链表的最前端，方便下次分配时快速取用</p>
<p>通过 <code>ptr</code> 将当前指针转换为 <code>ListNode</code>，并写入新创建的 <code>ListNode</code> 结构，最终完成回收操作</p>
</li>
</ul>
<p>​</p>
<h4 id="stack_allocatorrs"><a class="header" href="#stack_allocatorrs">stack_allocator.rs</a></h4>
<p>定义STK的引用（实际就是 ucosii 的栈指针，只不过多了栈底、栈大小的两项信息）：</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// the ref of the stk
pub struct OS_STK_REF {
    /// the ref of the stk(top or bottom),because the read of this
    /// field is in the asm code, so we use NonNull to ensure the safety
    /// and use #[allow(dead_code)]
    #[allow(dead_code)]
    pub STK_REF: NonNull&lt;OS_STK&gt;,
    /// the ref of this dynamic stk's src heap
    pub HEAP_REF: NonNull&lt;u8&gt;,
    /// the layout(size) of the stk
    pub layout: Layout,
}
<span class="boring">}</span></code></pre>
<ul>
<li><code>STK_REF</code>: 栈的引用（指向栈的顶部）。</li>
<li><code>HEAP_REF</code>: 栈内存的起始地址（换句话说就是指向栈底）。</li>
<li><code>layout</code>: 栈的内存布局（大小和对齐方式）。</li>
</ul>
<p>​</p>
<p>对于任务栈的分配都基于 <code>STACK_ALLOCATOR</code> 这个全局变量，类型就是上面提到的 <code>FixedSizeBlockAllocator</code>。</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>static STACK_ALLOCATOR: Locked&lt;FixedSizeBlockAllocator&gt; = Locked::new(FixedSizeBlockAllocator::new());
<span class="boring">}</span></code></pre>
<p>​</p>
<p>通过 <code>lazy_static</code> 声明了程序栈 <code>PROGRAM_STACK</code>，中断栈 <code>INTERRUPT_STACK</code>。程序栈在上面对PenSV说明已经提到了，中断栈顾名思义就是产生中断时保存中断上下文的栈（调用<code>OS_InitStackAllocator</code>完成分配，<code>OSStart</code>完成配置，也就是将主栈寄存器<code>msp</code>指向中断栈，这样MCU就知道发生中断时会去哪保存中断上下文）</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>lazy_static::lazy_static! {
    pub static ref PROGRAM_STACK: UPSafeCell&lt;OS_STK_REF&gt; = unsafe {
        UPSafeCell::new(OS_STK_REF::default())
    };
    pub static ref INTERRUPT_STACK: UPSafeCell&lt;OS_STK_REF&gt; = unsafe {
        UPSafeCell::new(OS_STK_REF::default())
    };
}
<span class="boring">}</span></code></pre>
<p>​</p>
<h3 id="arenars"><a class="header" href="#arenars">arena.rs</a></h3>
<p>实现了一个 <strong>基于固定大小的内存池分配器</strong>（<code>Arena</code>），</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct Arena&lt;const N: usize&gt; {
    buf: UnsafeCell&lt;MaybeUninit&lt;[u8; N]&gt;&gt;,
    ptr: Mutex&lt;Cell&lt;*mut u8&gt;&gt;,
}
<span class="boring">}</span></code></pre>
<ul>
<li><code>buf</code>：内存缓冲区
<ul>
<li><code>MaybeUninit</code> 表示数据未初始化，避免触发未初始化数据的未定义行为</li>
</ul>
</li>
<li><code>ptr</code>：一个指针，用于标记当前内存分配的起始地址</li>
</ul>
<p>​</p>
<p><code>OS_TASK_STORAGE</code> 是通过 <code>Arena</code> 来分配， <code>OS_TASK_STORAGE</code> 存储着 <code>OS_TCB</code> 和 <code>future</code>，这是两个关键成员， <code>OS_TCB</code> 存储着任务的完整信息，<code>future</code> 指向该任务通过 <code>async</code> 修饰之后返回的 <code>Future</code> 。</p>
<p>​</p>
<h2 id="os_corers"><a class="header" href="#os_corers">os_core.rs</a></h2>
<p>内核底层及接口函数的实现</p>
<h4 id="osinit"><a class="header" href="#osinit"><code>OSInit</code></a></h4>
<p>完成系统初始化，涉及内核外设初始化，IDLE任务初始化，栈分配器初始化，堆栈初始化，时钟初始化等</p>
<p>​</p>
<h4 id="osstart"><a class="header" href="#osstart"><code>OSStart</code></a></h4>
<blockquote>
<p>内核启动函数</p>
</blockquote>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>OSRunning.store(true, Ordering::Release);

let int_stk = INTERRUPT_STACK.exclusive_access();
let int_ptr = int_stk.STK_REF.as_ptr() as *mut u8;
drop(int_stk);
unsafe {
    set_int_change_2_psp(int_ptr);
    critical_section::with(|_| GlobalSyncExecutor.as_ref().unwrap().set_highrdy());
    GlobalSyncExecutor.as_ref().unwrap().poll();
}
<span class="boring">}</span></code></pre>
<p>其实可以看到，将全局变量OSRunning置为true，然后把主栈指针设置为之前提到的 <code>INTERRUPT_STACK</code> 中断栈，随后寻找就绪队列最高优先级任务执行 <code>poll</code> 方法</p>
<p>​</p>
<h4 id="os_inittaskidle"><a class="header" href="#os_inittaskidle"><code>OS_InitTaskIdle</code></a></h4>
<blockquote>
<p>初始化IDLE任务</p>
</blockquote>
<p>IDLE任务的任务体实际为ARM汇编 <code>wfe</code> ，MCU会进入低功耗模式，其实还是会跟用户创建的任务一样，调用 <code>SyncOSTaskCreate</code> 套上一层 async 闭包进行创建。</p>
<p>​</p>
<h2 id="os_taskrs"><a class="header" href="#os_taskrs">os_task.rs</a></h2>
<blockquote>
<p>关于任务的函数实现</p>
</blockquote>
<h4 id="syncostaskcreate"><a class="header" href="#syncostaskcreate"><code>SyncOSTaskCreate</code></a></h4>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub extern "aapcs" fn SyncOSTaskCreate&lt;F, R&gt;(
    task: F,
    p_arg: *mut c_void,
    _ptos: *mut OS_STK,
    prio: INT8U,
) -&gt; OS_ERR_STATE
where
    F: FnOnce(*mut c_void) -&gt; R + 'static,
    R: ReturnUnitOrNeverReturn,
{
    // check the priority
    if prio &gt; OS_LOWEST_PRIO as u8 {
        return OS_ERR_STATE::OS_ERR_PRIO_INVALID;
    }
    // warp the normal func to a async func
    let future_func = move || async move { task(p_arg) };
    // if the ptos is not null, we will revoke it as the miniaml stack size(which is 128 B)
    if !_ptos.is_null() {
        let layout = Layout::from_size_align(DEFAULT_REVOKE_STACK_SIZE, 4).unwrap();
        let heap_ptr = unsafe { (_ptos as *mut u8).offset(-(DEFAULT_REVOKE_STACK_SIZE as isize)) };
        // used to test ffi
        let mut stk = stk_from_ptr(heap_ptr as *mut u8, layout);
        dealloc_stack(&amp;mut stk);
    }
    OSTaskCtr.fetch_add(1, Ordering::SeqCst);
    return init_task(prio, future_func);
}
<span class="boring">}</span></code></pre>
<ul>
<li>
<p>16行，将用户编写的任务函数套上一层 <code>async</code> 闭包</p>
</li>
<li>
<p>18-24行的内容，则是调用该函数传入的栈指针是否是否为空，不为空则说明该指针指向的内存空间有数据，需要进行释放，后续调度时再重新分配</p>
</li>
<li>
<p>26行，核心任务创建代码，随后会说明</p>
</li>
</ul>
<p>​</p>
<h4 id="asyncostaskcreate"><a class="header" href="#asyncostaskcreate"><code>ASyncOSTaskCreate</code></a></h4>
<p>与 <code>OS_InitTaskIdle</code> 的差别仅在于不需要再套一层async</p>
<p>​</p>
<h4 id="init_task"><a class="header" href="#init_task"><code>init_task</code></a></h4>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let err = OS_TASK_STORAGE::init(prio, 0, 0 as *mut (), 0, "".to_string(), future_func);
if err == OS_ERR_STATE::OS_ERR_NONE {
    // check whether the task is created after the OS has started
    if OSRunning.load(Ordering::Acquire) {
    	// schedule the task, not using poll, we have to make a preemptive schedule
        unsafe {
        	GlobalSyncExecutor.as_ref().unwrap().IntCtxSW();
        }
    }
} else {
    critical_section::with(|_cs| {
        let executor = GlobalSyncExecutor.as_ref().unwrap();
        // clear the reserve bit
        executor.clear_bit(prio);
    })
}
<span class="boring">}</span></code></pre>
<ul>
<li>
<p>1行，任务创建的底层代码，整个创建过程以来于  <code>OS_TASK_STORAGE</code> 这个结构体， 上面 arean.rs 节也有提到，后面在 task.rs 会进行详细说明。</p>
</li>
<li>
<p>2-16行则判断系统是否启动，启动则调用 <code>IntCtxSW</code> 进入调度逻辑</p>
</li>
</ul>
<p>​</p>
<h2 id="taskrs"><a class="header" href="#taskrs">task.rs</a></h2>
<blockquote>
<p>TCB的实现</p>
</blockquote>
<p>关于TCB结构体及其方法这里就进行说明了，注释写得比较清楚了。这里着重分析<code>OS_TCB</code> 的上层封装  <code>OS_TASK_STORAGE</code> 结构体：</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct OS_TASK_STORAGE&lt;F: Future + 'static&gt; {
    task_tcb: OS_TCB,
    // this part is invisible to other crate
    // by noah: maybe we need to use raw ptr
    future: UninitCell&lt;F&gt;,
}
<span class="boring">}</span></code></pre>
<ul>
<li>future： <code>UninitCell</code> 类型，异步任务的 Future</li>
</ul>
<p>​</p>
<h4 id="os_task_storageclaim"><a class="header" href="#os_task_storageclaim"><code>OS_TASK_STORAGE::claim</code></a></h4>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn claim() -&gt; OS_TCB_REF {
    // by noah: for we can create task after OSTaskCreate, so we need a cs
    critical_section::with(|cs| {
        let task_storage = ARENA.alloc::&lt;OS_TASK_STORAGE&lt;F&gt;&gt;(cs);
        // create a new task which is not init
        task_storage.write(OS_TASK_STORAGE::new());
        // by noah：no panic will occurred here because if the Arena is not enough, the program will panic when alloc
        OS_TCB_REF {
            ptr: Some(NonNull::new(task_storage as *mut _ as _).unwrap()),
        }
    })
}
<span class="boring">}</span></code></pre>
<p>通过前面提到的 <code>ARENA</code> 分配内存空间，初始化并返回 <code>OS_TCB_REF</code> TCB指针（这里为什么返回<code>OS_TCB_REF</code> 而不返回 <code>OS_TASK_STORAGE</code> ，其实个人认为是一样的，因为结构体成员的内存分布是连续的，也就是说返回的结构体的地址是一样的，<code>init</code> 也会进行强转）</p>
<p>​</p>
<h4 id="os_task_storageinit"><a class="header" href="#os_task_storageinit"><code>OS_TASK_STORAGE::init</code></a></h4>
<pre><code>pub fn init(
    prio: INT8U,
    id: INT16U,
    pext: *mut (),
    opt: INT16U,
    _name: String,
    future_func: impl FnOnce() -&gt; F,
)
</code></pre>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let task_ref = OS_TASK_STORAGE::&lt;F&gt;::claim();
let this: &amp;mut OS_TASK_STORAGE&lt;F&gt;;
unsafe {
    this = &amp;mut *(task_ref.as_ptr() as *mut OS_TASK_STORAGE&lt;F&gt;);
    this.task_tcb.OS_POLL_FN.set(Some(OS_TASK_STORAGE::&lt;F&gt;::poll));
    this.future.write_in_place(future_func);
}
<span class="boring">}</span></code></pre>
<ul>
<li>
<p>4行，强制类型转换</p>
</li>
<li>
<p>5行，配置该任务的 Poll 方法，rust异步的必要操作？</p>
</li>
<li>
<p>6行，任务创建时传入的任务闭包写入内存</p>
</li>
</ul>
<p>​</p>
<h2 id="timer_queuers"><a class="header" href="#timer_queuers">timer_queue.rs</a></h2>
<p>在原本的 <code>ucosii</code> 中，任务的时间管理依赖于  <code>SysTick</code>，每次 <code>SysTick</code> 触发中断时，遍历 TCB链表，逐步递减 <code>OSTCBDly</code> 计数，若计数归零，则将任务加入就绪队列，也就是轮询的方式。</p>
<p>但异步不需要轮询的，这里采用的是时钟队列的实现方式：</p>
<h4 id="timerqueue结构体"><a class="header" href="#timerqueue结构体"><code>TimerQueue</code>结构体</a></h4>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub(crate) struct TimerQueue {
    head: SyncUnsafeCell&lt;Option&lt;OS_TCB_REF&gt;&gt;,
    pub(crate) set_time: SyncUnsafeCell&lt;u64&gt;,
}
<span class="boring">}</span></code></pre>
<ul>
<li>
<p><code>head</code> 表示队列的头保存一个指向 <code>OS_TCB_REF</code>的 <code>Option</code>，用于标识队列的首任务</p>
</li>
<li>
<p><code>set_time</code> 表示队列中任务的下一到期时间，即最近需加入就绪队列的时间</p>
</li>
</ul>
<p>全局调度器一个维护 <code>TimerQueue</code> 实例，当任务主动释放控制权时会添加到该时钟队列。</p>
<p>另外需要注意的一点是，最近到达的三个任务（任务总数大于等于3时）会像上面 port 节中的 <code>time_driver</code> 注册 <code>alarm</code>，用于唤醒</p>
<p>​</p>
<h2 id="wakerrs"><a class="header" href="#wakerrs">waker.rs</a></h2>
<p>rust异步的Waker实现</p>
<p>​</p>
<h2 id="modrs-3"><a class="header" href="#modrs-3">mod.rs</a></h2>
<blockquote>
<p>核心代码，异步调度器的实现</p>
</blockquote>
<h3 id="syncexecutor结构体"><a class="header" href="#syncexecutor结构体"><code>SyncExecutor结构体</code></a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// The executor for the uC/OS-II RTOS.
pub(crate) struct SyncExecutor {
    // the prio tbl stores a relation between the prio and the task_ref
    os_prio_tbl: SyncUnsafeCell&lt;[OS_TCB_REF; (OS_LOWEST_PRIO + 1) as usize]&gt;,
    // indicate the current running task
    pub(crate) OSPrioCur: SyncUnsafeCell&lt;OS_PRIO&gt;,
    pub(crate) OSTCBCur: SyncUnsafeCell&lt;OS_TCB_REF&gt;,
    // highest priority task in the ready queue
    pub(crate) OSPrioHighRdy: SyncUnsafeCell&lt;OS_PRIO&gt;,
    pub(crate) OSTCBHighRdy: SyncUnsafeCell&lt;OS_TCB_REF&gt;,
    // by liam: add a bitmap to record the status of the task
    #[cfg(feature = "OS_PRIO_LESS_THAN_64")]
    OSRdyGrp: SyncUnsafeCell&lt;u8&gt;,
    #[cfg(feature = "OS_PRIO_LESS_THAN_64")]
    OSRdyTbl: SyncUnsafeCell&lt;[u8; OS_RDY_TBL_SIZE]&gt;,
    #[cfg(feature = "OS_PRIO_LESS_THAN_256")]
    OSRdyGrp: u16,
    #[cfg(feature = "OS_PRIO_LESS_THAN_256")]
    OSRdyTbl: [u16; OS_RDY_TBL_SIZE],
    pub(crate) timer_queue: timer_queue::TimerQueue,
    pub(crate) alarm: AlarmHandle,
}
<span class="boring">}</span></code></pre>
<ul>
<li>
<p><code>os_prio_tbl</code>：优先级表，个数为 OS_LOWEST_PRIO + 1，也就是最低优先级+1个。初始化时全为空，当创建任务时，对应序号为该任务优先级的元素会存储该任务的TCB指针。优先级表很重要，关于调度器的很多代码都基于它</p>
</li>
<li>
<p><code> OSRdyGrp</code>，<code>OSRdyTbl</code>：优先级位图法的实现，即就绪队列</p>
</li>
<li>
<p><code>timer_queue</code> ：上面提到的时钟队列</p>
</li>
<li>
<p><code>alarm</code>：闹钟</p>
</li>
</ul>
<p>仍然通过 <code>lazy_static</code> 声明</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>lazy_static! {
    pub(crate) static ref GlobalSyncExecutor: Option&lt;SyncExecutor&gt; = Some(SyncExecutor::new());
}
<span class="boring">}</span></code></pre>
<p>关于 <code>SyncExecutor</code> 的工具函数实现就不展开说明了，这里着重分析一下调度器核心的几个函数</p>
<p>​</p>
<h4 id="alarm_callback"><a class="header" href="#alarm_callback"><code>alarm_callback</code></a></h4>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn alarm_callback(ctx: *mut ()) {
    let this: &amp;Self = unsafe { &amp;*(ctx as *const Self) };
    // first to dequeue all the expired task, note that there must
    // have a task in the tiemr_queue because the alarm is triggered
    loop {
        unsafe { this.timer_queue.dequeue_expired(RTC_DRIVER.now(), wake_task_no_pend) };
        // then we need to set a new alarm according to the next expiration time
        let next_expire = unsafe { this.timer_queue.next_expiration() };
        // by noah：we also need to updater the set_time of the timer_queue
        unsafe {
            this.timer_queue.set_time.set(next_expire);
        }
        if RTC_DRIVER.set_alarm(this.alarm, next_expire) {
            break;
        }
    }
    // call Interrupt Context Switch
    unsafe { this.IntCtxSW() };
}
<span class="boring">}</span></code></pre>
<p>设置的闹钟回调函数，当任务延时到达时，会调用该函数。在poll函数完成配置：</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>RTC_DRIVER.set_alarm_callback(self.alarm, Self::alarm_callback, self as *const _ as *mut ());
<span class="boring">}</span></code></pre>
<p>​</p>
<h4 id="intctxsw"><a class="header" href="#intctxsw"><code>IntCtxSW</code></a></h4>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// as an interface to join the scheduler logic
pub(crate) unsafe fn IntCtxSW(&amp;'static self) {
    if critical_section::with(|_| unsafe {
        let new_prio = self.find_highrdy_prio();
        if new_prio &gt;= self.OSPrioCur.get() {
            false
        } else {
            if OSIntNesting.load(Ordering::Acquire) == 0{
                if OSLockNesting.load(Ordering::Acquire) == 0{
                    self.set_highrdy_with_prio(new_prio);
                    return true;
                }
            }
            false
        }
    }) 
    {
        unsafe { self.interrupt_poll() }
    }
}
<span class="boring">}</span></code></pre>
<ul>
<li><code>find_highrdy_prio</code> 找到最高优先级，随后可以看到其实还是去调用 <code>interrupt_poll</code></li>
</ul>
<p>进入调度器调度逻辑的接口，如果自己编写的代码想进入调度可以调用该函数。</p>
<p>​</p>
<h4 id="interrupt_poll"><a class="header" href="#interrupt_poll"><code>interrupt_poll</code></a></h4>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub(crate) unsafe fn interrupt_poll(&amp;'static self) {
    extern "Rust" {
        fn OSTaskStkInit(stk_ref: NonNull&lt;OS_STK&gt;) -&gt; NonNull&lt;OS_STK&gt;;
        fn restore_thread_task();
    }

    if *self.OSPrioCur.get_unmut() != OS_TASK_IDLE_PRIO {
        self.OSTCBCur.get().is_in_thread_poll.set(false);
        // If the current task will be deleted, 
        // setting 'is_in_thread_poll' to 'true' will destroy the stack in PenSV
        if self.os_prio_tbl.get_unmut()[*self.OSPrioCur.get_unmut() as usize].ptr.is_none() 		{
            self.OSTCBCur.get().is_in_thread_poll.set(true);
        }
    }
    
    let mut task = critical_section::with(|_| self.OSTCBHighRdy.get());
    if task.OSTCBStkPtr.is_none() {
        // if the task has no stack, it's a task, we need to mock a stack for it.
        // we need to alloc a stack for the task
        let mut stk: OS_STK_REF;
        if *self.OSPrioCur.get_unmut() == OS_TASK_IDLE_PRIO {    
            // if is idle, we don't need to alloc stack,just use the idle stack
            // but this branch will not be executed
            let mut program_stk = PROGRAM_STACK.exclusive_access();
            program_stk.STK_REF = NonNull::new(
                program_stk.HEAP_REF.as_ptr().offset(program_stk.layout.size() as isize) as *mut OS_STK,
            )
            .unwrap();
            stk = program_stk.clone();
        } else {
            let layout = Layout::from_size_align(TASK_STACK_SIZE, 4).unwrap();
            stk = alloc_stack(layout);
        }
        // then we need to mock the stack for the task(the stk will change during the mock)
        stk.STK_REF = OSTaskStkInit(stk.STK_REF);

        task.OSTCBStkPtr = Some(stk);
    }
    
    // restore the task from stk
    critical_section::with(|_| {
        if task.OSTCBPrio == *self.OSPrioHighRdy.get_unmut() {
            unsafe {
                restore_thread_task()
            };
        }
    });
}
<span class="boring">}</span></code></pre>
<ul>
<li>
<p>7-14行，这里会难懂一点，因为涉及到 <code>is_in_thread_poll</code> 用来区别线程协程的TCB成员。在通过PenSV异常中断完成任务切换后，被切换的任务的<code>is_in_thread_poll</code> 会被置为true，也就是协程。所以在再次进入PenSV上下文切换前修改该变量，IDLE任务默认设置为协程不需要重新设置，其他任务则设置为false，但如果当前任务是即将被删除的任务（也就是调用了 <code>OSTaskDel</code> 函数）会将其置为true，这样技能回收其分配的栈空间了，具体原因及细节可见本人写的“周报4-7 ~ 4-11节“。</p>
</li>
<li>
<p>17-38行，获取最高优先级任务，判断堆栈是否为空，为空则需要分配堆栈</p>
</li>
<li>
<p>41-47行，<code>restore_thread_task()</code> 实则是触发PenSV异常中断，进入其异常处理函数去完成上下文切换</p>
</li>
</ul>
<p>​</p>
<h1 id="设计框图"><a class="header" href="#设计框图">设计框图</a></h1>
<h2 id="系统流程图"><a class="header" href="#系统流程图">系统流程图</a></h2>
<p><img src="../discussions/graph/SystemFlowchart.png" alt=""></p>
<p>这是整个系统的流程图，大致描述了系统是如果完成任务调度的：</p>
<p>系统启动后，首先由 <strong>OSInit</strong> 完成 RTOS 的整体初始化工作，包括初始化内核外设（如时钟、定时器和中断控制器）、建立空闲任务（Idle Task）以及创建系统所需的各类内部管理结构。同时，<strong>OSInit</strong> 会分配了一块独立的全局的 <strong>程序栈</strong>（是用于栈复用的）和 <strong>中断栈</strong>（专用于在中断发生时保存中断上下文）。</p>
<p>完成初始化后，调用 <strong>OSCreateTask</strong> 接口进行任务创建，该过程会为每个用户定义的任务生成并初始化任务控制块（TCB），包括设置任务优先级、栈指针等核心信息。随后，执行 <strong>OSStart</strong> 正式启动调度器，进入系统的主循环。</p>
<p><code>poll</code>方法只会在os启动后调用一次，主要用于设置alarm闹钟的回调函数。</p>
<p>随后进入 <strong>single_poll</strong> ：</p>
<ol>
<li>single_poll 从准备就绪的任务队列（按优先级排序的就绪位图 Priority Bitmap）中选择<strong>最高优先级</strong>的异步任务；</li>
<li>调用该任务的 <code>poll</code> 方法，启动任务体代码的执行；</li>
<li>任务执行过程中如遇到主动调用 <strong>OSTimeDly</strong>，则主动释放 CPU，将自身加入<strong>时钟队列</strong>（delay queue），并向时钟驱动注册一个新的闹钟，用于在指定时刻唤醒任务；</li>
</ol>
<p>当某个任务的闹钟到期时，执行 <strong>alarm_callback</strong> 回调函数，回调函数内部最终则会去调用 <strong>interrupt_poll</strong>，重新进入调度器的核心逻辑，完成给新任务分配栈，完成任务堆栈初始化，从STK中恢复上下文，触发PenSV保存上下文一系列操作。</p>
<p>比较巧妙的是，执行完PenSV的逻辑，恢复的上下文中PC值被设定为进行模拟压栈时压入的 <code>executor_function_ptr</code> 闭包的地址，这个闭包会去调用再次 <code>single_poll</code>，这样就可以保证在切换后，会进入调度器的代码逻辑。</p>
<p>总的来说，通过 <strong>single_poll</strong> 与 <strong>interrupt_poll</strong> 两个调度函数的交替执行，结合闹钟回调触发机制，系统实现了<strong>基于优先级的抢占式调度</strong>与<strong>延迟唤醒</strong>的完整闭环。</p>
<p>​</p>
<h2 id="系统框图"><a class="header" href="#系统框图">系统框图</a></h2>
<p><img src="../discussions/graph/SystemBlockDiagram.png" alt=""></p>
<p>该框图展示了 <strong>embassy_preempt</strong> 的整体架构。全局调度器 <strong>executor</strong> 维护了系统的任务就绪队列，其底层通过右侧的优先级位图（Priority Bitmap）实现。位图和任务控制块（TCB）优先级相关的大部分操作均采用“空间换时间”的策略，以尽可能保证调度的实时性与确定性。</p>
<p>同时，executor 还维护左侧的 <strong>OS_prio_tbl</strong> 优先级表，其中存放所有任务的 TCB 指针。很大部分关于调度器的代码都是基于这个数据结构开展的。</p>
<p>在协程调度中，<strong>interrupt_poll</strong> 是调度器的核心函数。它首先从就绪队列中选出最高优先级的任务执行，并触发 PendSV 异常完成上下文切换。如果在任务执行过程中没有更高优先级的任务抢占，该任务在执行结束后会调用 <strong>OSTimeDly</strong> 主动释放 CPU，并向左上角的时钟驱动注册一个闹钟（alarm）。此时，任务进入休眠状态，调度器转而执行下一个就绪队列中的最高优先级任务。闹钟到期后，回调函数会重新调用 <strong>interrupt_poll</strong>，再次选取当前最高优先级的任务，实现抢占式调度。</p>
<p>为了支持协程的优先级抢占，系统需要在运行时动态分配任务栈，以保存被抢占任务的上下文。右下角的 <strong>Stack Allocator</strong> 即为此功能模块，其基于适用于 no_std 环境的链表分配器实现。当 <strong>interrupt_poll</strong> 检测到新任务首次执行时，会调用栈分配器分配栈空间；而在 <strong>PendSV</strong> 中断中完成上下文切换后，则负责回收已切换出任务的栈空间。</p>
<p>​</p>
<h2 id="时钟驱动"><a class="header" href="#时钟驱动">时钟驱动</a></h2>
<p><img src="../discussions/graph/TimerDrive.png" alt=""></p>
<p>主要是实现了一个timer的驱动。完成异步任务的延迟与定时唤醒</p>
<p>而这里，时钟驱动维护有alarm闹钟以及period。period就是一个时间戳，从上电起将会以更新中断的形式完成自增，这里我们设定的是 0.32768s更新一次。alarm闹钟则是异步任务延时的核心</p>
<p>我们知道，事件驱动是需要通过回调函数来实现对特定事件的响应，而异步任务就是事件驱动，不需要像ucosii那样主动轮询。</p>
<p>下面是调度器维护的一个时钟队列，当异步任务主动让权，会根据抵达时间前后加入时钟队列，而时钟队列会将最近抵达的任务，向时钟驱动注册一个alarm，当alarm到达，意味着有任务被唤醒，底层实际上是定时器的捕获中断，将会调用回调函数，加入就绪队列，如果优先级比当前任务高则实施抢占。</p>
<p>​</p>
<p>定时器驱动负责管理异步任务的延迟与定时唤醒，其核心由两部分组成：<strong>period</strong> 和 <strong>alarm 闹钟</strong>。</p>
<ol>
<li>period：
自系统上电起，period 作为时钟驱动的全局时间戳，以固定间隔递增。这里设定每 0.32768 秒通过定时器更新中断将 period 加 1。</li>
<li>alarm 闹钟：
异步任务在执行过程中若主动调用延时接口（如 OSTimeDly），会将自身的唤醒时间（目标时间戳）插入调度器维护的<strong>时钟队列</strong>。时钟队列始终追踪下一个到期任务，并向硬件定时器注册对应的 alarm。</li>
<li>延迟唤醒流程：
当硬件定时器捕获到期中断时，会触发 alarm 回调函数：
<ul>
<li>将到期任务从时钟队列中移除</li>
<li>将该任务加入就绪队列</li>
<li>若该任务优先级高于当前运行任务，则通过 PendSV 异常进行抢占式上下文切换</li>
</ul>
</li>
</ol>
<p>通过上述机制，异步任务无需轮询即可在指定时间自动唤醒，实现基于事件驱动的高效调度。</p>
<p>​</p>
<h2 id="组件化框图"><a class="header" href="#组件化框图">组件化框图</a></h2>
<p><img src="../discussions/graph/ComponentizedDiagram.png" alt=""></p>
<p>这是将项目解耦合组件化之后的结构框图。</p>
<p><strong>executor</strong>：调度器核心代码</p>
<p><strong>port</strong>：体系架构相关代码，包括时钟驱动</p>
<p><strong>cfg</strong>：整个RTOS的类型定义、os配置参数及定义、定时器tick值等</p>
<p><strong>cell</strong>：目前存放调度器所需要用到的 Cell 的上层封装，完成内部可变性的代码，后续可以存放关于Rust特性的代码</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="资料汇总"><a class="header" href="#资料汇总">资料汇总</a></h1>
<h1 id="本篇主要内容-1"><a class="header" href="#本篇主要内容-1">本篇主要内容</a></h1>
<p>本篇主要聚焦于与开发过程中相关的一些其他的软件项目</p>
<h1 id="embassy"><a class="header" href="#embassy">Embassy</a></h1>
<h2 id="1-task-arena"><a class="header" href="#1-task-arena">1. <strong>Task arena</strong></a></h2>
<p>from: <a href="https://docs.embassy.dev/embassy-executor/git/cortex-m/index.html">https://docs.embassy.dev/embassy-executor/git/cortex-m/index.html</a></p>
<h3 id="11-attention-we-set-the-arena-size-to-the-sum-of-sizes-of-all-tasks"><a class="header" href="#11-attention-we-set-the-arena-size-to-the-sum-of-sizes-of-all-tasks">1.1 Attention: we set the arena size to the sum of sizes of all tasks.</a></h3>
<p>When the <code>nightly</code> Cargo feature is not enabled, <code>embassy-executor</code> allocates tasks out of an arena (a very simple bump allocator).
If the task arena gets full, the program will panic at runtime. To guarantee this doesn’t happen, you must set the size to <strong>the sum of sizes of all tasks</strong>.</p>
<h3 id="12-attention-we-can-set-arena-size-in-two-ways"><a class="header" href="#12-attention-we-can-set-arena-size-in-two-ways">1.2 Attention: we can set arena size in two ways</a></h3>
<p>The arena size can be configured in two ways:</p>
<ul>
<li><strong>Via Cargo features</strong>: enable a Cargo feature like <code>task-arena-size-8192</code>. <strong>Only a selection of values</strong> is available, see <a href="https://docs.embassy.dev/embassy-executor/git/cortex-m/index.html#task-arena-size">Task Area Sizes</a> for reference.</li>
<li><strong>Via environment variables at build time</strong>: set the variable named <code>EMBASSY_EXECUTOR_TASK_ARENA_SIZE</code>. For example <code>EMBASSY_EXECUTOR_TASK_ARENA_SIZE=4321 cargo build</code>. You can also set them in the <code>[env]</code> section of <code>.cargo/config.toml</code>. <strong>Any value can be set</strong>, unlike with Cargo features.</li>
</ul>
<p><strong>Environment variables take precedence over Cargo features</strong>. If two Cargo features are enabled for the same setting with different values, compilation fails.</p>
<h2 id="2-executor"><a class="header" href="#2-executor">2. Executor</a></h2>
<p>from: <a href="https://docs.embassy.dev/embassy-executor/git/cortex-m/index.html#executor">https://docs.embassy.dev/embassy-executor/git/cortex-m/index.html#executor</a></p>
<h3 id="21-attention-the-executor-interrupt-particularly-in-cortex-m"><a class="header" href="#21-attention-the-executor-interrupt-particularly-in-cortex-m">2.1 Attention the executor-interrupt particularly in cortex-M</a></h3>
<ul>
<li><code>executor-thread</code> — Enable the thread-mode executor (using WFE/SEV in Cortex-M, WFI in other embedded archs)</li>
<li><code>executor-interrupt</code> — Enable the interrupt-mode executor (available in Cortex-M only)</li>
</ul>
<h2 id="3-attribute-macros"><a class="header" href="#3-attribute-macros">3. <strong>Attribute Macros</strong></a></h2>
<p>from: <a href="https://docs.embassy.dev/embassy-executor/git/cortex-m/index.html#attributes">https://docs.embassy.dev/embassy-executor/git/cortex-m/index.html#attributes</a></p>
<h3 id="31-attention-we-can-spawn-multiple-task-from-the-same-function-by-setting-the-pool_size"><a class="header" href="#31-attention-we-can-spawn-multiple-task-from-the-same-function-by-setting-the-pool_size">3.1 Attention: we can spawn multiple task from the same function by setting the pool_size</a></h3>
<ul>
<li>
<p><a href="https://docs.embassy.dev/embassy-executor/git/cortex-m/attr.main.html">main</a></p>
<p>Creates a new <code>executor</code> instance and declares an application entry point for Cortex-M spawning the corresponding function body as an async task.</p>
</li>
<li>
<p><a href="https://docs.embassy.dev/embassy-executor/git/cortex-m/attr.task.html">task</a></p>
<p>Declares an async task that can be run by <code>embassy-executor</code>. The optional <code>pool_size</code> parameter can be used to specify how many concurrent tasks can be spawned (default is 1) for the function.</p>
</li>
</ul>
<h2 id="4-what-is-const-generic-and-how-we-use"><a class="header" href="#4-what-is-const-generic-and-how-we-use">4. what is const generic and how we use?</a></h2>
<p><a href="https://www.awwsmm.com/blog/what-are-const-generics-and-how-are-they-used-in-rust">https://www.awwsmm.com/blog/what-are-const-generics-and-how-are-they-used-in-rust</a></p>
<p><a href="https://doc.rust-lang.org/reference/items/generics.html#const-generics">https://doc.rust-lang.org/reference/items/generics.html#const-generics</a></p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Examples where const generic parameters can be used.

// Used in the signature of the item itself.
fn foo&lt;const N: usize&gt;(arr: [i32; N]) {
    // Used as a type within a function body.
    let x: [i32; N];
    // Used as an expression.
    println!("{}", N * 2);
}

// Used as a field of a struct.
struct Foo&lt;const N: usize&gt;([i32; N]);

impl&lt;const N: usize&gt; Foo&lt;N&gt; {
    // Used as an associated constant.
    const CONST: usize = N * 4;
}

trait Trait {
    type Output;
}

impl&lt;const N: usize&gt; Trait for Foo&lt;N&gt; {
    // Used as an associated type.
    type Output = [i32; N];
}
<span class="boring">}</span></code></pre>
<h2 id="5additional-part-for-previous-blog"><a class="header" href="#5additional-part-for-previous-blog">5.additional part for <a href="https://liamy.clovy.top/e771385866b0465990dcd7e17870b591#a71a07cdddde4f0196809b9cf4eff89c">previous blog</a>:</a></h2>
<h3 id="51-note-the-type-dont-be-messed-up"><a class="header" href="#51-note-the-type-dont-be-messed-up">5.1 note the type, don’t be messed up</a></h3>
<p>from embassy-executor/src/raw/mod.rs:189</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;F: Future + 'static&gt; AvailableTask&lt;F&gt; {
    /// Try to claim a [`TaskStorage`].
    ///
    /// This function returns `None` if a task has already been spawned and has not finished running.
    pub fn claim(task: &amp;'static TaskStorage&lt;F&gt;) -&gt; Option&lt;Self&gt; {
        task.raw.state.spawn().then(|| Self { task })
    }

    fn initialize_impl&lt;S&gt;(self, future: impl FnOnce() -&gt; F) -&gt; SpawnToken&lt;S&gt; {
        unsafe {
            self.task.raw.poll_fn.set(Some(TaskStorage::&lt;F&gt;::poll));
            self.task.future.write_in_place(future);

            let task = TaskRef::new(self.task);

            SpawnToken::new(task)
        }
    }

    /// Initialize the [`TaskStorage`] to run the given future.
    pub fn initialize(self, future: impl FnOnce() -&gt; F) -&gt; SpawnToken&lt;F&gt; {
        self.initialize_impl::&lt;F&gt;(future)
    }
...
}
<span class="boring">}</span></code></pre>
<p>Note the parameter future is not what we thought of future. In fact it’s return is what <code>future</code> in rust is, which is generic type F who implement the Future trait.</p>
<p>And so we found that <code>self.task.future.write_in_place(future);</code> , who’s <code>write_in_place</code> function is critical:</p>
<p>from embassy-executor/src/raw/util.rs:5</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub(crate) struct UninitCell&lt;T&gt;(MaybeUninit&lt;UnsafeCell&lt;T&gt;&gt;);
impl&lt;T&gt; UninitCell&lt;T&gt; {
    pub const fn uninit() -&gt; Self {
        Self(MaybeUninit::uninit())
    }

    pub unsafe fn as_mut_ptr(&amp;self) -&gt; *mut T {
        (*self.0.as_ptr()).get()
    }

    #[allow(clippy::mut_from_ref)]
    pub unsafe fn as_mut(&amp;self) -&gt; &amp;mut T {
        &amp;mut *self.as_mut_ptr()
    }

    #[inline(never)]
    pub unsafe fn write_in_place(&amp;self, func: impl FnOnce() -&gt; T) {
        ptr::write(self.as_mut_ptr(), func())
    }

    pub unsafe fn drop_in_place(&amp;self) {
        ptr::drop_in_place(self.as_mut_ptr())
    }
}
<span class="boring">}</span></code></pre>
<p>note that what the <code>write_in_place</code> does is just call the func(in our example is the future parameter who implement the FnOnce() → T trait). So actually we write the return future which truly implement Future trait into the <code>UninitCell</code>, which in our example is future member of TaskStorage:</p>
<p>from embassy-executor/src/raw/mod.rs:104</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[repr(C)]
pub struct TaskStorage&lt;F: Future + 'static&gt; {
    raw: TaskHeader,
    future: UninitCell&lt;F&gt;, // Valid if STATE_SPAWNED
}
<span class="boring">}</span></code></pre>
<h2 id="6-embassy-book"><a class="header" href="#6-embassy-book">6. Embassy Book</a></h2>
<p><a href="https://embassy.dev/book/#_the_memory_definition_for_my_stm_chip_seems_wrong_how_do_i_define_a_memory_x_file">Embassy Book</a></p>
<h1 id="cortex-m-pac"><a class="header" href="#cortex-m-pac">cortex-m pac</a></h1>
<h2 id="1-interrupt-vector-table"><a class="header" href="#1-interrupt-vector-table">1. Interrupt Vector Table</a></h2>
<p>from: <a href="https://github.com/rust-embedded/cortex-m?tab=readme-ov-file">https://github.com/rust-embedded/cortex-m?tab=readme-ov-file</a></p>
<p><a href="https://crates.io/crates/cortex-m-rt"><code>cortex-m-rt</code></a>: Startup code and interrupt handling</p>
<h2 id="2-the-attributes"><a class="header" href="#2-the-attributes">2. the Attributes:</a></h2>
<p>from: <a href="https://docs.rs/cortex-m-rt/latest/cortex_m_rt/">https://docs.rs/cortex-m-rt/latest/cortex_m_rt/</a></p>
<h3 id="21-intro"><a class="header" href="#21-intro">2.1 Intro</a></h3>
<p>This crate also provides the following attributes:</p>
<ul>
<li><a href="https://docs.rs/cortex-m-rt/latest/cortex_m_rt/attr.entry.html"><code>#[entry]</code></a> to declare the entry point of the program</li>
<li><a href="https://docs.rs/cortex-m-rt/latest/cortex_m_rt/attr.exception.html"><code>#[exception]</code></a> <strong>to override an exception handler</strong>. If not overridden all exception handlers default to an infinite loop.</li>
<li><a href="https://docs.rs/cortex-m-rt/latest/cortex_m_rt/attr.pre_init.html"><code>#[pre_init]</code></a> to run code <em>before</em> <code>static</code> variables are initialized</li>
</ul>
<p>This crate also implements a related attribute called <code>#[interrupt]</code>, which allows you to define interrupt handlers. However, since which interrupts are available depends on the microcontroller in use, this attribute should be re-exported and used from a device crate.
The documentation for these attributes can be found in the <a href="https://docs.rs/cortex-m-rt/latest/cortex_m_rt/#attributes">Attribute Macros</a> section.</p>
<h3 id="22-the-attribute-macros"><a class="header" href="#22-the-attribute-macros">2.2 the <a href="https://docs.rs/cortex-m-rt/latest/cortex_m_rt/#attributes"><strong>Attribute Macros</strong></a></a></h3>
<p><a href="https://docs.rs/cortex-m-rt/latest/cortex_m_rt/attr.entry.html">entry</a>:         Attribute to declare the entry point of the program</p>
<p><a href="https://docs.rs/cortex-m-rt/latest/cortex_m_rt/attr.exception.html">exception</a>:  Attribute to declare an exception handler</p>
<p><a href="https://docs.rs/cortex-m-rt/latest/cortex_m_rt/attr.interrupt.html">interrupt</a>:    Attribute to declare an interrupt (AKA device-specific exception) handler</p>
<p><a href="https://docs.rs/cortex-m-rt/latest/cortex_m_rt/attr.pre_init.html">pre_init</a>:      Attribute to mark which function will be called at the beginning of the reset handler.</p>
<h3 id="23-attribute-macro-cortex_m_rtexception"><a class="header" href="#23-attribute-macro-cortex_m_rtexception"><strong>2.3 Attribute Macro <a href="https://docs.rs/cortex-m-rt/latest/cortex_m_rt/index.html">cortex_m_rt</a>::<a href="https://docs.rs/cortex-m-rt/latest/cortex_m_rt/attr.exception.html#">exception</a></strong></a></h3>
<h3 id="syntax"><a class="header" href="#syntax"><a href="https://docs.rs/cortex-m-rt/latest/cortex_m_rt/attr.exception.html#syntax"><strong>Syntax</strong></a></a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[exception]
fn SysTick() {
    // ..
}
<span class="boring">}</span></code></pre>
<p>where the name of the function must be one of:</p>
<ul>
<li><code>DefaultHandler</code></li>
<li><code>NonMaskableInt</code></li>
<li><code>HardFault</code></li>
<li><code>MemoryManagement</code> (a)</li>
<li><code>BusFault</code> (a)</li>
<li><code>UsageFault</code> (a)</li>
<li><code>SecureFault</code> (b)</li>
<li><code>SVCall</code></li>
<li><code>DebugMonitor</code> (a)</li>
<li><code>PendSV</code></li>
<li><code>SysTick</code></li>
</ul>
<p>(a) Not available on Cortex-M0 variants (<code>thumbv6m-none-eabi</code>)</p>
<p>(b) Only available on ARMv8-M</p>
<h3 id="usage"><a class="header" href="#usage"><a href="https://docs.rs/cortex-m-rt/latest/cortex_m_rt/attr.exception.html#usage"><strong>Usage</strong></a></a></h3>
<p><code>#[exception] unsafe fn HardFault(..</code> sets the hard fault handler. The handler must have signature <code>unsafe fn(&amp;ExceptionFrame) -&gt; !</code>. This handler is not allowed to return as that can cause undefined behavior.</p>
<p><code>#[exception] unsafe fn DefaultHandler(..</code> sets the <em>default</em> handler. All exceptions which have not been assigned a handler will be serviced by this handler. This handler must have signature <code>unsafe fn(irqn: i16) [-&gt; !]</code>. <code>irqn</code> is the IRQ number (See CMSIS); <code>irqn</code> will be a negative number when the handler is servicing a core exception; <code>irqn</code> will be a positive number when the handler is servicing a device specific exception (interrupt).</p>
<p><code>#[exception] fn Name(..</code> overrides the default handler for the exception with the given <code>Name</code>. These handlers must have signature <code>[unsafe] fn() [-&gt; !]</code>. When overriding these other exception it’s possible to add state to them by declaring <code>static mut</code> variables at the beginning of the body of the function. These variables will be safe to access from the function body.</p>
<h1 id="drone-rtos"><a class="header" href="#drone-rtos">Drone RTOS</a></h1>
<p>Some reference about the research of RTOS in rust:<a href="https://arewertosyet.com/">https://arewertosyet.com/</a></p>
<p>we need two repo, the file directory is：</p>
<pre><code class="language-ignore">├── drone
│   ├── CHANGELOG.md
│   ├── Cargo.lock
│   ├── Cargo.toml
│   ├── LICENSE-APACHE
│   ├── LICENSE-MIT
│   ├── README.md
│   ├── config
│   ├── flake.lock
│   ├── flake.nix
│   ├── openocd
│   ├── project-templates
│   ├── rustfmt.toml
│   ├── src
│   ├── stream
│   └── templates
└── drone-core
    ├── CHANGELOG.md
    ├── Cargo.toml
    ├── LICENSE-APACHE
    ├── LICENSE-MIT
    ├── README.md
    ├── flake.lock
    ├── flake.nix
    ├── macros
    ├── macros-core
    ├── rustfmt.toml
    ├── src
    └── tests
</code></pre>
<p><a href="https://github.com/drone-os/drone">https://github.com/drone-os/drone</a></p>
<p><a href="https://github.com/drone-os/drone-core">https://github.com/drone-os/drone-core</a></p>
<p>we reference from the drone book:<a href="https://book.drone-os.com/introduction.html">https://book.drone-os.com/introduction.html</a></p>
<h2 id="1memory-allocation"><a class="header" href="#1memory-allocation">1.Memory Allocation</a></h2>
<p><a href="https://api.drone-os.com/drone-core/0.14/drone_core/heap/index.html">drone_core::heap - Rust</a></p>
<p>Dynamic memory is crucial for Drone operation. Objectives like real-time characteristics, high concurrency, small code size, fast execution have led to Memory Pools design of the heap. All operations are lock-free and have <em>O(1)</em> time complexity, which means they are deterministic.</p>
<p>The continuous memory region for the heap is split into pools. A pool is further split into fixed-sized blocks that hold actual allocations. A pool is defined by its block-size and the number of blocks. The pools configuration should be defined in the compile-time. A drawback of this approach is that memory pools may need to be tuned for the application.</p>
<p>Using empiric values for the memory pools layout may lead to undesired memory fragmentation. Eventually the layout will need to be tuned for the application. Drone can capture allocation statistics from the real target device at the run-time and generate an optimized memory layout for this specific application. Ideally this will result in zero fragmentation.</p>
<p>The actual steps are platform-specific. Refer to the platform crate documentation for instructions.</p>
<h3 id="11-we-need-the-platform-module-and-stream-module"><a class="header" href="#11-we-need-the-platform-module-and-stream-module">1.1 we need the platform module and stream module</a></h3>
<p>To adapt our structure, I decide to add it to helper directory, the whole structure like this:</p>
<pre><code class="language-ignore">├── helper
│   ├── linked_list.rs
│   ├── macros.rs
│   ├── mod.rs
│   ├── runtime.rs
│   └── soft_atomic.rs
</code></pre>
<p>and to use stream, I have to import it’s dependency—<code>drone_stream</code>  directly into the <code>mod.rs</code></p>
<p>finally our project like this(I omit the other parts that not belonged to our adapt of Drone):</p>
<pre><code class="language-ignore">├── heap
│   ├── mod.rs
│   ├── pool.rs
│   └── trace.rs
├── helper
│   ├── linked_list.rs
│   ├── macros.rs
│   ├── mod.rs
│   ├── runtime.rs
│   └── soft_atomic.rs
├── lang_items.rs
├── lib.rs
├── platform
│   ├── interrputs.rs
│   └── mod.rs
</code></pre>
<h3 id="12-with-heap-we-can-do-more-thing-like-smart-pointer"><a class="header" href="#12-with-heap-we-can-do-more-thing-like-smart-pointer">1.2 with heap we can do more thing like smart pointer</a></h3>
<p><img src="docs/graph/ref1.png" alt="                                     the mind map of the smart pointer’s memory allocation "></p>
<pre><code>                                 the mind map of the smart pointer’s memory allocation 
</code></pre>
<h3 id="13-problem-we-need-heap-macro"><a class="header" href="#13-problem-we-need-heap-macro">1.3 problem: we need heap! macro</a></h3>
<p>according to the api doc:</p>
<p><a href="https://api.drone-os.com/drone-core/0.14/drone_core/heap/index.html#usage">https://api.drone-os.com/drone-core/0.14/drone_core/heap/index.html#usage</a></p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use drone_core::heap;

// Define a concrete heap type with the layout defined in the Drone.toml
heap! {
    // Heap configuration key in `Drone.toml`.
    config =&gt; main;
    /// The main heap allocator generated from the `Drone.toml`.
    metadata =&gt; pub Heap;
    // Use this heap as the global allocator.
    global =&gt; true;
    // Uncomment the following line to enable heap tracing feature:
    // trace_port =&gt; 31;
}

// Create a static instance of the heap type and declare it as the global
// allocator.
/// The global allocator.
#[global_allocator]
pub static HEAP: Heap = Heap::new();
<span class="boring">}</span></code></pre>
<p>we need to use the macro heap, which is a <code>proc-macro</code> of rust, we have to know it’s grammar:</p>
<p><a href="https://www.notion.so/proc-macro-1-c9ef4b1da67d48b8969da5e060050443?pvs=21">proc-macro (1)</a></p>
<p>you should know workspace:</p>
<p><a href="https://doc.rust-lang.org/cargo/reference/workspaces.html">Workspaces - The Cargo Book</a></p>
<p>As the macro in drone is so poor in designing, I give up port it to my project. So I try to construct a global allocator myself.</p>
<p>there is my reference:</p>
<p><a href="https://os.phil-opp.com/heap-allocation/">Heap Allocation | Writing an OS in Rust</a></p>
<p><a href="https://os.phil-opp.com/allocator-designs/#fixed-size-block-allocator">Allocator Designs | Writing an OS in Rust</a></p>
<p>When I implementing the allocator above, as it discussed, we also need linked list to optimize our design:</p>
<p><a href="https://os.phil-opp.com/allocator-designs/#linked-list-allocator">Allocator Designs | Writing an OS in Rust</a></p>
<p>I leave the tutorial’s linked list example, but still use the <code>linked_list_allocator</code> crate because of the merge of freed blocks.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="rust-ucos-ii开发杂记"><a class="header" href="#rust-ucos-ii开发杂记">Rust-uC/OS II开发杂记</a></h1>
<h1 id="本篇主要内容-2"><a class="header" href="#本篇主要内容-2">本篇主要内容</a></h1>
<p>本篇的主要内容为，在开发过程中遇到的一些代码上的问题，包括Rust的语言特性，以及对Embassy和uCOSII更深层次的一点理解和一些变动</p>
<h1 id="1-rust-cargo-error"><a class="header" href="#1-rust-cargo-error">1. rust cargo error</a></h1>
<h2 id="11-cargo-shows-error"><a class="header" href="#11-cargo-shows-error">1.1 cargo shows error</a></h2>
<p>rust analyzer runs at the same time you run a <code>cargo</code> command after updating the toolchain file. If it’s not that please open a new rustup issue</p>
<p><a href="https://github.com/rust-lang/rust-clippy/issues/12763">https://github.com/rust-lang/rust-clippy/issues/12763</a></p>
<p>The workaround is to uninstall the toolchain and reinstall it, usually stopping rust analyzer or similar while you’re doing that</p>
<h2 id="12-cargo-stuck-in--waiting-for-cargo-metadata-or-cargo-check"><a class="header" href="#12-cargo-stuck-in--waiting-for-cargo-metadata-or-cargo-check">1.2 cargo stuck in  <strong>waiting for cargo metadata or cargo check</strong></a></h2>
<p><a href="https://github.com/rust-lang/rust-analyzer/issues/10910">https://github.com/rust-lang/rust-analyzer/issues/10910</a></p>
<h2 id="13-a-chinese-problem-we-may-need-mirror-accelerate"><a class="header" href="#13-a-chinese-problem-we-may-need-mirror-accelerate">1.3 A Chinese problem, we may need mirror accelerate</a></h2>
<p><a href="https://juejin.cn/post/7133482060307496997">https://juejin.cn/post/7133482060307496997</a></p>
<p>and we set a proxy for git</p>
<p><a href="https://blog.csdn.net/yoyo_u/article/details/132637141">https://blog.csdn.net/yoyo_u/article/details/132637141</a></p>
<h1 id="2-defmt"><a class="header" href="#2-defmt">2. defmt</a></h1>
<p>as the code show below, the defmt and log feature can not be active at the same time.</p>
<pre><code class="language-jsx">#[cfg(all(feature = "defmt", feature = "log"))]
compile_error!("You may not enable both `defmt` and `log` features.");
</code></pre>
<h1 id="3-why-embassy-executors-test-can-run-with-src-in-no_std"><a class="header" href="#3-why-embassy-executors-test-can-run-with-src-in-no_std">3. Why Embassy-Executor’s test can run with src in no_std?</a></h1>
<p><a href="https://stackoverflow.com/questions/28185854/how-do-i-test-crates-with-no-std">https://stackoverflow.com/questions/28185854/how-do-i-test-crates-with-no-std</a></p>
<h1 id="4-rust-conditional-compilation"><a class="header" href="#4-rust-conditional-compilation">4. rust conditional compilation</a></h1>
<h2 id="41-how-to-use-env-section-of-cargoconfigtoml"><a class="header" href="#41-how-to-use-env-section-of-cargoconfigtoml">4.1 how to use <code>[env]</code> section of <code>.cargo/config.toml</code></a></h2>
<p><a href="https://doc.rust-lang.org/cargo/reference/config.html">https://doc.rust-lang.org/cargo/reference/config.html</a></p>
<h2 id="42-the-usage-of-cfg--cfg_attr"><a class="header" href="#42-the-usage-of-cfg--cfg_attr">4.2 the usage of cfg &amp; cfg_attr</a></h2>
<p><a href="https://doc.rust-lang.org/reference/conditional-compilation.html">https://doc.rust-lang.org/reference/conditional-compilation.html</a></p>
<h1 id="5covariant"><a class="header" href="#5covariant">5.covariant</a></h1>
<p><a href="https://doc.rust-lang.org/reference/subtyping.html">https://doc.rust-lang.org/reference/subtyping.html</a></p>
<p><a href="https://stackoverflow.com/questions/74990774/how-to-understand-covariance-in-rust">https://stackoverflow.com/questions/74990774/how-to-understand-covariance-in-rust</a></p>
<p><a href="https://doc.rust-lang.org/nomicon/subtyping.html">https://doc.rust-lang.org/nomicon/subtyping.html</a></p>
<p><img src="docs/graph/dev1.png" alt="Untitled"></p>
<h1 id="6-fnonce-vs-fnmut-vs-fn-rust"><a class="header" href="#6-fnonce-vs-fnmut-vs-fn-rust">6. fnonce vs fnmut vs fn rust</a></h1>
<p><a href="https://google.github.io/comprehensive-rust/std-traits/closures.html">https://google.github.io/comprehensive-rust/std-traits/closures.html</a></p>
<h1 id="7-how-can-we-transfer-from-a-function-pointer-to-a-closure"><a class="header" href="#7-how-can-we-transfer-from-a-function-pointer-to-a-closure">7. how can we transfer from a function pointer to a closure</a></h1>
<h1 id="8-const-fn"><a class="header" href="#8-const-fn">8. const fn</a></h1>
<p>The const fn can be called at compiling time so there are some restrictions of it(Just like cpp?).</p>
<p><a href="https://doc.rust-lang.org/reference/const_eval.html">https://doc.rust-lang.org/reference/const_eval.html</a></p>
<h1 id="9-feature-edition2021-is-required"><a class="header" href="#9-feature-edition2021-is-required">9. feature <code>edition2021</code> is required</a></h1>
<p>Caused by:
feature <code>edition2021</code> is required</p>
<p>consider adding <code>cargo-features = ["edition2021"]</code> to the manifest</p>
<p><a href="https://stackoverflow.com/questions/69848319/unable-to-specify-edition2021-in-order-to-use-unstable-packages-in-rust">https://stackoverflow.com/questions/69848319/unable-to-specify-edition2021-in-order-to-use-unstable-packages-in-rust</a></p>
<p>however, my problem is that my toolchain set the rust so old</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>[toolchain]
channel = "nightly-2024-06-18"
components = [ "clippy", "llvm-tools-preview", "rust-src", "rustfmt" ]
profile = "minimal"
<span class="boring">}</span></code></pre>
<h1 id="10-liveshare-give-full-access"><a class="header" href="#10-liveshare-give-full-access">10. liveshare give full access</a></h1>
<p><a href="https://stackoverflow.com/questions/53729195/visual-studio-live-share-as-a-host-how-to-give-access-permission-to-my-particip">https://stackoverflow.com/questions/53729195/visual-studio-live-share-as-a-host-how-to-give-access-permission-to-my-particip</a></p>
<h1 id="11-cant-use-lazy_static-with-no_std"><a class="header" href="#11-cant-use-lazy_static-with-no_std">11. can’t use lazy_static with no_std</a></h1>
<p><a href="https://stackoverflow.com/questions/73049446/could-not-compile-lazy-static">https://stackoverflow.com/questions/73049446/could-not-compile-lazy-static</a></p>
<p><a href="https://github.com/rust-lang-nursery/lazy-static.rs/issues/35">https://github.com/rust-lang-nursery/lazy-static.rs/issues/35</a></p>
<h1 id="12-the-layout-of-rust"><a class="header" href="#12-the-layout-of-rust">12. the <code>layout</code> of rust</a></h1>
<p><a href="https://doc.rust-lang.org/reference/type-layout.html">https://doc.rust-lang.org/reference/type-layout.html</a></p>
<p><a href="https://doc.rust-lang.org/nightly/core/alloc/struct.Layout.html">https://doc.rust-lang.org/nightly/core/alloc/struct.Layout.html</a></p>
<h1 id="13-how-to-design-the-ostcbtbl"><a class="header" href="#13-how-to-design-the-ostcbtbl">13. how to design the OSTCBTbl</a></h1>
<p>To make space allocation certain, we can not design the <code>OSTCBTbl</code> as uC/OS. In uC/OS the TCBs’ size is confirmed and same. But in our Rust-uC/OS, because we use future, the size of <code>TaskStorage</code> is not the same, and we can not confirmed it before we know how the async func is defined.</p>
<p>We can find that the source of the problem is the size of futures of every <code>TaskStorage</code> is different, but we want to make it the same to avoid some tough issues related to memory.</p>
<aside>
💡 So I thought about to set the Size of `TaskStorage` as the maximum of all the objects of `TaskStorage` . But because we can not calculate the maximum when we init the TCB Table, so we abandoned the plan.
</aside>
<p>There is another way to solve this problem: using pointer. But unavoidably there will be some raw pointers and unsafe code block. But for now, we will take this approach. In the future, we can wrap the raw pointer by some types to make our code safe.</p>
<h1 id="14-the-function-of-unsafecell"><a class="header" href="#14-the-function-of-unsafecell">14. the Function of UnsafeCell</a></h1>
<p>Quote from copilot:</p>
<blockquote>
<p><strong>内部可变性</strong>：允许在外部看似不可变的情况下，修改<code>UnsafeCell&lt;T&gt;</code>内部的值。这对于实现像<code>RefCell&lt;T&gt;</code>和<code>Mutex&lt;T&gt;</code>这样的类型非常重要，这些类型提供了在运行时而不是编译时检查借用规则的能力。
<strong>绕过借用规则</strong>：正常情况下，Rust不允许在存在不可变引用的同时创建可变引用，因为这可能导致数据竞争和不一致的状态。然而，通过使用<code>UnsafeCell&lt;T&gt;</code>，开发者可以手动管理这种访问，允许在不违反所有权模型的前提下，进行更灵活的内存访问。
<strong>安全性责任</strong>：使用<code>UnsafeCell&lt;T&gt;</code>意味着绕过了Rust编译器的安全检查，将安全性的责任转移到了开发者身上。开发者需要确保使用<code>UnsafeCell&lt;T&gt;</code>时不会引入数据竞争或其他安全问题。
<strong>底层构建块</strong>：<code>UnsafeCell&lt;T&gt;</code>通常被用作构建更高级别抽象的底层构建块，如同步原语（<code>Mutex</code>、<code>RwLock</code>等）或其他需要内部可变性的类型。直接使用<code>UnsafeCell&lt;T&gt;</code>是不常见的，除非你正在实现这些高级抽象。</p>
</blockquote>
<p>So, only when the inner var is immutable, but we need it to be mutable temporary will we wrap the var in <code>UnsafeCell</code> . It is common to wrap static var or var with static life-cycles in <code>UnsafeCell</code></p>
<h1 id="15-the-import-of-future"><a class="header" href="#15-the-import-of-future">15. the import of Future</a></h1>
<p>In the definition of TCB, we need to import the future of the task. But for Future is a trait, so we only import it as a trait bound:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub(crate) struct OS_TCB&lt;F: Future + 'static&gt;{...}
<span class="boring">}</span></code></pre>
<p>But we want to be uncoupled so that in other crate, only OS_TCB_REF can be visited. So we wrap the TCB as OS_TCB_REF:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct OS_TCB_REF{
    ptr:NonNull&lt;OS_TCB&gt;,
}
<span class="boring">}</span></code></pre>
<p>But after we import the Future, we need to add a trait bound to OS_TCB_REF too:</p>
<pre><code class="language-jsx">pub struct OS_TCB_REF&lt;F: Future + 'static&gt;{
    ptr:NonNull&lt;OS_TCB&lt;F&gt;&gt;,
}
</code></pre>
<p>Besides, everything about the OS_TCB_REF needs to be added a trait bound. As a result, there will be too much var having a static life time, which is not what we want to see.</p>
<aside>
💡 In uC，TCB can have a static life time in order to ensure the certainty of space allocation. But we don’t want to make the REF also having the static life time, because only the running task is meaningful to us.
</aside>
<p>In Embassy, the TCB is separated from the future：</p>
<pre><code class="language-jsx">pub struct TaskStorage&lt;F: Future + 'static&gt; {
    raw: TaskHeader,
    future: UninitCell&lt;F&gt;, // Valid if STATE_SPAWNED
}
</code></pre>
<p><code>TaskRef</code> still point to <code>TaskHeader</code> , which has nothing to do with Future.:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Clone, Copy)]
pub struct TaskRef {
    ptr: NonNull&lt;TaskHeader&gt;,
}
<span class="boring">}</span></code></pre>
<p>In this way, there is no need to add a trait bound to <code>TaskRef</code> . So it can be recycled freely. When we want to get the <code>TaskStorage</code> , we can use type casting, for <code>TaskHeader</code> is <code>TaskStorage</code> ’s first member.</p>
<p>So we will refer to the realization of Embassy. So in OS_init, we should alloc an array of <code>OS_TASK_STORAGE</code>, instead of <code>OS_TCB</code> .</p>
<h1 id="16-the-executor"><a class="header" href="#16-the-executor">16. the Executor</a></h1>
<p>In the Rust-uC we imagine, there is no concept of thread. So there just need an executor, which I will make it lazy_static.</p>
<p>Besides, there is also no need to add a member to TCB to store the executor, which is different to Embassy.</p>
<h1 id="17-string--str"><a class="header" href="#17-string--str">17. String &amp; str</a></h1>
<p>At the beginning, we can only use str, for it is a slice, which doesn’t require a heap allocator.</p>
<p>But there is still one problem: the size of str can be confirmed when compiling. So we have to impl a heap allocator. Otherwise, we can only use unsafe code.</p>
<p>After we impl a heap allocator, we can use the String type, which is <strong>Sized</strong> in Rust.</p>
<h1 id="18-global-static-var"><a class="header" href="#18-global-static-var">18. Global Static Var</a></h1>
<p>In the first version of our uC/OS, we just use <code>pub</code> and <code>static</code> to define global var. It is so annoyed because it makes our code unsafe. In the second version of Rust-uC, we try to refer to the realization of Embassy and rCore.</p>
<p>In Embassy, the <code>RtcDriver</code> is static and we need to change its member in the static life time. It’s definition looks like:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>embassy_time_driver::time_driver_impl!(static DRIVER: RtcDriver = RtcDriver {
    period: AtomicU32::new(0),
    alarm_count: AtomicU8::new(0),
    alarms: Mutex::const_new(CriticalSectionRawMutex::new(), [ALARM_STATE_NEW; ALARM_COUNT]),
    #[cfg(feature = "low-power")]
    rtc: Mutex::const_new(CriticalSectionRawMutex::new(), Cell::new(None)),
});
<span class="boring">}</span></code></pre>
<p>Here, Embassy use <code>Mutex</code> and <code>AtomicU32</code> for the static structure’s member to ensure the thread safety. The <code>Mutex</code> used here is defined in <code>embassy::sync</code> and <code>AtomicU32</code> is in the <code>core::sync::atomic</code> . Actually, there is also a <code>Mutex</code> in <code>critical-section</code> . It expose a safe interface to us. Because there is only one core on our board, so we can ensure that if we acquire a critical section, the interrupt will be disable and task will not switch.</p>
<p>So we will use <code>AtomicU32</code> to keep var of primary data type thread safe, and use <code>critical-section::Mutex&lt;RefCell&lt;T&gt;&gt;</code> to keep var of other type safe.</p>
<p>Besides, by using <code>Atomic</code> , we can change the global var without critical section:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn next_period(&amp;self) {
    let r = regs_gp16();

    // We only modify the period from the timer interrupt, so we know this can't race.
    let period = self.period.load(Ordering::Relaxed) + 1;
    self.period.store(period, Ordering::Relaxed);
    let t = (period as u64) &lt;&lt; 15;

    critical_section::with(move |cs| {
        r.dier().modify(move |w| {
            for n in 0..ALARM_COUNT {
                let alarm = &amp;self.alarms.borrow(cs)[n];
                let at = alarm.timestamp.get();

                if at &lt; t + 0xc000 {
                    // just enable it. `set_alarm` has already set the correct CCR val.
                    w.set_ccie(n + 1, true);
                }
            }
        })
    })
}
<span class="boring">}</span></code></pre>
<p>The period’s type is <code>AtomicU32</code> and it is one of the members of the RtcDriver. But in the example pick out from Embassy above, it can be get and set without a critical section.</p>
<p>Before, our code looks like this:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// need a cs
critical_section::with(|_cs| unsafe {
    if OS_IS_RUNNING &amp;&amp; OSINT_NESTING &gt; 0 {
        OSINT_NESTING -= 1;
    }
    let _os_int_nesting = OSINT_NESTING;
    // info!("in os_int_exit the OSINT_NESTING is {}", OSINT_NESTING);
    if OS_IS_RUNNING &amp;&amp; OSINT_NESTING == 0 {
        os_sched_new();
        OS_TCB_HIGH_RDY = OS_TCB_PRIO_TBL[OS_PRIO_HIGH_RDY as usize];
        (*OS_TCB_HIGH_RDY).stride += OS_STRIDE_NUM / (OS_LOWEST_PRIO - (*OS_TCB_HIGH_RDY).os_prio as usize);
        if OS_PRIO_CUR != OS_PRIO_HIGH_RDY {
            // update the stride
            OSIntCtxSw();
        }
    }
});
<span class="boring">}</span></code></pre>
<p>Though we can ensure there will only one thread enter the critical section, there is still a huge unsafe block.</p>
<p>But now our code may looks like:</p>
<pre class="playground"><code class="language-rust">static FOO: Mutex&lt;RefCell&lt;i32&gt;&gt; = Mutex::new(RefCell::new(42));

fn main() {
   critical_section::with(|cs| {
       // Instead of calling this
       let _ = FOO.borrow(cs).take();
       // Call this
       let _ = FOO.take(cs);
       // `RefCell::borrow` and `RefCell::borrow_mut` are renamed to
       // `borrow_ref` and `borrow_ref_mut` to avoid name collisions
       let _: &amp;mut i32 = &amp;mut *FOO.borrow_ref_mut(cs);
   })
}</code></pre>
<p>Good, there is no unsafe block.</p>
<aside>
💡 we use the type:`Mutex<refcell<i32>&gt;` to define the static var because `RefCell` is not thread safe.

<h1 id="19-the-function-of-refcell"><a class="header" href="#19-the-function-of-refcell">19. the Function of RefCell</a></h1>
<p>In the last part, there is a type: <code>RefCell</code> . It provide a mechanism for borrowing checks at run time. We need this because if we do static check on our borrowing of the global var, there are many places that get mutable references to global variables, which will make our code can not pass compiling. But in an OS, this situation is unavoidable, so we need <code>RefCell</code> to do borrowing checks at run time.</p>
<h1 id="20-the-order-of-atomic"><a class="header" href="#20-the-order-of-atomic">20. the Order of Atomic</a></h1>
<p><a href="https://course.rs/advance/concurrency-with-threads/sync2.html">https://course.rs/advance/concurrency-with-threads/sync2.html</a></p>
<p>There is a para we should pass to func <code>load</code> and <code>store</code> when we need to read or write the Atomic var. The para is order. Its type is <code>Ordering</code> , which is an enum.</p>
<p>As the comment on <code>Ordering</code> in Rust lib, <code>Ordering</code> is used to:</p>
<blockquote>
<p>Memory orderings specify the way atomic operations synchronize memory.</p>
</blockquote>
<p>There are five possible values of <code>Ordering</code> :</p>
<ul>
<li>
<p>Relaxed</p>
<blockquote>
<p>No ordering constraints, only atomic operations.
<a href="https://en.cppreference.com/w/cpp/atomic/memory_order#Relaxed_ordering">https://en.cppreference.com/w/cpp/atomic/memory_order#Relaxed_ordering</a></p>
</blockquote>
</li>
<li>
<p>Release</p>
<blockquote>
<p>When coupled with a <strong>store</strong>, all previous operations become ordered before any load of this value with [<code>Acquire</code>] (or stronger) ordering.In particular, all previous writes become visible to all threads that perform an [<code>Acquire</code>] (or stronger) load of this value.
This ordering is only applicable for operations that can perform a store
<a href="https://en.cppreference.com/w/cpp/atomic/memory_order#Release-Acquire_ordering">https://en.cppreference.com/w/cpp/atomic/memory_order#Release-Acquire_ordering</a></p>
</blockquote>
</li>
<li>
<p>Acquire</p>
<blockquote>
<p>When coupled with a load, if the loaded value was written by a store operation with [<code>Release</code>] (or stronger) ordering, then all subsequent operations become ordered after that store. In particular, all subsequent loads will see data written before the store.
<a href="https://en.cppreference.com/w/cpp/atomic/memory_order#Release-Acquire_ordering">https://en.cppreference.com/w/cpp/atomic/memory_order#Release-Acquire_ordering</a></p>
</blockquote>
</li>
<li>
<p>AcqRel</p>
<blockquote>
<p>Has the effects of both [<code>Acquire</code>] and [<code>Release</code>] together:
For loads it uses [<code>Acquire</code>] ordering. For stores it uses the [<code>Release</code>] ordering.
<a href="https://en.cppreference.com/w/cpp/atomic/memory_order#Release-Acquire_ordering">https://en.cppreference.com/w/cpp/atomic/memory_order#Release-Acquire_ordering</a></p>
</blockquote>
</li>
<li>
<p>SeqCst</p>
<blockquote>
<p>Like [<code>Acquire</code>]/[<code>Release</code>]/[<code>AcqRel</code>] (for load, store, and load-with-store operations, respectively) with the additional guarantee that all threads see all sequentially consistent operations in the same order.
<a href="https://en.cppreference.com/w/cpp/atomic/memory_order#Sequentially-consistent_ordering">https://en.cppreference.com/w/cpp/atomic/memory_order#Sequentially-consistent_ordering</a></p>
</blockquote>
</li>
</ul>
<p>In the comment of the possible values, we can know that we can build a Memory Barrier by using <code>Release</code> coupled with <code>store</code> and  <code>Acquire</code> coupled with <code>load</code> (or just use <code>AcqRel</code>). In this way, we can ensure the <strong>synchronization</strong> when we read or write an Atomic var, just like we set a mutex.</p>
<aside>
💡 By `Release` , the operations before `store` will be finished before the `store` operation, which can ensure that the `store` op is effective and the stored value is visible to other threads. By `Acquire` , the operations after `load` will not be finished before the `load` operation, which can ensure that the `load` op can load the val we need.
</aside>
<p>There is an example:</p>
<pre class="playground"><code class="language-rust">use std::thread::{self, JoinHandle};
use std::sync::atomic::{Ordering, AtomicBool};

static mut DATA: u64 = 0;
static READY: AtomicBool = AtomicBool::new(false);

fn reset() {
    unsafe {
        DATA = 0;
    }
    READY.store(false, Ordering::Relaxed);
}

fn producer() -&gt; JoinHandle&lt;()&gt; {
    thread::spawn(move || {
        unsafe {
            DATA = 100;                                 // A
        }
        READY.store(true, Ordering::Release);           // B: Memory Barrier ↑
    })
}

fn consumer() -&gt; JoinHandle&lt;()&gt; {
    thread::spawn(move || {
        while !READY.load(Ordering::Acquire) {}         // C: Memory Barrier ↓

        assert_eq!(100, unsafe { DATA });               // D
    })
}

fn main() {
    loop {
        reset();

        let t_producer = producer();
        let t_consumer = consumer();

        t_producer.join().unwrap();
        t_consumer.join().unwrap();
    }
}</code></pre>
<h1 id="21-steps-to-adapt-to-embassy"><a class="header" href="#21-steps-to-adapt-to-embassy">21. steps to adapt to embassy</a></h1>
<p><a href="https://www.notion.so/embassy-9ae45929a3dc49128a4349679d38fa07?pvs=21">embassy 改变设计想法</a></p>
<h1 id="22-design-of-the-testing-part"><a class="header" href="#22-design-of-the-testing-part">22. Design of the testing part</a></h1>
<p><img src="docs/graph/dev2.png" alt="Untitled"></p>
<p><a href="https://os.phil-opp.com/testing/">https://os.phil-opp.com/testing/</a></p>
<p><a href="https://ferrous-systems.com/blog/tags/embedded-rust-testing/">https://ferrous-systems.com/blog/tags/embedded-rust-testing/</a></p>
<h2 id="221-i-choose-the-defmt-test"><a class="header" href="#221-i-choose-the-defmt-test">22.1 I choose the defmt-test:</a></h2>
<p><a href="https://github.com/knurling-rs/defmt/tree/704bee6ebfa153aad9dba1fcee5ba0ec6b77f3a8/firmware/defmt-test">defmt/firmware/defmt-test at 704bee6ebfa153aad9dba1fcee5ba0ec6b77f3a8 · knurling-rs/defmt</a></p>
<h2 id="222-and-learn-from-the-template-to-know-how-to-use-it"><a class="header" href="#222-and-learn-from-the-template-to-know-how-to-use-it">22.2 And learn from the template to know how to use it:</a></h2>
<p><a href="https://github.com/knurling-rs/app-template">https://github.com/knurling-rs/app-template</a></p>
<h1 id="23-what-does-flip-link-do-"><a class="header" href="#23-what-does-flip-link-do-">23. what does <strong><code>flip-link</code> do ?</strong></a></h1>
<p><a href="https://github.com/knurling-rs/flip-link">https://github.com/knurling-rs/flip-link</a></p>
<p><img src="docs/graph/dev3.png" alt="Untitled"></p>
<p><img src="docs/graph/dev4.png" alt="Untitled"></p>
<h1 id="24-we-need-taskpoolref"><a class="header" href="#24-we-need-taskpoolref">24. We Need TaskPoolRef</a></h1>
<p>Just as the comments in Embassy：</p>
<blockquote>
<p>type-erased <code>&amp;'static mut TaskPool&lt;F, N&gt;</code>. Needed because statics can’t have generics.</p>
</blockquote>
<p>Because the TaskPool is static in both our uC and Embassy, so it is important to use <code>TaskPoolRef</code> to define a <code>TaskPool</code>in a static life time</p>
<aside>
💡 the `Arena` is also known as `OSTCBTbl` in uC/OS
</aside>
<p>plus: I add note of static usage:<a href="https://doc.rust-lang.org/reference/items/static-items.html">https://doc.rust-lang.org/reference/items/static-items.html</a></p>
<p>and the embassy use this to init TaskPool static var once in the task macro design:</p>
<p>from file embassy-executor-macros/src/macros:113</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    #[cfg(not(feature = "nightly"))]
    let mut task_outer: ItemFn = parse_quote! {
        #visibility fn #task_ident(#fargs) -&gt; ::embassy_executor::SpawnToken&lt;impl Sized&gt; {
            const POOL_SIZE: usize = #pool_size;
            static POOL: ::embassy_executor::_export::TaskPoolRef = ::embassy_executor::_export::TaskPoolRef::new();
            unsafe { POOL.get::&lt;_, POOL_SIZE&gt;()._spawn_async_fn(move || #task_inner_ident(#(#full_args,)*)) }
        }
    };
<span class="boring">}</span></code></pre>
<h1 id="25-about-arena"><a class="header" href="#25-about-arena">25. About Arena</a></h1>
<p>In the last part, we know that we need <code>TaskPoolRef</code> because statics can’t have generics. But a new problem arose: The <code>TaskPoolRef</code> is static but <code>TaskPool</code> is not. This will cause error because a ref’s life time is longer than the data it points. So we should do something to make <code>TaskPool</code> static too.</p>
<p>In Embassy, <code>TaskPool</code> become static with the help of <code>Arena</code> . It defined as:</p>
<pre><code class="language-jsx">    struct Arena&lt;const N: usize&gt; {
        buf: UnsafeCell&lt;MaybeUninit&lt;[u8; N]&gt;&gt;,
        ptr: Mutex&lt;Cell&lt;*mut u8&gt;&gt;,
    }
</code></pre>
<p>For now, we just focus on <code>buf</code> . It is a <code>UnsafeCell&lt;MaybeUninit&lt;[u8; N]&gt;&gt;</code> . About <code>MaybeUninit</code> , we will discuss it below. Now we just need to know that <code>MaybeUninit</code> ’s memory layout is the same to <code>[u8; N]</code> . So if we claim an <code>Arena</code> with static life time, its member will be static too. We get what we want.</p>
<aside>
💡 “N” is defined as the number of bytes of the TaskPool.
</aside>
<p>Maybe you will ask that if we use <code>Arena</code> , why do we still need the <code>TaskPool</code> and <code>TaskPoolRef</code> ? As shown above and in Embassy, the <code>Arena</code> just used to alloc a piece of memory but <code>TaskPool</code> or <code>TaskPoolRef</code> is used to complete the relevant parts of the task and scheduling. By this, the coupling degree is reduced. Of course we can define <code>Arena</code> as:</p>
<pre><code class="language-jsx">   struct Arena&lt;const N: usize&gt; {
        buf: UnsafeCell&lt;MaybeUninit&lt;[TaskStorage; N]&gt;&gt;,
        ptr: Mutex&lt;Cell&lt;*mut u8&gt;&gt;,
    }
</code></pre>
<p>In this way, the the coupling degree increases, and there is anther problem: if we use <code>TaskStorage</code> directly, we need genericity, which can’t be added to the static <code>Arena</code> .</p>
<h1 id="26-sync-and-send-trait"><a class="header" href="#26-sync-and-send-trait">26. Sync and Send trait</a></h1>
<p><a href="https://doc.rust-lang.org/nomicon/send-and-sync.html">Send and Sync - The Rustonomicon</a></p>
<ul>
<li>A type is Send if it is safe to send it to another thread.</li>
<li>A type is Sync if it is safe to share between threads (T is Sync if and only if <code>&amp;T</code> is Send).</li>
</ul>
<h1 id="27-maybeuninit"><a class="header" href="#27-maybeuninit">27. MaybeUninit</a></h1>
<p>This type is used to define vars which are not init. Its memory layout is the same to the genericity var’s memory layout. MaybeUninit is defined as:</p>
<pre><code class="language-jsx">  pub union MaybeUninit&lt;T&gt; {
      uninit: (),
      value: ManuallyDrop&lt;T&gt;,
  }
</code></pre>
<p>For more information about MaybeUninit, read: <a href="https://learnku.com/articles/65520">https://learnku.com/articles/65520</a></p>
<h1 id="28-deref-and-derefmut"><a class="header" href="#28-deref-and-derefmut">28. Deref and DerefMut</a></h1>
<p>The usage of these trait is:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span> use std::ops::{Deref, DerefMut};

 struct DerefMutExample&lt;T&gt; {
     value: T
 }

 impl&lt;T&gt; Deref for DerefMutExample&lt;T&gt; {
     type Target = T;

     fn deref(&amp;self) -&gt; &amp;Self::Target {
         &amp;self.value
     }
 }

 impl&lt;T&gt; DerefMut for DerefMutExample&lt;T&gt; {
     fn deref_mut(&amp;mut self) -&gt; &amp;mut Self::Target {
         &amp;mut self.value
     }
 }
<span class="boring">}</span></code></pre>
<p>Maybe you will be confused with the <code>Target</code> in <code>DerefMut</code> . Once you know how <code>DerefMut</code> defined, you won’t be confused:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait DerefMut: Deref {
    /// Mutably dereferences the value.
    #[stable(feature = "rust1", since = "1.0.0")]
    #[rustc_diagnostic_item = "deref_mut_method"]
    fn deref_mut(&amp;mut self) -&gt; &amp;mut Self::Target;
}
<span class="boring">}</span></code></pre>
<h1 id="29-关于refmut"><a class="header" href="#29-关于refmut">29. 关于refmut</a></h1>
<p><a href="https://doc.rust-lang.org/std/cell/struct.RefMut.html">https://doc.rust-lang.org/std/cell/struct.RefMut.html</a></p>
<h3 id="refcell"><a class="header" href="#refcell"><strong><code>RefCell</code></strong></a></h3>
<p><code>RefCell</code> is a type that provides interior mutability. It allows you to borrow its contents either mutably or immutably, but these borrows are checked at runtime. If you try to violate Rust’s borrowing rules (e.g., having multiple mutable borrows or a mutable borrow while there are immutable borrows), the program will panic.</p>
<h3 id="refmut"><a class="header" href="#refmut"><strong><code>RefMut</code></strong></a></h3>
<p><code>RefMut</code> is a smart pointer type that <code>RefCell</code> returns when you borrow its contents mutably. It implements <code>Deref</code> and <code>DerefMut</code>, so you can use it like a regular mutable reference.</p>
<h1 id="30-tokenstream"><a class="header" href="#30-tokenstream">30. TokenStream</a></h1>
<p><a href="https://zjp-cn.github.io/rust-note/proc/proc_macro2.html">https://zjp-cn.github.io/rust-note/proc/proc_macro2.html</a></p>
<h1 id="31-quote"><a class="header" href="#31-quote">31. quote!</a></h1>
<p><a href="https://zjp-cn.github.io/rust-note/proc/quote.html#quote-%E4%B8%8E-totokens">https://zjp-cn.github.io/rust-note/proc/quote.html#quote-与-totokens</a></p>
<h1 id="32-过程宏"><a class="header" href="#32-过程宏">32. 过程宏</a></h1>
<p><a href="https://zjp-cn.github.io/rust-note/proc/ref.html">https://zjp-cn.github.io/rust-note/proc/ref.html</a></p>
<p>学习过程宏的lab（感觉可以考虑开学出成题目）：</p>
<p><a href="https://github.com/dtolnay/proc-macro-workshop">https://github.com/dtolnay/proc-macro-workshop</a></p>
<p>感觉还不错的中文博客：</p>
<p><a href="https://rustmagazine.github.io/rust_magazine_2021/chapter_5/proc_macro_workshop_guide_for_builder_project.html">Rust过程宏系列教程 | Proc Macro Workshop 之 Builder 实现 - Rust精选</a></p>
<p>我自己的lab笔记：</p>
<p><a href="https://liamy.clovy.top/en/article/notes/proc-macro-workshop">proc-macro-workshop 笔记 | LiamY’s Blog</a></p>
<p>很有用的宏debug工具，把宏展开的样子写出来：</p>
<p><a href="https://github.com/dtolnay/cargo-expand">https://github.com/dtolnay/cargo-expand</a></p>
<h1 id="33-out_dir环境变量"><a class="header" href="#33-out_dir环境变量">33. OUT_DIR环境变量</a></h1>
<p><a href="https://rustwiki.org/zh-CN/cargo/reference/environment-variables.html">https://rustwiki.org/zh-CN/cargo/reference/environment-variables.html</a></p>
</refcell<i32></aside><div style="break-before: page; page-break-before: always;"></div>
<h1 id="开发时间表"><a href="#开发时间表" class="header">开发时间表</a></h1>
<ol>
<li>
<p>上下文切换的分类：分成抢占和让权两种；</p>
</li>
<li>
<p>上下文切换的过程分成保存和恢复两步。抢占时的保存会占用堆栈，可视为线程；让权时的保存会让出堆栈，可视为协程。恢复过程按是否需要空栈分成线程恢复和协程恢复两种情况。</p>
</li>
<li>
<p>可能的实施线路：</p>
<ol>
<li>在uCOS中<strong>没有中断的场景</strong>下，引入embassy，以支持协程；（线程被视为不会暂停的协程）
<ul>
<li>统一线程和协程的控制块结构TCB（Task Control Block）；</li>
<li>只有让权情况出现，让权时栈空，可以复用栈；（解决堆栈的分配和回收问题）</li>
</ul>
</li>
<li>在uCOS中没有中断的场景下，引入embassy和<strong>优先级</strong>，以支持线程和协程的优先级调度；
<ul>
<li>按优先级选就绪任务（可能是线程，也可能是协程）；</li>
</ul>
</li>
<li>在uCOS中<strong>有中断的场景</strong>下，引入embassy和优先级，以支持线程和协程的优先级调度；
<ul>
<li>中断就是抢占情况，需要保存堆栈，并（有可能）分配新堆栈，用于恢复下一个任务；</li>
</ul>
</li>
</ol>
<p>时间线安排：</p>
<p>7.28-7.29：完成思路设计结束</p>
<p>7.30-8.5：至少完成线路1整体代码部分，测试以及debug可以留到下周</p>
<p>8.6-8.12：至少完成线路1，最好线路2也完成了</p>
<p>8.13-8.19： 完成线路2以及完成最终的抢占设计的代码部分，测试以及debug可以留到下周</p>
<p>8.20-8.26：完成所有测试与debug</p>
<p>8.27-…: 做一些数据分析以及形成较好的文档</p>
<p>修正时间线：</p>
<p>8.13-8.19: 完成所有代码，开始debug</p>
<p>8.20-8.26: 完成所有测试与debug</p>
</li>
</ol>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr-ef4e11c1.min.js"></script>
        <script src="mark-09e88c2c.min.js"></script>
        <script src="searcher-c2a407aa.js"></script>

        <script src="clipboard-1626706a.min.js"></script>
        <script src="highlight-abc7f01d.js"></script>
        <script src="book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
